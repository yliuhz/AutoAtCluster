{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "206fd8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import normalized_mutual_info_score as NMI, adjusted_mutual_info_score as AMI, adjusted_rand_score as ARI\n",
    "import scipy.sparse as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea05ad4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68459251",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_assortative(dataset=\"cora\"):\n",
    "    import pickle as pkl\n",
    "    import networkx as nx\n",
    "    import scipy.sparse as sp\n",
    "    import torch\n",
    "\n",
    "    def parse_index_file(filename):\n",
    "        index = []\n",
    "        for line in open(filename):\n",
    "            index.append(int(line.strip()))\n",
    "        return index\n",
    "\n",
    "    def sample_mask(idx, l):\n",
    "        \"\"\"Create mask.\"\"\"\n",
    "        mask = np.zeros(l)\n",
    "        mask[idx] = 1\n",
    "        return np.array(mask, dtype=np.bool)\n",
    "\n",
    "    if dataset in [\"cora\", \"citeseer\", \"pubmed\"]:\n",
    "        names = ['x', 'y', 'tx', 'ty', 'allx', 'ally', 'graph']\n",
    "        objects = []\n",
    "\n",
    "        for i in range(len(names)):\n",
    "            '''\n",
    "            fix Pickle incompatibility of numpy arrays between Python 2 and 3\n",
    "            https://stackoverflow.com/questions/11305790/pickle-incompatibility-of-numpy-arrays-between-python-2-and-3\n",
    "            '''\n",
    "            with open(\"/data/liuyue/New/SBM/mySBM/data/{}/ind.{}.{}\".format(dataset, dataset, names[i]), 'rb') as rf:\n",
    "                u = pkl._Unpickler(rf)\n",
    "                u.encoding = 'latin1'\n",
    "                cur_data = u.load()\n",
    "                objects.append(cur_data)\n",
    "            # objects.append(\n",
    "            #     pkl.load(open(\"data/ind.{}.{}\".format(dataset, names[i]), 'rb')))\n",
    "        x, y, tx, ty, allx, ally, graph = tuple(objects)\n",
    "        test_idx_reorder = parse_index_file(\n",
    "            \"data/{}/ind.{}.test.index\".format(dataset, dataset))\n",
    "        test_idx_range = np.sort(test_idx_reorder)\n",
    "\n",
    "\n",
    "        if dataset == 'citeseer':\n",
    "            # Fix citeseer dataset (there are some isolated nodes in the graph)\n",
    "            # Find isolated nodes, add them as zero-vecs into the right position\n",
    "            test_idx_range_full = range(\n",
    "                min(test_idx_reorder), max(test_idx_reorder) + 1)\n",
    "            tx_extended = sp.lil_matrix((len(test_idx_range_full), x.shape[1]))\n",
    "            tx_extended[test_idx_range - min(test_idx_range), :] = tx\n",
    "            tx = tx_extended\n",
    "            ty_extended = np.zeros((len(test_idx_range_full), y.shape[1]))\n",
    "            ty_extended[test_idx_range - min(test_idx_range), :] = ty\n",
    "            ty = ty_extended\n",
    "\n",
    "        features = sp.vstack((allx, tx)).tolil()\n",
    "        features[test_idx_reorder, :] = features[test_idx_range, :]\n",
    "        features = torch.FloatTensor(np.array(features.todense()))\n",
    "        adj = nx.adjacency_matrix(nx.from_dict_of_lists(graph))\n",
    "        \n",
    "        labels = np.vstack((ally, ty))\n",
    "        labels[test_idx_reorder, :] = labels[test_idx_range, :]\n",
    "        \n",
    "        idx_test = test_idx_range.tolist()\n",
    "        idx_train = range(len(y))\n",
    "        idx_val = range(len(y), len(y) + 500)\n",
    "\n",
    "        train_mask = sample_mask(idx_train, labels.shape[0])\n",
    "        val_mask = sample_mask(idx_val, labels.shape[0])\n",
    "        test_mask = sample_mask(idx_test, labels.shape[0])\n",
    "\n",
    "        y_train = np.zeros(labels.shape)\n",
    "        y_val = np.zeros(labels.shape)\n",
    "        y_test = np.zeros(labels.shape)\n",
    "        y_train[train_mask, :] = labels[train_mask, :]\n",
    "        y_val[val_mask, :] = labels[val_mask, :]\n",
    "        y_test[test_mask, :] = labels[test_mask, :]\n",
    "\n",
    "        adj = adj.toarray()\n",
    "        labels = labels.argmax(1)\n",
    "        # idx = labels.argsort(0)\n",
    "        # adj = adj[idx, :][:, idx]\n",
    "        # labels = labels[idx]\n",
    "        # features = features[idx]\n",
    "\n",
    "        adj = sp.coo_matrix(adj)\n",
    "        features = sp.coo_matrix(features)\n",
    "\n",
    "        return adj, features, labels\n",
    "    elif dataset == \"wiki\":\n",
    "        f = open('/data/liuyue/New/SBM/mySBM/data/wiki/graph.txt','r')\n",
    "        adj, xind, yind = [], [], []\n",
    "        for line in f.readlines():\n",
    "            line = line.split()\n",
    "            \n",
    "            xind.append(int(line[0]))\n",
    "            yind.append(int(line[1]))\n",
    "            adj.append([int(line[0]), int(line[1])])\n",
    "        f.close()\n",
    "        ##print(len(adj))\n",
    "\n",
    "        f = open('/data/liuyue/New/SBM/mySBM/data/wiki/group.txt','r')\n",
    "        label = []\n",
    "        for line in f.readlines():\n",
    "            line = line.split()\n",
    "            label.append(int(line[1]))\n",
    "        f.close()\n",
    "\n",
    "        f = open('/data/liuyue/New/SBM/mySBM/data/wiki/tfidf.txt','r')\n",
    "        fea_idx = []\n",
    "        fea = []\n",
    "        adj = np.array(adj)\n",
    "        adj = np.vstack((adj, adj[:,[1,0]]))\n",
    "        adj = np.unique(adj, axis=0)\n",
    "        \n",
    "        labelset = np.unique(label)\n",
    "        labeldict = dict(zip(labelset, range(len(labelset))))\n",
    "        label = np.array([labeldict[x] for x in label])\n",
    "        adj = sp.coo_matrix((np.ones(len(adj)), (adj[:,0], adj[:,1])), shape=(len(label), len(label)))\n",
    "\n",
    "        for line in f.readlines():\n",
    "            line = line.split()\n",
    "            fea_idx.append([int(line[0]), int(line[1])])\n",
    "            fea.append(float(line[2]))\n",
    "        f.close()\n",
    "\n",
    "        fea_idx = np.array(fea_idx)\n",
    "        features = sp.coo_matrix((fea, (fea_idx[:,0], fea_idx[:,1])), shape=(len(label), 4973)).toarray()\n",
    "        scaler = preprocessing.MinMaxScaler()\n",
    "        #features = preprocess.normalize(features, norm='l2')\n",
    "        features = scaler.fit_transform(features)\n",
    "        # features = torch.FloatTensor(features)\n",
    "        features = sp.coo_matrix(features)\n",
    "\n",
    "        return adj, features, label\n",
    "    elif dataset in [\"ogbn-arxiv\", \"ogbn-products\"]:\n",
    "        dataset = DglNodePropPredDataset(name=\"{}\".format(dataset))\n",
    "        g, labels = dataset[0]\n",
    "        edge_indices = g.adj_sparse(fmt=\"coo\")\n",
    "        n, m = labels.shape[0], edge_indices[0].shape[0]\n",
    "        adj = sp.coo_matrix((np.ones(m), (edge_indices[0].numpy(), edge_indices[1].numpy())), shape=(n,n))\n",
    "        features = g.ndata[\"feat\"]\n",
    "        features = sp.coo_matrix(features)\n",
    "\n",
    "        if labels.ndim > 1:\n",
    "            if labels.shape[1] == 1:\n",
    "                labels = labels.view(-1)\n",
    "            else:\n",
    "                labels = labels.argmax(1)\n",
    "        labels = labels.numpy()\n",
    "        return adj, features, labels\n",
    "    elif dataset in [\"amazon-photo\", \"amazon-computers\", \"cora-full\"]:\n",
    "        map2names = {\n",
    "            \"amazon-photo\": \"/data/liuyue/New/SBM/mySBM/data/amazon_electronics_photo.npz\",\n",
    "            \"amazon-computers\": \"/data/liuyue/New/SBM/mySBM/data/amazon_electronics_computers.npz\",\n",
    "            \"cora-full\": \"/data/liuyue/New/SBM/mySBM/data/cora_full.npz\",\n",
    "        }\n",
    "\n",
    "        data = np.load(map2names[dataset])\n",
    "        # print(list(data.keys()))\n",
    "        adj_data, adj_indices, adj_indptr, adj_shape = data[\"adj_data\"], data[\"adj_indices\"], data[\"adj_indptr\"], data[\"adj_shape\"]\n",
    "        attr_data, attr_indices, attr_indptr, attr_shape = data[\"attr_data\"], data[\"attr_indices\"], data[\"attr_indptr\"], data[\"attr_shape\"]\n",
    "        labels = data[\"labels\"]\n",
    "\n",
    "        adj = sp.csr_matrix((adj_data, adj_indices, adj_indptr), shape=adj_shape).tocoo()\n",
    "        features = sp.csr_matrix((attr_data, attr_indices, attr_indptr), shape=attr_shape).tocoo()\n",
    "\n",
    "        if labels.ndim > 1:\n",
    "            if labels.shape[1] == 1:\n",
    "                labels = labels.reshape(-1)\n",
    "            else:\n",
    "                labels = labels.argmax(1)\n",
    "\n",
    "        return adj, features, labels\n",
    "    else:\n",
    "        raise NotImplementedError()\n",
    "def load_cora_full_diff_cls(nclass=10, seed=None):\n",
    "    filename = \"/data/liuyue/New/SBM/mySBM/data_diff_cls/cora-full_{}_{}.npz\".format(nclass, seed)\n",
    "    data = np.load(filename)\n",
    "\n",
    "    adj_raw, features_raw, labels_raw = load_assortative(\"cora-full\")\n",
    "\n",
    "    adj_data, adj_row, adj_col, features_load, labels_load, mask = data[\"data\"], data[\"row\"], data[\"col\"], data[\"features\"], data[\"labels\"], data[\"mask\"]\n",
    "    adj_load = sp.coo_matrix((adj_data, (adj_row, adj_col)), shape=(labels_load.shape[0], labels_load.shape[0]))\n",
    "\n",
    "    adj_mask = adj_raw.toarray()[mask,:][:,mask]\n",
    "    assert (adj_mask - adj_load).sum() < 1e-7\n",
    "    features_mask = features_raw.toarray()[mask]\n",
    "    assert (features_mask - features_load).sum() < 1e-7\n",
    "\n",
    "    return adj_load, features_load, labels_load, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bc4949",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c045b207",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"MVGRL\"\n",
    "nclasses = np.arange(5, 30, 5, dtype=int)\n",
    "seeds = np.arange(0, 3, 1, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1a540fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 0\n",
      "5 1\n",
      "5 2\n",
      "10 0\n",
      "10 1\n",
      "10 2\n",
      "15 0\n",
      "15 1\n",
      "15 2\n",
      "20 0\n",
      "20 1\n",
      "20 2\n",
      "25 0\n",
      "25 1\n",
      "25 2\n",
      "dict_values([0.684763233893273, 0.5615929873994042, 0.42745470833124966, 0.28558800050804667, 0.2622590953339026])\n"
     ]
    }
   ],
   "source": [
    "nmi_m, ami_m, ari_m = {}, {}, {}\n",
    "for nclass in nclasses:\n",
    "    nmis, amis, aris = [], [], []\n",
    "    for seed in seeds:\n",
    "        print(nclass, seed)\n",
    "        \n",
    "        adj, features, labels, mask = load_cora_full_diff_cls(nclass, seed)\n",
    "        \n",
    "        data = np.load(\"Cluster/{}/lo_cora-full_preds_{:d}_{:d}.npz\".format(model, nclass, seed))\n",
    "        preds = data[\"preds\"]\n",
    "        \n",
    "        nmi = NMI(labels, preds)\n",
    "        ami = AMI(labels, preds)\n",
    "        ari = ARI(labels, preds)\n",
    "        \n",
    "        nmis.append(nmi)\n",
    "        amis.append(ami)\n",
    "        aris.append(ari)\n",
    "    nmi_m[nclass] = np.mean(nmis)\n",
    "    ami_m[nclass] = np.mean(amis)\n",
    "    ari_m[nclass] = np.mean(aris)\n",
    "    \n",
    "print(ari_m.values())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2c5185d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 0\n",
      "5 1\n",
      "5 2\n",
      "10 0\n",
      "10 1\n",
      "10 2\n",
      "15 0\n",
      "15 1\n",
      "15 2\n",
      "20 0\n",
      "20 1\n",
      "20 2\n",
      "25 0\n",
      "25 1\n",
      "25 2\n",
      "dict_values([0.6895115180624249, 0.6498257368682231, 0.5984047566740517, 0.502911088009132, 0.5070790600237952])\n"
     ]
    }
   ],
   "source": [
    "nmi_m, ami_m, ari_m = {}, {}, {}\n",
    "for nclass in nclasses:\n",
    "    nmis, amis, aris = [], [], []\n",
    "    for seed in seeds:\n",
    "        print(nclass, seed)\n",
    "        \n",
    "        adj, features, labels, mask = load_cora_full_diff_cls(nclass, seed)\n",
    "        \n",
    "        data = np.load(\"Cluster/{}/lo_cora-full_preds_{:d}_{:d}.npz\".format(model, nclass, seed))\n",
    "        preds = data[\"preds\"]\n",
    "        \n",
    "        nmi = NMI(labels, preds)\n",
    "        ami = AMI(labels, preds)\n",
    "        ari = ARI(labels, preds)\n",
    "        \n",
    "        nmis.append(nmi)\n",
    "        amis.append(ami)\n",
    "        aris.append(ari)\n",
    "    nmi_m[nclass] = np.mean(nmis)\n",
    "    ami_m[nclass] = np.mean(amis)\n",
    "    ari_m[nclass] = np.mean(aris)\n",
    "    \n",
    "print(ami_m.values())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3814237a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31d63e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 0\n",
      "10 1\n",
      "10 2\n",
      "15 0\n",
      "15 1\n",
      "15 2\n",
      "20 0\n",
      "20 1\n",
      "20 2\n",
      "25 0\n",
      "25 1\n",
      "25 2\n",
      "dict_values([0.520174650272346, 0.3951582340722349, 0.2963118914818221, 0.24482040317321627])\n"
     ]
    }
   ],
   "source": [
    "model = \"MVGRL\"\n",
    "nclasses = np.arange(10, 30, 5, dtype=int)\n",
    "seeds = np.arange(0, 3, 1, dtype=int)\n",
    "nmi_m, ami_m, ari_m = {}, {}, {}\n",
    "for nclass in nclasses:\n",
    "    nmis, amis, aris = [], [], []\n",
    "    for seed in seeds:\n",
    "        print(nclass, seed)\n",
    "        \n",
    "        adj, features, labels, mask = load_cora_full_diff_cls(nclass, seed)\n",
    "        \n",
    "        data = np.load(\"Cluster/{}/lo_cora-full_preds_{:d}_{:d}_20m.npz\".format(model, nclass, seed))\n",
    "        preds = data[\"preds\"]\n",
    "        \n",
    "        nmi = NMI(labels, preds)\n",
    "        ami = AMI(labels, preds)\n",
    "        ari = ARI(labels, preds)\n",
    "        \n",
    "        nmis.append(nmi)\n",
    "        amis.append(ami)\n",
    "        aris.append(ari)\n",
    "    nmi_m[nclass] = np.mean(nmis)\n",
    "    ami_m[nclass] = np.mean(amis)\n",
    "    ari_m[nclass] = np.mean(aris)\n",
    "    \n",
    "print(ari_m.values())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0ca735",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e499420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0\n",
      "2 1\n",
      "2 2\n",
      "4 0\n",
      "4 1\n",
      "4 2\n",
      "6 0\n",
      "6 1\n",
      "6 2\n",
      "8 0\n",
      "8 1\n",
      "8 2\n",
      "10 0\n",
      "10 1\n",
      "10 2\n",
      "dict_values([0.7686434049993044, 0.7547663270464376, 0.6755129409229564, 0.5658450546388248, 0.5399687429222942])\n"
     ]
    }
   ],
   "source": [
    "model = \"MVGRL\"\n",
    "nclasses = np.arange(2, 12, 2, dtype=int)\n",
    "seeds = np.arange(0, 3, 1, dtype=int)\n",
    "nmi_m, ami_m, ari_m = {}, {}, {}\n",
    "for nclass in nclasses:\n",
    "    nmis, amis, aris = [], [], []\n",
    "    for seed in seeds:\n",
    "        print(nclass, seed)\n",
    "        \n",
    "        adj, features, labels, mask = load_cora_full_diff_cls(nclass, seed)\n",
    "        \n",
    "        data = np.load(\"Cluster/{}/lo_cora-full_preds_{:d}_{:d}.npz\".format(model, nclass, seed))\n",
    "        preds = data[\"preds\"]\n",
    "        \n",
    "        nmi = NMI(labels, preds)\n",
    "        ami = AMI(labels, preds)\n",
    "        ari = ARI(labels, preds)\n",
    "        \n",
    "        nmis.append(nmi)\n",
    "        amis.append(ami)\n",
    "        aris.append(ari)\n",
    "    nmi_m[nclass] = np.mean(nmis)\n",
    "    ami_m[nclass] = np.mean(amis)\n",
    "    ari_m[nclass] = np.mean(aris)\n",
    "    \n",
    "print(ari_m.values())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28b807a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0\n",
      "2 1\n",
      "2 2\n",
      "4 0\n",
      "4 1\n",
      "4 2\n",
      "6 0\n",
      "6 1\n",
      "6 2\n",
      "8 0\n",
      "8 1\n",
      "8 2\n",
      "10 0\n",
      "10 1\n",
      "10 2\n",
      "dict_values([0.6965557337232374, 0.7271197258025127, 0.7133557899835897, 0.6400073151098621, 0.6480345678867704])\n"
     ]
    }
   ],
   "source": [
    "model = \"MVGRL\"\n",
    "nclasses = np.arange(2, 12, 2, dtype=int)\n",
    "seeds = np.arange(0, 3, 1, dtype=int)\n",
    "nmi_m, ami_m, ari_m = {}, {}, {}\n",
    "for nclass in nclasses:\n",
    "    nmis, amis, aris = [], [], []\n",
    "    for seed in seeds:\n",
    "        print(nclass, seed)\n",
    "        \n",
    "        adj, features, labels, mask = load_cora_full_diff_cls(nclass, seed)\n",
    "        \n",
    "        data = np.load(\"Cluster/{}/lo_cora-full_preds_{:d}_{:d}.npz\".format(model, nclass, seed))\n",
    "        preds = data[\"preds\"]\n",
    "        \n",
    "        nmi = NMI(labels, preds)\n",
    "        ami = AMI(labels, preds)\n",
    "        ari = ARI(labels, preds)\n",
    "        \n",
    "        nmis.append(nmi)\n",
    "        amis.append(ami)\n",
    "        aris.append(ari)\n",
    "    nmi_m[nclass] = np.mean(nmis)\n",
    "    ami_m[nclass] = np.mean(amis)\n",
    "    ari_m[nclass] = np.mean(aris)\n",
    "    \n",
    "print(ami_m.values())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77271099",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc3d3d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyg] *",
   "language": "python",
   "name": "conda-env-pyg-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
