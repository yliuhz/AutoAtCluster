{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41d83611",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:The OGB package is out of date. Your version is 1.3.4, while the latest version is 1.3.5.\n",
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "from ogb.nodeproppred import DglNodePropPredDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601da6da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afc7f1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    \"cora\",\n",
    "    \"citeseer\",\n",
    "    \"wiki\",\n",
    "    \"pubmed\",\n",
    "    \"amazon-photo\",\n",
    "    \"amazon-computers\",\n",
    "    \"ogbn-arxiv\",\n",
    "    \"ogbn-products\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "878ad6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "import sklearn.preprocessing as preprocess\n",
    "import sys\n",
    "def load_data(dataset_str): # {'pubmed', 'citeseer', 'cora'}\n",
    "    \"\"\"Load data.\"\"\"\n",
    "\n",
    "    if dataset_str == 'wiki':\n",
    "        adj, features, label = load_wiki()\n",
    "        return adj, features, label, 0, 0, 0\n",
    "\n",
    "    elif dataset_str in [\"cora\", \"citeseer\", \"pubmed\"]:\n",
    "\n",
    "        names = ['x', 'y', 'tx', 'ty', 'allx', 'ally', 'graph']\n",
    "        objects = []\n",
    "        for i in range(len(names)):\n",
    "            with open(\"/data/liuyue/New/AGE/data/ind.{}.{}\".format(dataset_str, names[i]), 'rb') as f:\n",
    "                if sys.version_info > (3, 0):\n",
    "                    objects.append(pkl.load(f, encoding='latin1'))\n",
    "                else:\n",
    "                    objects.append(pkl.load(f))\n",
    "\n",
    "        x, y, tx, ty, allx, ally, graph = tuple(objects)\n",
    "        test_idx_reorder = parse_index_file(\"/data/liuyue/New/AGE/data/ind.{}.test.index\".format(dataset_str))\n",
    "        test_idx_range = np.sort(test_idx_reorder)\n",
    "\n",
    "        if dataset_str == 'citeseer':\n",
    "            # Fix citeseer dataset (there are some isolated nodes in the graph)\n",
    "            # Find isolated nodes, add them as zero-vecs into the right position\n",
    "            test_idx_range_full = range(min(test_idx_reorder), max(test_idx_reorder)+1)\n",
    "            tx_extended = sp.lil_matrix((len(test_idx_range_full), x.shape[1]))\n",
    "            tx_extended[test_idx_range-min(test_idx_range), :] = tx\n",
    "            tx = tx_extended\n",
    "            ty_extended = np.zeros((len(test_idx_range_full), y.shape[1]))\n",
    "            ty_extended[test_idx_range-min(test_idx_range), :] = ty\n",
    "            ty = ty_extended\n",
    "\n",
    "        features = sp.vstack((allx, tx)).tolil()\n",
    "        features[test_idx_reorder, :] = features[test_idx_range, :]\n",
    "        adj = nx.adjacency_matrix(nx.from_dict_of_lists(graph))\n",
    "\n",
    "        labels = np.vstack((ally, ty))\n",
    "        labels[test_idx_reorder, :] = labels[test_idx_range, :]\n",
    "\n",
    "        idx_test = test_idx_range.tolist()\n",
    "        idx_train = range(len(y))\n",
    "        idx_val = range(len(y), len(y)+500)\n",
    "\n",
    "\n",
    "        if labels.ndim > 1:\n",
    "            if labels.shape[1] == 1:\n",
    "                labels = labels.view(-1)\n",
    "            else:\n",
    "                labels = labels.argmax(1)\n",
    "\n",
    "    elif dataset_str in [\"amazon-photo\", \"amazon-computers\", \"cora-full\"]:\n",
    "        map2names = {\n",
    "            \"amazon-photo\": \"/data/liuyue/New/SBM/mySBM/data/amazon_electronics_photo.npz\",\n",
    "            \"amazon-computers\": \"/data/liuyue/New/SBM/mySBM/data/amazon_electronics_computers.npz\",\n",
    "            \"cora-full\": \"/data/liuyue/New/SBM/mySBM/data/cora_full.npz\",\n",
    "        }\n",
    "\n",
    "        data = np.load(map2names[dataset_str])\n",
    "        # print(list(data.keys()))\n",
    "        adj_data, adj_indices, adj_indptr, adj_shape = data[\"adj_data\"], data[\"adj_indices\"], data[\"adj_indptr\"], data[\"adj_shape\"]\n",
    "        attr_data, attr_indices, attr_indptr, attr_shape = data[\"attr_data\"], data[\"attr_indices\"], data[\"attr_indptr\"], data[\"attr_shape\"]\n",
    "        labels = data[\"labels\"]\n",
    "\n",
    "        adj = sp.csr_matrix((adj_data, adj_indices, adj_indptr), shape=adj_shape).tocoo()\n",
    "        features = sp.csr_matrix((attr_data, attr_indices, attr_indptr), shape=attr_shape).tocoo()\n",
    "\n",
    "        if labels.ndim > 1:\n",
    "            if labels.shape[1] == 1:\n",
    "                labels = labels.reshape(-1)\n",
    "            else:\n",
    "                labels = labels.argmax(1)\n",
    "\n",
    "        return adj, features, labels, 0, 0, 0\n",
    "    \n",
    "    elif dataset_str in [\"ogbn-arxiv\", \"ogbn-products\"]:\n",
    "        dataset = DglNodePropPredDataset(name=\"{}\".format(dataset_str))\n",
    "        g, labels = dataset[0]\n",
    "        edge_indices = g.adj_sparse(fmt=\"coo\")\n",
    "        n, m = labels.shape[0], edge_indices[0].shape[0]\n",
    "        adj = sp.coo_matrix((np.ones(m), (edge_indices[0].numpy(), edge_indices[1].numpy())), shape=(n,n))\n",
    "        features = g.ndata[\"feat\"]\n",
    "        features = sp.coo_matrix(features)\n",
    "\n",
    "        if labels.ndim > 1:\n",
    "            if labels.shape[1] == 1:\n",
    "                labels = labels.view(-1)\n",
    "            else:\n",
    "                labels = labels.argmax(1)\n",
    "        labels = labels.numpy()\n",
    "        return adj, features, labels, 0, 0, 0\n",
    "    \n",
    "    \n",
    "\n",
    "    return adj, features, labels, idx_train, idx_val, idx_test\n",
    "\n",
    "def load_wiki():\n",
    "    f = open('/data/liuyue/New/AGE/data/graph.txt','r')\n",
    "    adj, xind, yind = [], [], []\n",
    "    for line in f.readlines():\n",
    "        line = line.split()\n",
    "        \n",
    "        xind.append(int(line[0]))\n",
    "        yind.append(int(line[1]))\n",
    "        adj.append([int(line[0]), int(line[1])])\n",
    "    f.close()\n",
    "    ##print(len(adj))\n",
    "\n",
    "    f = open('/data/liuyue/New/AGE/data/group.txt','r')\n",
    "    label = []\n",
    "    for line in f.readlines():\n",
    "        line = line.split()\n",
    "        label.append(int(line[1]))\n",
    "    f.close()\n",
    "\n",
    "    f = open('/data/liuyue/New/AGE/data/tfidf.txt','r')\n",
    "    fea_idx = []\n",
    "    fea = []\n",
    "    adj = np.array(adj)\n",
    "    adj = np.vstack((adj, adj[:,[1,0]]))\n",
    "    adj = np.unique(adj, axis=0)\n",
    "    \n",
    "    labelset = np.unique(label)\n",
    "    labeldict = dict(zip(labelset, range(len(labelset))))\n",
    "    label = np.array([labeldict[x] for x in label])\n",
    "    adj = sp.csr_matrix((np.ones(len(adj)), (adj[:,0], adj[:,1])), shape=(len(label), len(label)))\n",
    "\n",
    "    for line in f.readlines():\n",
    "        line = line.split()\n",
    "        fea_idx.append([int(line[0]), int(line[1])])\n",
    "        fea.append(float(line[2]))\n",
    "    f.close()\n",
    "\n",
    "    fea_idx = np.array(fea_idx)\n",
    "    features = sp.csr_matrix((fea, (fea_idx[:,0], fea_idx[:,1])), shape=(len(label), 4973)).toarray()\n",
    "    scaler = preprocess.MinMaxScaler()\n",
    "    #features = preprocess.normalize(features, norm='l2')\n",
    "    features = scaler.fit_transform(features)\n",
    "    features = torch.FloatTensor(features)\n",
    "\n",
    "    return adj, features, label\n",
    "def parse_index_file(filename):\n",
    "    index = []\n",
    "    for line in open(filename):\n",
    "        index.append(int(line.strip()))\n",
    "    return index\n",
    "def sample_mask(idx, l):\n",
    "    \"\"\"Create mask.\"\"\"\n",
    "    mask = np.zeros(l)\n",
    "    mask[idx] = 1\n",
    "    return np.array(mask, dtype=np.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "954e4c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cora: (2708,), 10556\n",
      "citeseer: (3327,), 9228\n",
      "wiki: (2405,), 24357.0\n",
      "pubmed: (19717,), 88651\n",
      "amazon-photo: (7650,), 143663.0\n",
      "amazon-computers: (13752,), 287209.0\n",
      "ogbn-arxiv: (169343,), 1166243.0\n",
      "ogbn-products: (2449029,), 123718280.0\n"
     ]
    }
   ],
   "source": [
    "true_labels = {}\n",
    "num_edges = {}\n",
    "raw_adjs = {}\n",
    "for dataset in datasets:\n",
    "    adj, _, label, _, _, _ = load_data(dataset)\n",
    "    true_labels[dataset] = label\n",
    "    num_edges[dataset] = adj.sum()\n",
    "    raw_adjs[dataset] = adj\n",
    "    print(\"{}: {}, {}\".format(dataset, label.shape, num_edges[dataset]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6463423d",
   "metadata": {},
   "source": [
    "# Baselines on G and F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "8bd5e072",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    \"KMeans\",\n",
    "    \"SC-G\",\n",
    "    \"SC-F\",\n",
    "    # --- # \n",
    "    \"AP\",\n",
    "    \"HCA\",\n",
    "    \"HDBSCAN\",\n",
    "    \"Mean-shift\",\n",
    "    # --- #\n",
    "    \"Louvain\",\n",
    "    \"Leiden\",\n",
    "#     \"ILouvain\",    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d167b9cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>models</th>\n",
       "      <th>cora</th>\n",
       "      <th>citeseer</th>\n",
       "      <th>wiki</th>\n",
       "      <th>pubmed</th>\n",
       "      <th>amazon-photo</th>\n",
       "      <th>amazon-computers</th>\n",
       "      <th>ogbn-arxiv</th>\n",
       "      <th>ogbn-products</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KMeans</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SC-G</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SC-F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HCA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HDBSCAN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mean-shift</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Louvain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Leiden</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       models cora citeseer wiki pubmed amazon-photo amazon-computers  \\\n",
       "0      KMeans  NaN      NaN  NaN    NaN          NaN              NaN   \n",
       "1        SC-G  NaN      NaN  NaN    NaN          NaN              NaN   \n",
       "2        SC-F  NaN      NaN  NaN    NaN          NaN              NaN   \n",
       "3          AP  NaN      NaN  NaN    NaN          NaN              NaN   \n",
       "4         HCA  NaN      NaN  NaN    NaN          NaN              NaN   \n",
       "5     HDBSCAN  NaN      NaN  NaN    NaN          NaN              NaN   \n",
       "6  Mean-shift  NaN      NaN  NaN    NaN          NaN              NaN   \n",
       "7     Louvain  NaN      NaN  NaN    NaN          NaN              NaN   \n",
       "8      Leiden  NaN      NaN  NaN    NaN          NaN              NaN   \n",
       "\n",
       "  ogbn-arxiv ogbn-products  \n",
       "0        NaN           NaN  \n",
       "1        NaN           NaN  \n",
       "2        NaN           NaN  \n",
       "3        NaN           NaN  \n",
       "4        NaN           NaN  \n",
       "5        NaN           NaN  \n",
       "6        NaN           NaN  \n",
       "7        NaN           NaN  \n",
       "8        NaN           NaN  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data={\"models\":models}, columns=[\"models\"]+datasets)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "88bec4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nmi = df.copy()\n",
    "df_ami = df.copy()\n",
    "df_ari = df.copy()\n",
    "df_nclass = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24303256",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c6d42c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:32<00:00,  3.63s/it]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import normalized_mutual_info_score as NMI, adjusted_mutual_info_score as AMI, adjusted_rand_score as ARI\n",
    "from tqdm import tqdm\n",
    "\n",
    "seeds = np.arange(10, dtype=int)\n",
    "for model in tqdm(models, total=len(models)):\n",
    "    for dataset in datasets:\n",
    "        nmis, amis, aris, nclasses = [], [], [], []\n",
    "        for seed in seeds:\n",
    "            emb_name = os.path.join(\"{}/outputs\".format(model), \"{}_{}.npz\".format(dataset, seed))\n",
    "            \n",
    "            if model == \"HDBSCAN\":\n",
    "                emb_name = os.path.join(\"{}/outputs\".format(model), \"GRACE_{}_{}.npz\".format(dataset, seed))\n",
    "            \n",
    "            try:\n",
    "                data = np.load(emb_name)\n",
    "\n",
    "                preds = data[\"preds\"]\n",
    "                labels = true_labels[dataset]\n",
    "\n",
    "                nmi = NMI(labels, preds)\n",
    "                ami = AMI(labels, preds)\n",
    "                ari = ARI(labels, preds)\n",
    "\n",
    "                nmis.append(nmi)\n",
    "                amis.append(ami)\n",
    "                aris.append(ari)\n",
    "                nclasses.append(np.unique(preds).shape[0])\n",
    "            except Exception as e:\n",
    "                pass\n",
    "        if len(nmis) > 0:\n",
    "            nmi_m = np.mean(nmis)\n",
    "            ami_m = np.mean(amis)\n",
    "            ari_m = np.mean(aris)\n",
    "            nclass_m = np.mean(nclasses)\n",
    "\n",
    "            df_nmi[dataset][models.index(model)] = nmi_m\n",
    "            df_ami[dataset][models.index(model)] = ami_m\n",
    "            df_ari[dataset][models.index(model)] = ari_m           \n",
    "            df_nclass[dataset][models.index(model)] = nclass_m           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "c7c0eff4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>models</th>\n",
       "      <th>cora</th>\n",
       "      <th>citeseer</th>\n",
       "      <th>wiki</th>\n",
       "      <th>pubmed</th>\n",
       "      <th>amazon-photo</th>\n",
       "      <th>amazon-computers</th>\n",
       "      <th>ogbn-arxiv</th>\n",
       "      <th>ogbn-products</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KMeans</td>\n",
       "      <td>0.151309</td>\n",
       "      <td>0.203321</td>\n",
       "      <td>0.30189</td>\n",
       "      <td>0.31289</td>\n",
       "      <td>0.135396</td>\n",
       "      <td>0.125363</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SC-G</td>\n",
       "      <td>0.030296</td>\n",
       "      <td>0.014547</td>\n",
       "      <td>0.329268</td>\n",
       "      <td>0.182967</td>\n",
       "      <td>0.113414</td>\n",
       "      <td>0.004043</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SC-F</td>\n",
       "      <td>0.15254</td>\n",
       "      <td>0.203047</td>\n",
       "      <td>0.481433</td>\n",
       "      <td>0.311106</td>\n",
       "      <td>0.379951</td>\n",
       "      <td>0.304717</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AP</td>\n",
       "      <td>0.167834</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.130919</td>\n",
       "      <td>0.270812</td>\n",
       "      <td>0.215447</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HCA</td>\n",
       "      <td>0.071929</td>\n",
       "      <td>0.088722</td>\n",
       "      <td>0.116015</td>\n",
       "      <td>0.021587</td>\n",
       "      <td>0.048579</td>\n",
       "      <td>0.01818</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HDBSCAN</td>\n",
       "      <td>0.022805</td>\n",
       "      <td>0.003887</td>\n",
       "      <td>0.033626</td>\n",
       "      <td>0.053884</td>\n",
       "      <td>0.045347</td>\n",
       "      <td>0.054236</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mean-shift</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.237858</td>\n",
       "      <td>0.046976</td>\n",
       "      <td>0.161419</td>\n",
       "      <td>0.138108</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Louvain</td>\n",
       "      <td>0.453118</td>\n",
       "      <td>0.328346</td>\n",
       "      <td>0.383993</td>\n",
       "      <td>0.199124</td>\n",
       "      <td>0.653116</td>\n",
       "      <td>0.525299</td>\n",
       "      <td>0.395117</td>\n",
       "      <td>0.512033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Leiden</td>\n",
       "      <td>0.461396</td>\n",
       "      <td>0.32892</td>\n",
       "      <td>0.387589</td>\n",
       "      <td>0.205247</td>\n",
       "      <td>0.657552</td>\n",
       "      <td>0.53523</td>\n",
       "      <td>0.413164</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       models      cora  citeseer      wiki    pubmed amazon-photo  \\\n",
       "0      KMeans  0.151309  0.203321   0.30189   0.31289     0.135396   \n",
       "1        SC-G  0.030296  0.014547  0.329268  0.182967     0.113414   \n",
       "2        SC-F   0.15254  0.203047  0.481433  0.311106     0.379951   \n",
       "3          AP  0.167834       0.0      -0.0  0.130919     0.270812   \n",
       "4         HCA  0.071929  0.088722  0.116015  0.021587     0.048579   \n",
       "5     HDBSCAN  0.022805  0.003887  0.033626  0.053884     0.045347   \n",
       "6  Mean-shift      -0.0       0.0  0.237858  0.046976     0.161419   \n",
       "7     Louvain  0.453118  0.328346  0.383993  0.199124     0.653116   \n",
       "8      Leiden  0.461396   0.32892  0.387589  0.205247     0.657552   \n",
       "\n",
       "  amazon-computers ogbn-arxiv ogbn-products  \n",
       "0         0.125363        NaN           NaN  \n",
       "1         0.004043        NaN           NaN  \n",
       "2         0.304717        NaN           NaN  \n",
       "3         0.215447        NaN           NaN  \n",
       "4          0.01818        NaN           NaN  \n",
       "5         0.054236        NaN           NaN  \n",
       "6         0.138108        NaN           NaN  \n",
       "7         0.525299   0.395117      0.512033  \n",
       "8          0.53523   0.413164           NaN  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "cf221678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>models</th>\n",
       "      <th>cora</th>\n",
       "      <th>citeseer</th>\n",
       "      <th>wiki</th>\n",
       "      <th>pubmed</th>\n",
       "      <th>amazon-photo</th>\n",
       "      <th>amazon-computers</th>\n",
       "      <th>ogbn-arxiv</th>\n",
       "      <th>ogbn-products</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KMeans</td>\n",
       "      <td>0.088724</td>\n",
       "      <td>0.157663</td>\n",
       "      <td>0.065474</td>\n",
       "      <td>0.281103</td>\n",
       "      <td>0.05621</td>\n",
       "      <td>0.06718</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SC-G</td>\n",
       "      <td>-0.005074</td>\n",
       "      <td>0.004582</td>\n",
       "      <td>0.074955</td>\n",
       "      <td>0.132341</td>\n",
       "      <td>0.034353</td>\n",
       "      <td>-0.000883</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SC-F</td>\n",
       "      <td>0.07154</td>\n",
       "      <td>0.184096</td>\n",
       "      <td>0.27226</td>\n",
       "      <td>0.278447</td>\n",
       "      <td>0.242542</td>\n",
       "      <td>0.09878</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AP</td>\n",
       "      <td>0.064888</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002963</td>\n",
       "      <td>0.038962</td>\n",
       "      <td>0.037655</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HCA</td>\n",
       "      <td>-0.022496</td>\n",
       "      <td>0.069867</td>\n",
       "      <td>0.051882</td>\n",
       "      <td>0.001049</td>\n",
       "      <td>0.045892</td>\n",
       "      <td>0.014193</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HDBSCAN</td>\n",
       "      <td>0.01147</td>\n",
       "      <td>0.001512</td>\n",
       "      <td>0.00095</td>\n",
       "      <td>0.064208</td>\n",
       "      <td>0.031569</td>\n",
       "      <td>0.067018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mean-shift</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.004621</td>\n",
       "      <td>0.056289</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Louvain</td>\n",
       "      <td>0.236914</td>\n",
       "      <td>0.094663</td>\n",
       "      <td>0.20417</td>\n",
       "      <td>0.102391</td>\n",
       "      <td>0.556958</td>\n",
       "      <td>0.289072</td>\n",
       "      <td>0.255769</td>\n",
       "      <td>0.293714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Leiden</td>\n",
       "      <td>0.251237</td>\n",
       "      <td>0.089436</td>\n",
       "      <td>0.205325</td>\n",
       "      <td>0.097587</td>\n",
       "      <td>0.563174</td>\n",
       "      <td>0.296467</td>\n",
       "      <td>0.260133</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       models      cora  citeseer      wiki    pubmed amazon-photo  \\\n",
       "0      KMeans  0.088724  0.157663  0.065474  0.281103      0.05621   \n",
       "1        SC-G -0.005074  0.004582  0.074955  0.132341     0.034353   \n",
       "2        SC-F   0.07154  0.184096   0.27226  0.278447     0.242542   \n",
       "3          AP  0.064888       0.0       0.0  0.002963     0.038962   \n",
       "4         HCA -0.022496  0.069867  0.051882  0.001049     0.045892   \n",
       "5     HDBSCAN   0.01147  0.001512   0.00095  0.064208     0.031569   \n",
       "6  Mean-shift       0.0       0.0  0.000471  0.004167     0.004621   \n",
       "7     Louvain  0.236914  0.094663   0.20417  0.102391     0.556958   \n",
       "8      Leiden  0.251237  0.089436  0.205325  0.097587     0.563174   \n",
       "\n",
       "  amazon-computers ogbn-arxiv ogbn-products  \n",
       "0          0.06718        NaN           NaN  \n",
       "1        -0.000883        NaN           NaN  \n",
       "2          0.09878        NaN           NaN  \n",
       "3         0.037655        NaN           NaN  \n",
       "4         0.014193        NaN           NaN  \n",
       "5         0.067018        NaN           NaN  \n",
       "6         0.056289        NaN           NaN  \n",
       "7         0.289072   0.255769      0.293714  \n",
       "8         0.296467   0.260133           NaN  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "095f1419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>models</th>\n",
       "      <th>cora</th>\n",
       "      <th>citeseer</th>\n",
       "      <th>wiki</th>\n",
       "      <th>pubmed</th>\n",
       "      <th>amazon-photo</th>\n",
       "      <th>amazon-computers</th>\n",
       "      <th>ogbn-arxiv</th>\n",
       "      <th>ogbn-products</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KMeans</td>\n",
       "      <td>0.148137</td>\n",
       "      <td>0.201569</td>\n",
       "      <td>0.286782</td>\n",
       "      <td>0.312817</td>\n",
       "      <td>0.133941</td>\n",
       "      <td>0.124074</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SC-G</td>\n",
       "      <td>0.023376</td>\n",
       "      <td>0.011086</td>\n",
       "      <td>0.309929</td>\n",
       "      <td>0.182861</td>\n",
       "      <td>0.110797</td>\n",
       "      <td>0.001595</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SC-F</td>\n",
       "      <td>0.149277</td>\n",
       "      <td>0.201347</td>\n",
       "      <td>0.468978</td>\n",
       "      <td>0.311036</td>\n",
       "      <td>0.378921</td>\n",
       "      <td>0.303673</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AP</td>\n",
       "      <td>0.15201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.116579</td>\n",
       "      <td>0.249347</td>\n",
       "      <td>0.191938</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HCA</td>\n",
       "      <td>0.070986</td>\n",
       "      <td>0.088149</td>\n",
       "      <td>0.114134</td>\n",
       "      <td>0.021508</td>\n",
       "      <td>0.048242</td>\n",
       "      <td>0.017929</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HDBSCAN</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.000353</td>\n",
       "      <td>0.018244</td>\n",
       "      <td>0.053767</td>\n",
       "      <td>0.032228</td>\n",
       "      <td>0.016264</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mean-shift</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006883</td>\n",
       "      <td>0.018927</td>\n",
       "      <td>0.133633</td>\n",
       "      <td>0.105905</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Louvain</td>\n",
       "      <td>0.429578</td>\n",
       "      <td>0.248895</td>\n",
       "      <td>0.357009</td>\n",
       "      <td>0.198327</td>\n",
       "      <td>0.64627</td>\n",
       "      <td>0.514626</td>\n",
       "      <td>0.392699</td>\n",
       "      <td>0.502337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Leiden</td>\n",
       "      <td>0.437528</td>\n",
       "      <td>0.249633</td>\n",
       "      <td>0.360288</td>\n",
       "      <td>0.20442</td>\n",
       "      <td>0.650806</td>\n",
       "      <td>0.52483</td>\n",
       "      <td>0.410841</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       models      cora  citeseer      wiki    pubmed amazon-photo  \\\n",
       "0      KMeans  0.148137  0.201569  0.286782  0.312817     0.133941   \n",
       "1        SC-G  0.023376  0.011086  0.309929  0.182861     0.110797   \n",
       "2        SC-F  0.149277  0.201347  0.468978  0.311036     0.378921   \n",
       "3          AP   0.15201       0.0      -0.0  0.116579     0.249347   \n",
       "4         HCA  0.070986  0.088149  0.114134  0.021508     0.048242   \n",
       "5     HDBSCAN    0.0034  0.000353  0.018244  0.053767     0.032228   \n",
       "6  Mean-shift      -0.0       0.0  0.006883  0.018927     0.133633   \n",
       "7     Louvain  0.429578  0.248895  0.357009  0.198327      0.64627   \n",
       "8      Leiden  0.437528  0.249633  0.360288   0.20442     0.650806   \n",
       "\n",
       "  amazon-computers ogbn-arxiv ogbn-products  \n",
       "0         0.124074        NaN           NaN  \n",
       "1         0.001595        NaN           NaN  \n",
       "2         0.303673        NaN           NaN  \n",
       "3         0.191938        NaN           NaN  \n",
       "4         0.017929        NaN           NaN  \n",
       "5         0.016264        NaN           NaN  \n",
       "6         0.105905        NaN           NaN  \n",
       "7         0.514626   0.392699      0.502337  \n",
       "8          0.52483   0.410841           NaN  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "1530c3c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>models</th>\n",
       "      <th>cora</th>\n",
       "      <th>citeseer</th>\n",
       "      <th>wiki</th>\n",
       "      <th>pubmed</th>\n",
       "      <th>amazon-photo</th>\n",
       "      <th>amazon-computers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KMeans</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SC-G</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SC-F</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AP</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1103.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>260.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HCA</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HDBSCAN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mean-shift</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>470.0</td>\n",
       "      <td>366.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>236.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Louvain</td>\n",
       "      <td>103.6</td>\n",
       "      <td>469.9</td>\n",
       "      <td>64.4</td>\n",
       "      <td>40.4</td>\n",
       "      <td>150.2</td>\n",
       "      <td>330.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Leiden</td>\n",
       "      <td>106.3</td>\n",
       "      <td>470.9</td>\n",
       "      <td>65.2</td>\n",
       "      <td>42.2</td>\n",
       "      <td>150.4</td>\n",
       "      <td>330.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       models   cora citeseer   wiki  pubmed amazon-photo amazon-computers\n",
       "0      KMeans    7.0      6.0   19.0     3.0          8.0             10.0\n",
       "1        SC-G    7.0      6.0   19.0     3.0          8.0             10.0\n",
       "2        SC-F    7.0      6.0   19.0     3.0          8.0             10.0\n",
       "3          AP   42.0      1.0    1.0  1103.0        173.0            260.0\n",
       "4         HCA    2.0      2.0    2.0     2.0          2.0              2.0\n",
       "5     HDBSCAN    NaN      NaN    NaN     NaN          NaN              NaN\n",
       "6  Mean-shift    1.0      1.0  470.0   366.0        120.0            236.0\n",
       "7     Louvain  103.6    469.9   64.4    40.4        150.2            330.3\n",
       "8      Leiden  106.3    470.9   65.2    42.2        150.4            330.4"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "481a33a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Louvain cora 0\n",
      "Louvain cora 1\n",
      "Louvain cora 2\n",
      "Louvain cora 3\n",
      "Louvain cora 4\n",
      "Louvain cora 5\n",
      "Louvain cora 6\n",
      "Louvain cora 7\n",
      "Louvain cora 8\n",
      "Louvain cora 9\n",
      "Louvain citeseer 0\n",
      "Louvain citeseer 1\n",
      "Louvain citeseer 2\n",
      "Louvain citeseer 3\n",
      "Louvain citeseer 4\n",
      "Louvain citeseer 5\n",
      "Louvain citeseer 6\n",
      "Louvain citeseer 7\n",
      "Louvain citeseer 8\n",
      "Louvain citeseer 9\n",
      "Louvain wiki 0\n",
      "Louvain wiki 1\n",
      "Louvain wiki 2\n",
      "Louvain wiki 3\n",
      "Louvain wiki 4\n",
      "Louvain wiki 5\n",
      "Louvain wiki 6\n",
      "Louvain wiki 7\n",
      "Louvain wiki 8\n",
      "Louvain wiki 9\n",
      "Louvain pubmed 0\n",
      "Louvain pubmed 1\n",
      "Louvain pubmed 2\n",
      "Louvain pubmed 3\n",
      "Louvain pubmed 4\n",
      "Louvain pubmed 5\n",
      "Louvain pubmed 6\n",
      "Louvain pubmed 7\n",
      "Louvain pubmed 8\n",
      "Louvain pubmed 9\n",
      "Louvain amazon-photo 0\n",
      "Louvain amazon-photo 1\n",
      "Louvain amazon-photo 2\n",
      "Louvain amazon-photo 3\n",
      "Louvain amazon-photo 4\n",
      "Louvain amazon-photo 5\n",
      "Louvain amazon-photo 6\n",
      "Louvain amazon-photo 7\n",
      "Louvain amazon-photo 8\n",
      "Louvain amazon-photo 9\n",
      "Louvain amazon-computers 0\n",
      "Louvain amazon-computers 1\n",
      "Louvain amazon-computers 2\n",
      "Louvain amazon-computers 3\n",
      "Louvain amazon-computers 4\n",
      "Louvain amazon-computers 5\n",
      "Louvain amazon-computers 6\n",
      "Louvain amazon-computers 7\n",
      "Louvain amazon-computers 8\n",
      "Louvain amazon-computers 9\n",
      "Louvain ogbn-arxiv 0\n",
      "Louvain ogbn-arxiv 1\n",
      "Louvain ogbn-arxiv 2\n",
      "Louvain ogbn-arxiv 3\n",
      "Louvain ogbn-arxiv 4\n",
      "Louvain ogbn-arxiv 5\n",
      "Louvain ogbn-arxiv 6\n",
      "Louvain ogbn-arxiv 7\n",
      "Louvain ogbn-arxiv 8\n",
      "Louvain ogbn-arxiv 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 1/2 [03:06<03:06, 186.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leiden cora 0\n",
      "Leiden cora 1\n",
      "Leiden cora 2\n",
      "Leiden cora 3\n",
      "Leiden cora 4\n",
      "Leiden cora 5\n",
      "Leiden cora 6\n",
      "Leiden cora 7\n",
      "Leiden cora 8\n",
      "Leiden cora 9\n",
      "Leiden citeseer 0\n",
      "Leiden citeseer 1\n",
      "Leiden citeseer 2\n",
      "Leiden citeseer 3\n",
      "Leiden citeseer 4\n",
      "Leiden citeseer 5\n",
      "Leiden citeseer 6\n",
      "Leiden citeseer 7\n",
      "Leiden citeseer 8\n",
      "Leiden citeseer 9\n",
      "Leiden wiki 0\n",
      "Leiden wiki 1\n",
      "Leiden wiki 2\n",
      "Leiden wiki 3\n",
      "Leiden wiki 4\n",
      "Leiden wiki 5\n",
      "Leiden wiki 6\n",
      "Leiden wiki 7\n",
      "Leiden wiki 8\n",
      "Leiden wiki 9\n",
      "Leiden pubmed 0\n",
      "Leiden pubmed 1\n",
      "Leiden pubmed 2\n",
      "Leiden pubmed 3\n",
      "Leiden pubmed 4\n",
      "Leiden pubmed 5\n",
      "Leiden pubmed 6\n",
      "Leiden pubmed 7\n",
      "Leiden pubmed 8\n",
      "Leiden pubmed 9\n",
      "Leiden amazon-photo 0\n",
      "Leiden amazon-photo 1\n",
      "Leiden amazon-photo 2\n",
      "Leiden amazon-photo 3\n",
      "Leiden amazon-photo 4\n",
      "Leiden amazon-photo 5\n",
      "Leiden amazon-photo 6\n",
      "Leiden amazon-photo 7\n",
      "Leiden amazon-photo 8\n",
      "Leiden amazon-photo 9\n",
      "Leiden amazon-computers 0\n",
      "Leiden amazon-computers 1\n",
      "Leiden amazon-computers 2\n",
      "Leiden amazon-computers 3\n",
      "Leiden amazon-computers 4\n",
      "Leiden amazon-computers 5\n",
      "Leiden amazon-computers 6\n",
      "Leiden amazon-computers 7\n",
      "Leiden amazon-computers 8\n",
      "Leiden amazon-computers 9\n",
      "Leiden ogbn-arxiv 0\n",
      "Leiden ogbn-arxiv 1\n",
      "Leiden ogbn-arxiv 2\n",
      "Leiden ogbn-arxiv 3\n",
      "Leiden ogbn-arxiv 4\n",
      "Leiden ogbn-arxiv 5\n",
      "Leiden ogbn-arxiv 6\n",
      "Leiden ogbn-arxiv 7\n",
      "Leiden ogbn-arxiv 8\n",
      "Leiden ogbn-arxiv 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [06:09<00:00, 184.54s/it]\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import networkx.algorithms.community as nx_comm\n",
    "mod_models = [\"Louvain\", \"Leiden\"]\n",
    "df_mods = pd.DataFrame(data={\"models\":mod_models}, columns=[\"models\"]+datasets)\n",
    "seeds = np.arange(10, dtype=int)\n",
    "for model in tqdm(mod_models, total=len(mod_models)):\n",
    "    for dataset in datasets:\n",
    "        mods = []\n",
    "        for seed in seeds:\n",
    "            emb_name = os.path.join(\"{}/outputs\".format(model), \"{}_{}.npz\".format(dataset, seed))\n",
    "            print(model, dataset, seed)\n",
    "            \n",
    "            try:\n",
    "                data = np.load(emb_name)\n",
    "\n",
    "                preds = data[\"preds\"]\n",
    "                labels = true_labels[dataset]\n",
    "                n = labels.shape[0]\n",
    "                \n",
    "                adj = raw_adjs[dataset]\n",
    "                graph = nx.from_scipy_sparse_matrix(adj)\n",
    "                \n",
    "                pp = []\n",
    "                nn = np.arange(n, dtype=int)\n",
    "                for i in np.unique(preds):\n",
    "                    pp.append(nn[preds==i])\n",
    "                \n",
    "                mod = nx_comm.modularity(graph, pp)\n",
    "                \n",
    "                mods.append(mod)\n",
    "            except Exception as e:\n",
    "                pass\n",
    "        if len(mods) > 0:\n",
    "            mod_m = np.mean(mods)\n",
    "\n",
    "            df_mods[dataset][mod_models.index(model)] = mod_m          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a102fa44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>models</th>\n",
       "      <th>cora</th>\n",
       "      <th>citeseer</th>\n",
       "      <th>wiki</th>\n",
       "      <th>pubmed</th>\n",
       "      <th>amazon-photo</th>\n",
       "      <th>amazon-computers</th>\n",
       "      <th>ogbn-arxiv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Louvain</td>\n",
       "      <td>0.813513</td>\n",
       "      <td>0.891644</td>\n",
       "      <td>0.710988</td>\n",
       "      <td>0.767732</td>\n",
       "      <td>0.733934</td>\n",
       "      <td>0.637784</td>\n",
       "      <td>0.703991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Leiden</td>\n",
       "      <td>0.821935</td>\n",
       "      <td>0.894705</td>\n",
       "      <td>0.718905</td>\n",
       "      <td>0.781971</td>\n",
       "      <td>0.739438</td>\n",
       "      <td>0.640652</td>\n",
       "      <td>0.713558</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    models      cora  citeseer      wiki    pubmed amazon-photo  \\\n",
       "0  Louvain  0.813513  0.891644  0.710988  0.767732     0.733934   \n",
       "1   Leiden  0.821935  0.894705  0.718905  0.781971     0.739438   \n",
       "\n",
       "  amazon-computers ogbn-arxiv  \n",
       "0         0.637784   0.703991  \n",
       "1         0.640652   0.713558  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a309b9d",
   "metadata": {},
   "source": [
    "# Baselines on Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "ab5a0dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    \"KMeans\",\n",
    "#     \"SC-G\",\n",
    "    \"SC-F\",\n",
    "    # --- # \n",
    "    \"AP\",\n",
    "    \"HCA\",\n",
    "    \"DBSCAN\",\n",
    "    \"Mean-shift\",\n",
    "    # --- #\n",
    "#     \"Louvain\",\n",
    "#     \"Leiden\",\n",
    "#     \"ILouvain\",   \n",
    "#     \"OPTICS\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "bfc81916",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_models = [\n",
    "#     \"GAE\",\n",
    "#     \"VGAE\",\n",
    "#     \"ARGA\",\n",
    "#     \"ARVGA\",\n",
    "#     \"AGE\",\n",
    "#     \"DGI\",\n",
    "#     \"MVGRL\",\n",
    "    \"GRACE\",\n",
    "#     \"GGD\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "ce3981e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>models</th>\n",
       "      <th>cora</th>\n",
       "      <th>citeseer</th>\n",
       "      <th>wiki</th>\n",
       "      <th>pubmed</th>\n",
       "      <th>amazon-photo</th>\n",
       "      <th>amazon-computers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KMeans</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SC-F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HCA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DBSCAN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mean-shift</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       models cora citeseer wiki pubmed amazon-photo amazon-computers\n",
       "0      KMeans  NaN      NaN  NaN    NaN          NaN              NaN\n",
       "1        SC-F  NaN      NaN  NaN    NaN          NaN              NaN\n",
       "2          AP  NaN      NaN  NaN    NaN          NaN              NaN\n",
       "3         HCA  NaN      NaN  NaN    NaN          NaN              NaN\n",
       "4      DBSCAN  NaN      NaN  NaN    NaN          NaN              NaN\n",
       "5  Mean-shift  NaN      NaN  NaN    NaN          NaN              NaN"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data={\"models\":models}, columns=[\"models\"]+datasets)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "7a984f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nmi = df.copy()\n",
    "df_ami = df.copy()\n",
    "df_ari = df.copy()\n",
    "df_nclass = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "7313dd3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMeans GRACE cora 0\n",
      "KMeans GRACE cora 1\n",
      "KMeans GRACE cora 2\n",
      "KMeans GRACE cora 3\n",
      "KMeans GRACE cora 4\n",
      "KMeans GRACE cora 5\n",
      "KMeans GRACE cora 6\n",
      "KMeans GRACE cora 7\n",
      "KMeans GRACE cora 8\n",
      "KMeans GRACE cora 9\n",
      "KMeans GRACE citeseer 0\n",
      "KMeans GRACE citeseer 1\n",
      "KMeans GRACE citeseer 2\n",
      "KMeans GRACE citeseer 3\n",
      "KMeans GRACE citeseer 4\n",
      "KMeans GRACE citeseer 5\n",
      "KMeans GRACE citeseer 6\n",
      "KMeans GRACE citeseer 7\n",
      "KMeans GRACE citeseer 8\n",
      "KMeans GRACE citeseer 9\n",
      "KMeans GRACE wiki 0\n",
      "KMeans GRACE wiki 1\n",
      "KMeans GRACE wiki 2\n",
      "KMeans GRACE wiki 3\n",
      "KMeans GRACE wiki 4\n",
      "KMeans GRACE wiki 5\n",
      "KMeans GRACE wiki 6\n",
      "KMeans GRACE wiki 7\n",
      "KMeans GRACE wiki 8\n",
      "KMeans GRACE wiki 9\n",
      "KMeans GRACE pubmed 0\n",
      "KMeans GRACE pubmed 1\n",
      "KMeans GRACE pubmed 2\n",
      "KMeans GRACE pubmed 3\n",
      "KMeans GRACE pubmed 4\n",
      "KMeans GRACE pubmed 5\n",
      "KMeans GRACE pubmed 6\n",
      "KMeans GRACE pubmed 7\n",
      "KMeans GRACE pubmed 8\n",
      "KMeans GRACE pubmed 9\n",
      "KMeans GRACE amazon-photo 0\n",
      "KMeans GRACE amazon-photo 1\n",
      "KMeans GRACE amazon-photo 2\n",
      "KMeans GRACE amazon-photo 3\n",
      "KMeans GRACE amazon-photo 4\n",
      "KMeans GRACE amazon-photo 5\n",
      "KMeans GRACE amazon-photo 6\n",
      "KMeans GRACE amazon-photo 7\n",
      "KMeans GRACE amazon-photo 8\n",
      "KMeans GRACE amazon-photo 9\n",
      "KMeans GRACE amazon-computers 0\n",
      "KMeans GRACE amazon-computers 1\n",
      "KMeans GRACE amazon-computers 2\n",
      "KMeans GRACE amazon-computers 3\n",
      "KMeans GRACE amazon-computers 4\n",
      "KMeans GRACE amazon-computers 5\n",
      "KMeans GRACE amazon-computers 6\n",
      "KMeans GRACE amazon-computers 7\n",
      "KMeans GRACE amazon-computers 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 1/6 [00:00<00:03,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMeans GRACE amazon-computers 9\n",
      "SC-F GRACE cora 0\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_emb/GRACE_cora_0.npz'\n",
      "SC-F GRACE cora 1\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_emb/GRACE_cora_1.npz'\n",
      "SC-F GRACE cora 2\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_emb/GRACE_cora_2.npz'\n",
      "SC-F GRACE cora 3\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_emb/GRACE_cora_3.npz'\n",
      "SC-F GRACE cora 4\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_emb/GRACE_cora_4.npz'\n",
      "SC-F GRACE cora 5\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_emb/GRACE_cora_5.npz'\n",
      "SC-F GRACE cora 6\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_emb/GRACE_cora_6.npz'\n",
      "SC-F GRACE cora 7\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_emb/GRACE_cora_7.npz'\n",
      "SC-F GRACE cora 8\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_emb/GRACE_cora_8.npz'\n",
      "SC-F GRACE cora 9\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_emb/GRACE_cora_9.npz'\n",
      "SC-F GRACE citeseer 0\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_emb/GRACE_citeseer_0.npz'\n",
      "SC-F GRACE citeseer 1\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_emb/GRACE_citeseer_1.npz'\n",
      "SC-F GRACE citeseer 2\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_emb/GRACE_citeseer_2.npz'\n",
      "SC-F GRACE citeseer 3\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_emb/GRACE_citeseer_3.npz'\n",
      "SC-F GRACE citeseer 4\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_emb/GRACE_citeseer_4.npz'\n",
      "SC-F GRACE citeseer 5\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_emb/GRACE_citeseer_5.npz'\n",
      "SC-F GRACE citeseer 6\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_emb/GRACE_citeseer_6.npz'\n",
      "SC-F GRACE citeseer 7\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_emb/GRACE_citeseer_7.npz'\n",
      "SC-F GRACE citeseer 8\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_emb/GRACE_citeseer_8.npz'\n",
      "SC-F GRACE citeseer 9\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_emb/GRACE_citeseer_9.npz'\n",
      "SC-F GRACE wiki 0\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_emb/GRACE_wiki_0.npz'\n",
      "SC-F GRACE wiki 1\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_emb/GRACE_wiki_1.npz'\n",
      "SC-F GRACE wiki 2\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_emb/GRACE_wiki_2.npz'\n",
      "SC-F GRACE wiki 3\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_emb/GRACE_wiki_3.npz'\n",
      "SC-F GRACE wiki 4\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_emb/GRACE_wiki_4.npz'\n",
      "SC-F GRACE wiki 5\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_emb/GRACE_wiki_5.npz'\n",
      "SC-F GRACE wiki 6\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_emb/GRACE_wiki_6.npz'\n",
      "SC-F GRACE wiki 7\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_emb/GRACE_wiki_7.npz'\n",
      "SC-F GRACE wiki 8\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_emb/GRACE_wiki_8.npz'\n",
      "SC-F GRACE wiki 9\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_emb/GRACE_wiki_9.npz'\n",
      "SC-F GRACE pubmed 0\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_emb/GRACE_pubmed_0.npz'\n",
      "SC-F GRACE pubmed 1\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_emb/GRACE_pubmed_1.npz'\n",
      "SC-F GRACE pubmed 2\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_emb/GRACE_pubmed_2.npz'\n",
      "SC-F GRACE pubmed 3\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_emb/GRACE_pubmed_3.npz'\n",
      "SC-F GRACE pubmed 4\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_emb/GRACE_pubmed_4.npz'\n",
      "SC-F GRACE pubmed 5\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_emb/GRACE_pubmed_5.npz'\n",
      "SC-F GRACE pubmed 6\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_emb/GRACE_pubmed_6.npz'\n",
      "SC-F GRACE pubmed 7\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_emb/GRACE_pubmed_7.npz'\n",
      "SC-F GRACE pubmed 8\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_emb/GRACE_pubmed_8.npz'\n",
      "SC-F GRACE pubmed 9\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_emb/GRACE_pubmed_9.npz'\n",
      "SC-F GRACE amazon-photo 0\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_emb/GRACE_amazon-photo_0.npz'\n",
      "SC-F GRACE amazon-photo 1\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_emb/GRACE_amazon-photo_1.npz'\n",
      "SC-F GRACE amazon-photo 2\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_emb/GRACE_amazon-photo_2.npz'\n",
      "SC-F GRACE amazon-photo 3\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_emb/GRACE_amazon-photo_3.npz'\n",
      "SC-F GRACE amazon-photo 4\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_emb/GRACE_amazon-photo_4.npz'\n",
      "SC-F GRACE amazon-photo 5\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_emb/GRACE_amazon-photo_5.npz'\n",
      "SC-F GRACE amazon-photo 6\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_emb/GRACE_amazon-photo_6.npz'\n",
      "SC-F GRACE amazon-photo 7\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_emb/GRACE_amazon-photo_7.npz'\n",
      "SC-F GRACE amazon-photo 8\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_emb/GRACE_amazon-photo_8.npz'\n",
      "SC-F GRACE amazon-photo 9\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_emb/GRACE_amazon-photo_9.npz'\n",
      "SC-F GRACE amazon-computers 0\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_emb/GRACE_amazon-computers_0.npz'\n",
      "SC-F GRACE amazon-computers 1\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_emb/GRACE_amazon-computers_1.npz'\n",
      "SC-F GRACE amazon-computers 2\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_emb/GRACE_amazon-computers_2.npz'\n",
      "SC-F GRACE amazon-computers 3\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_emb/GRACE_amazon-computers_3.npz'\n",
      "SC-F GRACE amazon-computers 4\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_emb/GRACE_amazon-computers_4.npz'\n",
      "SC-F GRACE amazon-computers 5\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_emb/GRACE_amazon-computers_5.npz'\n",
      "SC-F GRACE amazon-computers 6\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_emb/GRACE_amazon-computers_6.npz'\n",
      "SC-F GRACE amazon-computers 7\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_emb/GRACE_amazon-computers_7.npz'\n",
      "SC-F GRACE amazon-computers 8\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_emb/GRACE_amazon-computers_8.npz'\n",
      "SC-F GRACE amazon-computers 9\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_emb/GRACE_amazon-computers_9.npz'\n",
      "AP GRACE cora 0\n",
      "AP GRACE cora 1\n",
      "AP GRACE cora 2\n",
      "AP GRACE cora 3\n",
      "AP GRACE cora 4\n",
      "AP GRACE cora 5\n",
      "AP GRACE cora 6\n",
      "AP GRACE cora 7\n",
      "AP GRACE cora 8\n",
      "AP GRACE cora 9\n",
      "AP GRACE citeseer 0\n",
      "AP GRACE citeseer 1\n",
      "AP GRACE citeseer 2\n",
      "AP GRACE citeseer 3\n",
      "AP GRACE citeseer 4\n",
      "AP GRACE citeseer 5\n",
      "AP GRACE citeseer 6\n",
      "AP GRACE citeseer 7\n",
      "AP GRACE citeseer 8\n",
      "AP GRACE citeseer 9\n",
      "AP GRACE wiki 0\n",
      "AP GRACE wiki 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ly/miniconda3/envs/pyg/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/ly/miniconda3/envs/pyg/lib/python3.7/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AP GRACE wiki 2\n",
      "AP GRACE wiki 3\n",
      "AP GRACE wiki 4\n",
      "AP GRACE wiki 5\n",
      "AP GRACE wiki 6\n",
      "AP GRACE wiki 7\n",
      "AP GRACE wiki 8\n",
      "AP GRACE wiki 9\n",
      "AP GRACE pubmed 0\n",
      "AP GRACE pubmed 1\n",
      "AP GRACE pubmed 2\n",
      "AP GRACE pubmed 3\n",
      "AP GRACE pubmed 4\n",
      "AP GRACE pubmed 5\n",
      "AP GRACE pubmed 6\n",
      "AP GRACE pubmed 7\n",
      "AP GRACE pubmed 8\n",
      "AP GRACE pubmed 9\n",
      "AP GRACE amazon-photo 0\n",
      "AP GRACE amazon-photo 1\n",
      "AP GRACE amazon-photo 2\n",
      "AP GRACE amazon-photo 3\n",
      "AP GRACE amazon-photo 4\n",
      "AP GRACE amazon-photo 5\n",
      "AP GRACE amazon-photo 6\n",
      "AP GRACE amazon-photo 7\n",
      "AP GRACE amazon-photo 8\n",
      "AP GRACE amazon-photo 9\n",
      "AP GRACE amazon-computers 0\n",
      "AP GRACE amazon-computers 1\n",
      "AP GRACE amazon-computers 2\n",
      "AP GRACE amazon-computers 3\n",
      "AP GRACE amazon-computers 4\n",
      "AP GRACE amazon-computers 5\n",
      "AP GRACE amazon-computers 6\n",
      "AP GRACE amazon-computers 7\n",
      "AP GRACE amazon-computers 8\n",
      "AP GRACE amazon-computers 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 3/6 [00:01<00:01,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HCA GRACE cora 0\n",
      "HCA GRACE cora 1\n",
      "HCA GRACE cora 2\n",
      "HCA GRACE cora 3\n",
      "HCA GRACE cora 4\n",
      "HCA GRACE cora 5\n",
      "HCA GRACE cora 6\n",
      "HCA GRACE cora 7\n",
      "HCA GRACE cora 8\n",
      "HCA GRACE cora 9\n",
      "HCA GRACE citeseer 0\n",
      "HCA GRACE citeseer 1\n",
      "HCA GRACE citeseer 2\n",
      "HCA GRACE citeseer 3\n",
      "HCA GRACE citeseer 4\n",
      "HCA GRACE citeseer 5\n",
      "HCA GRACE citeseer 6\n",
      "HCA GRACE citeseer 7\n",
      "HCA GRACE citeseer 8\n",
      "HCA GRACE citeseer 9\n",
      "HCA GRACE wiki 0\n",
      "HCA GRACE wiki 1\n",
      "HCA GRACE wiki 2\n",
      "HCA GRACE wiki 3\n",
      "HCA GRACE wiki 4\n",
      "HCA GRACE wiki 5\n",
      "HCA GRACE wiki 6\n",
      "HCA GRACE wiki 7\n",
      "HCA GRACE wiki 8\n",
      "HCA GRACE wiki 9\n",
      "HCA GRACE pubmed 0\n",
      "HCA GRACE pubmed 1\n",
      "HCA GRACE pubmed 2\n",
      "HCA GRACE pubmed 3\n",
      "HCA GRACE pubmed 4\n",
      "HCA GRACE pubmed 5\n",
      "HCA GRACE pubmed 6\n",
      "HCA GRACE pubmed 7\n",
      "HCA GRACE pubmed 8\n",
      "HCA GRACE pubmed 9\n",
      "HCA GRACE amazon-photo 0\n",
      "HCA GRACE amazon-photo 1\n",
      "HCA GRACE amazon-photo 2\n",
      "HCA GRACE amazon-photo 3\n",
      "HCA GRACE amazon-photo 4\n",
      "HCA GRACE amazon-photo 5\n",
      "HCA GRACE amazon-photo 6\n",
      "HCA GRACE amazon-photo 7\n",
      "HCA GRACE amazon-photo 8\n",
      "HCA GRACE amazon-photo 9\n",
      "HCA GRACE amazon-computers 0\n",
      "HCA GRACE amazon-computers 1\n",
      "HCA GRACE amazon-computers 2\n",
      "HCA GRACE amazon-computers 3\n",
      "HCA GRACE amazon-computers 4\n",
      "HCA GRACE amazon-computers 5\n",
      "HCA GRACE amazon-computers 6\n",
      "HCA GRACE amazon-computers 7\n",
      "HCA GRACE amazon-computers 8\n",
      "HCA GRACE amazon-computers 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [00:02<00:01,  1.97it/s]/home/ly/miniconda3/envs/pyg/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/ly/miniconda3/envs/pyg/lib/python3.7/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DBSCAN GRACE cora 0\n",
      "DBSCAN GRACE cora 1\n",
      "[Errno 2] No such file or directory: 'DBSCAN/outputs_emb/GRACE_cora_1.npz'\n",
      "DBSCAN GRACE cora 2\n",
      "[Errno 2] No such file or directory: 'DBSCAN/outputs_emb/GRACE_cora_2.npz'\n",
      "DBSCAN GRACE cora 3\n",
      "[Errno 2] No such file or directory: 'DBSCAN/outputs_emb/GRACE_cora_3.npz'\n",
      "DBSCAN GRACE cora 4\n",
      "[Errno 2] No such file or directory: 'DBSCAN/outputs_emb/GRACE_cora_4.npz'\n",
      "DBSCAN GRACE cora 5\n",
      "[Errno 2] No such file or directory: 'DBSCAN/outputs_emb/GRACE_cora_5.npz'\n",
      "DBSCAN GRACE cora 6\n",
      "[Errno 2] No such file or directory: 'DBSCAN/outputs_emb/GRACE_cora_6.npz'\n",
      "DBSCAN GRACE cora 7\n",
      "[Errno 2] No such file or directory: 'DBSCAN/outputs_emb/GRACE_cora_7.npz'\n",
      "DBSCAN GRACE cora 8\n",
      "[Errno 2] No such file or directory: 'DBSCAN/outputs_emb/GRACE_cora_8.npz'\n",
      "DBSCAN GRACE cora 9\n",
      "[Errno 2] No such file or directory: 'DBSCAN/outputs_emb/GRACE_cora_9.npz'\n",
      "DBSCAN GRACE citeseer 0\n",
      "[Errno 2] No such file or directory: 'DBSCAN/outputs_emb/GRACE_citeseer_0.npz'\n",
      "DBSCAN GRACE citeseer 1\n",
      "[Errno 2] No such file or directory: 'DBSCAN/outputs_emb/GRACE_citeseer_1.npz'\n",
      "DBSCAN GRACE citeseer 2\n",
      "[Errno 2] No such file or directory: 'DBSCAN/outputs_emb/GRACE_citeseer_2.npz'\n",
      "DBSCAN GRACE citeseer 3\n",
      "[Errno 2] No such file or directory: 'DBSCAN/outputs_emb/GRACE_citeseer_3.npz'\n",
      "DBSCAN GRACE citeseer 4\n",
      "[Errno 2] No such file or directory: 'DBSCAN/outputs_emb/GRACE_citeseer_4.npz'\n",
      "DBSCAN GRACE citeseer 5\n",
      "[Errno 2] No such file or directory: 'DBSCAN/outputs_emb/GRACE_citeseer_5.npz'\n",
      "DBSCAN GRACE citeseer 6\n",
      "[Errno 2] No such file or directory: 'DBSCAN/outputs_emb/GRACE_citeseer_6.npz'\n",
      "DBSCAN GRACE citeseer 7\n",
      "[Errno 2] No such file or directory: 'DBSCAN/outputs_emb/GRACE_citeseer_7.npz'\n",
      "DBSCAN GRACE citeseer 8\n",
      "[Errno 2] No such file or directory: 'DBSCAN/outputs_emb/GRACE_citeseer_8.npz'\n",
      "DBSCAN GRACE citeseer 9\n",
      "[Errno 2] No such file or directory: 'DBSCAN/outputs_emb/GRACE_citeseer_9.npz'\n",
      "DBSCAN GRACE wiki 0\n",
      "[Errno 2] No such file or directory: 'DBSCAN/outputs_emb/GRACE_wiki_0.npz'\n",
      "DBSCAN GRACE wiki 1\n",
      "[Errno 2] No such file or directory: 'DBSCAN/outputs_emb/GRACE_wiki_1.npz'\n",
      "DBSCAN GRACE wiki 2\n",
      "[Errno 2] No such file or directory: 'DBSCAN/outputs_emb/GRACE_wiki_2.npz'\n",
      "DBSCAN GRACE wiki 3\n",
      "[Errno 2] No such file or directory: 'DBSCAN/outputs_emb/GRACE_wiki_3.npz'\n",
      "DBSCAN GRACE wiki 4\n",
      "[Errno 2] No such file or directory: 'DBSCAN/outputs_emb/GRACE_wiki_4.npz'\n",
      "DBSCAN GRACE wiki 5\n",
      "[Errno 2] No such file or directory: 'DBSCAN/outputs_emb/GRACE_wiki_5.npz'\n",
      "DBSCAN GRACE wiki 6\n",
      "[Errno 2] No such file or directory: 'DBSCAN/outputs_emb/GRACE_wiki_6.npz'\n",
      "DBSCAN GRACE wiki 7\n",
      "[Errno 2] No such file or directory: 'DBSCAN/outputs_emb/GRACE_wiki_7.npz'\n",
      "DBSCAN GRACE wiki 8\n",
      "[Errno 2] No such file or directory: 'DBSCAN/outputs_emb/GRACE_wiki_8.npz'\n",
      "DBSCAN GRACE wiki 9\n",
      "[Errno 2] No such file or directory: 'DBSCAN/outputs_emb/GRACE_wiki_9.npz'\n",
      "DBSCAN GRACE pubmed 0\n",
      "[Errno 2] No such file or directory: 'DBSCAN/outputs_emb/GRACE_pubmed_0.npz'\n",
      "DBSCAN GRACE pubmed 1\n",
      "[Errno 2] No such file or directory: 'DBSCAN/outputs_emb/GRACE_pubmed_1.npz'\n",
      "DBSCAN GRACE pubmed 2\n",
      "[Errno 2] No such file or directory: 'DBSCAN/outputs_emb/GRACE_pubmed_2.npz'\n",
      "DBSCAN GRACE pubmed 3\n",
      "[Errno 2] No such file or directory: 'DBSCAN/outputs_emb/GRACE_pubmed_3.npz'\n",
      "DBSCAN GRACE pubmed 4\n",
      "[Errno 2] No such file or directory: 'DBSCAN/outputs_emb/GRACE_pubmed_4.npz'\n",
      "DBSCAN GRACE pubmed 5\n",
      "[Errno 2] No such file or directory: 'DBSCAN/outputs_emb/GRACE_pubmed_5.npz'\n",
      "DBSCAN GRACE pubmed 6\n",
      "[Errno 2] No such file or directory: 'DBSCAN/outputs_emb/GRACE_pubmed_6.npz'\n",
      "DBSCAN GRACE pubmed 7\n",
      "[Errno 2] No such file or directory: 'DBSCAN/outputs_emb/GRACE_pubmed_7.npz'\n",
      "DBSCAN GRACE pubmed 8\n",
      "[Errno 2] No such file or directory: 'DBSCAN/outputs_emb/GRACE_pubmed_8.npz'\n",
      "DBSCAN GRACE pubmed 9\n",
      "[Errno 2] No such file or directory: 'DBSCAN/outputs_emb/GRACE_pubmed_9.npz'\n",
      "DBSCAN GRACE amazon-photo 0\n",
      "[Errno 2] No such file or directory: 'DBSCAN/outputs_emb/GRACE_amazon-photo_0.npz'\n",
      "DBSCAN GRACE amazon-photo 1\n",
      "[Errno 2] No such file or directory: 'DBSCAN/outputs_emb/GRACE_amazon-photo_1.npz'\n",
      "DBSCAN GRACE amazon-photo 2\n",
      "[Errno 2] No such file or directory: 'DBSCAN/outputs_emb/GRACE_amazon-photo_2.npz'\n",
      "DBSCAN GRACE amazon-photo 3\n",
      "[Errno 2] No such file or directory: 'DBSCAN/outputs_emb/GRACE_amazon-photo_3.npz'\n",
      "DBSCAN GRACE amazon-photo 4\n",
      "[Errno 2] No such file or directory: 'DBSCAN/outputs_emb/GRACE_amazon-photo_4.npz'\n",
      "DBSCAN GRACE amazon-photo 5\n",
      "[Errno 2] No such file or directory: 'DBSCAN/outputs_emb/GRACE_amazon-photo_5.npz'\n",
      "DBSCAN GRACE amazon-photo 6\n",
      "[Errno 2] No such file or directory: 'DBSCAN/outputs_emb/GRACE_amazon-photo_6.npz'\n",
      "DBSCAN GRACE amazon-photo 7\n",
      "[Errno 2] No such file or directory: 'DBSCAN/outputs_emb/GRACE_amazon-photo_7.npz'\n",
      "DBSCAN GRACE amazon-photo 8\n",
      "[Errno 2] No such file or directory: 'DBSCAN/outputs_emb/GRACE_amazon-photo_8.npz'\n",
      "DBSCAN GRACE amazon-photo 9\n",
      "[Errno 2] No such file or directory: 'DBSCAN/outputs_emb/GRACE_amazon-photo_9.npz'\n",
      "DBSCAN GRACE amazon-computers 0\n",
      "[Errno 2] No such file or directory: 'DBSCAN/outputs_emb/GRACE_amazon-computers_0.npz'\n",
      "DBSCAN GRACE amazon-computers 1\n",
      "[Errno 2] No such file or directory: 'DBSCAN/outputs_emb/GRACE_amazon-computers_1.npz'\n",
      "DBSCAN GRACE amazon-computers 2\n",
      "[Errno 2] No such file or directory: 'DBSCAN/outputs_emb/GRACE_amazon-computers_2.npz'\n",
      "DBSCAN GRACE amazon-computers 3\n",
      "[Errno 2] No such file or directory: 'DBSCAN/outputs_emb/GRACE_amazon-computers_3.npz'\n",
      "DBSCAN GRACE amazon-computers 4\n",
      "[Errno 2] No such file or directory: 'DBSCAN/outputs_emb/GRACE_amazon-computers_4.npz'\n",
      "DBSCAN GRACE amazon-computers 5\n",
      "[Errno 2] No such file or directory: 'DBSCAN/outputs_emb/GRACE_amazon-computers_5.npz'\n",
      "DBSCAN GRACE amazon-computers 6\n",
      "[Errno 2] No such file or directory: 'DBSCAN/outputs_emb/GRACE_amazon-computers_6.npz'\n",
      "DBSCAN GRACE amazon-computers 7\n",
      "[Errno 2] No such file or directory: 'DBSCAN/outputs_emb/GRACE_amazon-computers_7.npz'\n",
      "DBSCAN GRACE amazon-computers 8\n",
      "[Errno 2] No such file or directory: 'DBSCAN/outputs_emb/GRACE_amazon-computers_8.npz'\n",
      "DBSCAN GRACE amazon-computers 9\n",
      "[Errno 2] No such file or directory: 'DBSCAN/outputs_emb/GRACE_amazon-computers_9.npz'\n",
      "Mean-shift GRACE cora 0\n",
      "Mean-shift GRACE cora 1\n",
      "Mean-shift GRACE cora 2\n",
      "Mean-shift GRACE cora 3\n",
      "Mean-shift GRACE cora 4\n",
      "Mean-shift GRACE cora 5\n",
      "Mean-shift GRACE cora 6\n",
      "Mean-shift GRACE cora 7\n",
      "Mean-shift GRACE cora 8\n",
      "Mean-shift GRACE cora 9\n",
      "Mean-shift GRACE citeseer 0\n",
      "Mean-shift GRACE citeseer 1\n",
      "Mean-shift GRACE citeseer 2\n",
      "Mean-shift GRACE citeseer 3\n",
      "Mean-shift GRACE citeseer 4\n",
      "Mean-shift GRACE citeseer 5\n",
      "Mean-shift GRACE citeseer 6\n",
      "Mean-shift GRACE citeseer 7\n",
      "Mean-shift GRACE citeseer 8\n",
      "Mean-shift GRACE citeseer 9\n",
      "Mean-shift GRACE wiki 0\n",
      "Mean-shift GRACE wiki 1\n",
      "Mean-shift GRACE wiki 2\n",
      "Mean-shift GRACE wiki 3\n",
      "Mean-shift GRACE wiki 4\n",
      "Mean-shift GRACE wiki 5\n",
      "Mean-shift GRACE wiki 6\n",
      "Mean-shift GRACE wiki 7\n",
      "Mean-shift GRACE wiki 8\n",
      "Mean-shift GRACE wiki 9\n",
      "Mean-shift GRACE pubmed 0\n",
      "Mean-shift GRACE pubmed 1\n",
      "Mean-shift GRACE pubmed 2\n",
      "Mean-shift GRACE pubmed 3\n",
      "Mean-shift GRACE pubmed 4\n",
      "Mean-shift GRACE pubmed 5\n",
      "Mean-shift GRACE pubmed 6\n",
      "Mean-shift GRACE pubmed 7\n",
      "Mean-shift GRACE pubmed 8\n",
      "Mean-shift GRACE pubmed 9\n",
      "Mean-shift GRACE amazon-photo 0\n",
      "Mean-shift GRACE amazon-photo 1\n",
      "Mean-shift GRACE amazon-photo 2\n",
      "Mean-shift GRACE amazon-photo 3\n",
      "Mean-shift GRACE amazon-photo 4\n",
      "Mean-shift GRACE amazon-photo 5\n",
      "Mean-shift GRACE amazon-photo 6\n",
      "Mean-shift GRACE amazon-photo 7\n",
      "Mean-shift GRACE amazon-photo 8\n",
      "Mean-shift GRACE amazon-photo 9\n",
      "Mean-shift GRACE amazon-computers 0\n",
      "Mean-shift GRACE amazon-computers 1\n",
      "Mean-shift GRACE amazon-computers 2\n",
      "Mean-shift GRACE amazon-computers 3\n",
      "Mean-shift GRACE amazon-computers 4\n",
      "Mean-shift GRACE amazon-computers 5\n",
      "Mean-shift GRACE amazon-computers 6\n",
      "Mean-shift GRACE amazon-computers 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:02<00:00,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean-shift GRACE amazon-computers 8\n",
      "Mean-shift GRACE amazon-computers 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import normalized_mutual_info_score as NMI, adjusted_mutual_info_score as AMI, adjusted_rand_score as ARI\n",
    "from tqdm import tqdm\n",
    "\n",
    "seeds = np.arange(10, dtype=int)\n",
    "for model in tqdm(models, total=len(models)):\n",
    "    for dataset in datasets:\n",
    "        nmis, amis, aris = [], [], []\n",
    "        nclasses = []\n",
    "        for seed in seeds:\n",
    "            emb_model = emb_models[0]\n",
    "            \n",
    "            print(model, emb_model, dataset, seed)\n",
    "            \n",
    "            try:\n",
    "                emb_name = os.path.join(\"{}/outputs_emb\".format(model), \"{}_{}_{}.npz\".format(emb_model, dataset, seed))\n",
    "                data = np.load(emb_name)\n",
    "\n",
    "                preds = data[\"preds\"]\n",
    "                labels = true_labels[dataset]\n",
    "\n",
    "                nmi = NMI(labels, preds)\n",
    "                ami = AMI(labels, preds)\n",
    "                ari = ARI(labels, preds)\n",
    "                nclass = np.unique(preds).shape[0]\n",
    "                \n",
    "                nmis.append(nmi)\n",
    "                amis.append(ami)\n",
    "                aris.append(ari)\n",
    "                nclasses.append(nclass)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                \n",
    "        try:\n",
    "            nmi_m = np.mean(nmis)\n",
    "            ami_m = np.mean(amis)\n",
    "            ari_m = np.mean(aris)\n",
    "            nclass_m = np.mean(nclasses)\n",
    "\n",
    "            df_nmi[dataset][models.index(model)] = nmi_m\n",
    "            df_ami[dataset][models.index(model)] = ami_m\n",
    "            df_ari[dataset][models.index(model)] = ari_m \n",
    "            df_nclass[dataset][models.index(model)] = nclass_m\n",
    "        except Exception as e:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "acfe07f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>models</th>\n",
       "      <th>cora</th>\n",
       "      <th>citeseer</th>\n",
       "      <th>wiki</th>\n",
       "      <th>pubmed</th>\n",
       "      <th>amazon-photo</th>\n",
       "      <th>amazon-computers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KMeans</td>\n",
       "      <td>0.492585</td>\n",
       "      <td>0.390674</td>\n",
       "      <td>0.452109</td>\n",
       "      <td>0.308011</td>\n",
       "      <td>0.448618</td>\n",
       "      <td>0.40564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SC-F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AP</td>\n",
       "      <td>0.210723</td>\n",
       "      <td>0.031486</td>\n",
       "      <td>0.426271</td>\n",
       "      <td>0.151319</td>\n",
       "      <td>0.454534</td>\n",
       "      <td>0.359423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HCA</td>\n",
       "      <td>0.209879</td>\n",
       "      <td>0.154041</td>\n",
       "      <td>0.101024</td>\n",
       "      <td>0.137792</td>\n",
       "      <td>0.122004</td>\n",
       "      <td>0.106444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DBSCAN</td>\n",
       "      <td>0.001361</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mean-shift</td>\n",
       "      <td>0.041039</td>\n",
       "      <td>0.020779</td>\n",
       "      <td>0.07806</td>\n",
       "      <td>0.054893</td>\n",
       "      <td>0.054772</td>\n",
       "      <td>0.030391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       models      cora  citeseer      wiki    pubmed amazon-photo  \\\n",
       "0      KMeans  0.492585  0.390674  0.452109  0.308011     0.448618   \n",
       "1        SC-F       NaN       NaN       NaN       NaN          NaN   \n",
       "2          AP  0.210723  0.031486  0.426271  0.151319     0.454534   \n",
       "3         HCA  0.209879  0.154041  0.101024  0.137792     0.122004   \n",
       "4      DBSCAN  0.001361       NaN       NaN       NaN          NaN   \n",
       "5  Mean-shift  0.041039  0.020779   0.07806  0.054893     0.054772   \n",
       "\n",
       "  amazon-computers  \n",
       "0          0.40564  \n",
       "1              NaN  \n",
       "2         0.359423  \n",
       "3         0.106444  \n",
       "4              NaN  \n",
       "5         0.030391  "
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "52c94e04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>models</th>\n",
       "      <th>cora</th>\n",
       "      <th>citeseer</th>\n",
       "      <th>wiki</th>\n",
       "      <th>pubmed</th>\n",
       "      <th>amazon-photo</th>\n",
       "      <th>amazon-computers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KMeans</td>\n",
       "      <td>0.411716</td>\n",
       "      <td>0.385981</td>\n",
       "      <td>0.215861</td>\n",
       "      <td>0.257699</td>\n",
       "      <td>0.172658</td>\n",
       "      <td>0.145507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SC-F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AP</td>\n",
       "      <td>0.024151</td>\n",
       "      <td>0.002805</td>\n",
       "      <td>0.091695</td>\n",
       "      <td>0.004419</td>\n",
       "      <td>0.038419</td>\n",
       "      <td>0.014359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HCA</td>\n",
       "      <td>0.128831</td>\n",
       "      <td>0.096461</td>\n",
       "      <td>0.026496</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.035066</td>\n",
       "      <td>0.032906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DBSCAN</td>\n",
       "      <td>0.000355</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mean-shift</td>\n",
       "      <td>-0.000775</td>\n",
       "      <td>0.001077</td>\n",
       "      <td>0.004184</td>\n",
       "      <td>0.002123</td>\n",
       "      <td>0.000548</td>\n",
       "      <td>0.000189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       models      cora  citeseer      wiki    pubmed amazon-photo  \\\n",
       "0      KMeans  0.411716  0.385981  0.215861  0.257699     0.172658   \n",
       "1        SC-F       NaN       NaN       NaN       NaN          NaN   \n",
       "2          AP  0.024151  0.002805  0.091695  0.004419     0.038419   \n",
       "3         HCA  0.128831  0.096461  0.026496     0.104     0.035066   \n",
       "4      DBSCAN  0.000355       NaN       NaN       NaN          NaN   \n",
       "5  Mean-shift -0.000775  0.001077  0.004184  0.002123     0.000548   \n",
       "\n",
       "  amazon-computers  \n",
       "0         0.145507  \n",
       "1              NaN  \n",
       "2         0.014359  \n",
       "3         0.032906  \n",
       "4              NaN  \n",
       "5         0.000189  "
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "315086ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>models</th>\n",
       "      <th>cora</th>\n",
       "      <th>citeseer</th>\n",
       "      <th>wiki</th>\n",
       "      <th>pubmed</th>\n",
       "      <th>amazon-photo</th>\n",
       "      <th>amazon-computers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KMeans</td>\n",
       "      <td>0.490725</td>\n",
       "      <td>0.389355</td>\n",
       "      <td>0.438541</td>\n",
       "      <td>0.30794</td>\n",
       "      <td>0.447596</td>\n",
       "      <td>0.404643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SC-F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AP</td>\n",
       "      <td>0.187944</td>\n",
       "      <td>0.026376</td>\n",
       "      <td>0.366997</td>\n",
       "      <td>0.143191</td>\n",
       "      <td>0.430549</td>\n",
       "      <td>0.332097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HCA</td>\n",
       "      <td>0.20913</td>\n",
       "      <td>0.153492</td>\n",
       "      <td>0.098958</td>\n",
       "      <td>0.137739</td>\n",
       "      <td>0.12163</td>\n",
       "      <td>0.10616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DBSCAN</td>\n",
       "      <td>-0.000031</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mean-shift</td>\n",
       "      <td>0.026431</td>\n",
       "      <td>0.012671</td>\n",
       "      <td>0.053498</td>\n",
       "      <td>0.050022</td>\n",
       "      <td>0.050181</td>\n",
       "      <td>0.026932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       models      cora  citeseer      wiki    pubmed amazon-photo  \\\n",
       "0      KMeans  0.490725  0.389355  0.438541   0.30794     0.447596   \n",
       "1        SC-F       NaN       NaN       NaN       NaN          NaN   \n",
       "2          AP  0.187944  0.026376  0.366997  0.143191     0.430549   \n",
       "3         HCA   0.20913  0.153492  0.098958  0.137739      0.12163   \n",
       "4      DBSCAN -0.000031       NaN       NaN       NaN          NaN   \n",
       "5  Mean-shift  0.026431  0.012671  0.053498  0.050022     0.050181   \n",
       "\n",
       "  amazon-computers  \n",
       "0         0.404643  \n",
       "1              NaN  \n",
       "2         0.332097  \n",
       "3          0.10616  \n",
       "4              NaN  \n",
       "5         0.026932  "
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "5bb5870c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>models</th>\n",
       "      <th>cora</th>\n",
       "      <th>citeseer</th>\n",
       "      <th>wiki</th>\n",
       "      <th>pubmed</th>\n",
       "      <th>amazon-photo</th>\n",
       "      <th>amazon-computers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KMeans</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SC-F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AP</td>\n",
       "      <td>103.8</td>\n",
       "      <td>30.0</td>\n",
       "      <td>128.6</td>\n",
       "      <td>654.9</td>\n",
       "      <td>317.4</td>\n",
       "      <td>513.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HCA</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DBSCAN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mean-shift</td>\n",
       "      <td>14.7</td>\n",
       "      <td>10.3</td>\n",
       "      <td>17.1</td>\n",
       "      <td>69.9</td>\n",
       "      <td>13.2</td>\n",
       "      <td>13.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       models   cora citeseer   wiki pubmed amazon-photo amazon-computers\n",
       "0      KMeans    7.0      6.0   19.0    3.0          8.0             10.0\n",
       "1        SC-F    NaN      NaN    NaN    NaN          NaN              NaN\n",
       "2          AP  103.8     30.0  128.6  654.9        317.4            513.3\n",
       "3         HCA    2.0      2.0    2.0    2.0          2.0              2.0\n",
       "4      DBSCAN    2.0      NaN    NaN    NaN          NaN              NaN\n",
       "5  Mean-shift   14.7     10.3   17.1   69.9         13.2             13.5"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef281198",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d4bd6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d60c140b",
   "metadata": {},
   "source": [
    "## Based on TSNE_Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "5a5b6521",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    \"KMeans\",\n",
    "#     \"SC-G\",\n",
    "    \"SC-F\",\n",
    "    # --- # \n",
    "    \"AP\",\n",
    "    \"HCA\",\n",
    "    \"HDBSCAN\",\n",
    "    \"Mean-shift\",\n",
    "    # --- #\n",
    "#     \"Louvain\",\n",
    "#     \"Leiden\",\n",
    "#     \"ILouvain\",   \n",
    "#     \"OPTICS\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "83408818",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_models = [\n",
    "#     \"GAE\",\n",
    "#     \"VGAE\",\n",
    "#     \"ARGA\",\n",
    "#     \"ARVGA\",\n",
    "#     \"AGE\",\n",
    "#     \"DGI\",\n",
    "#     \"MVGRL\",\n",
    "    \"GRACE\",\n",
    "#     \"GGD\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "8c958c2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>models</th>\n",
       "      <th>cora</th>\n",
       "      <th>citeseer</th>\n",
       "      <th>wiki</th>\n",
       "      <th>pubmed</th>\n",
       "      <th>amazon-photo</th>\n",
       "      <th>amazon-computers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KMeans</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SC-F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HCA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HDBSCAN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mean-shift</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       models cora citeseer wiki pubmed amazon-photo amazon-computers\n",
       "0      KMeans  NaN      NaN  NaN    NaN          NaN              NaN\n",
       "1        SC-F  NaN      NaN  NaN    NaN          NaN              NaN\n",
       "2          AP  NaN      NaN  NaN    NaN          NaN              NaN\n",
       "3         HCA  NaN      NaN  NaN    NaN          NaN              NaN\n",
       "4     HDBSCAN  NaN      NaN  NaN    NaN          NaN              NaN\n",
       "5  Mean-shift  NaN      NaN  NaN    NaN          NaN              NaN"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data={\"models\":models}, columns=[\"models\"]+datasets)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "156e0085",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nmi = df.copy()\n",
    "df_ami = df.copy()\n",
    "df_ari = df.copy()\n",
    "df_nclass = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "46878964",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]/home/ly/miniconda3/envs/pyg/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/ly/miniconda3/envs/pyg/lib/python3.7/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMeans GRACE cora 0\n",
      "[Errno 2] No such file or directory: 'KMeans/outputs_tsne/GRACE_cora_0.npz'\n",
      "KMeans GRACE cora 1\n",
      "[Errno 2] No such file or directory: 'KMeans/outputs_tsne/GRACE_cora_1.npz'\n",
      "KMeans GRACE cora 2\n",
      "[Errno 2] No such file or directory: 'KMeans/outputs_tsne/GRACE_cora_2.npz'\n",
      "KMeans GRACE cora 3\n",
      "[Errno 2] No such file or directory: 'KMeans/outputs_tsne/GRACE_cora_3.npz'\n",
      "KMeans GRACE cora 4\n",
      "[Errno 2] No such file or directory: 'KMeans/outputs_tsne/GRACE_cora_4.npz'\n",
      "KMeans GRACE cora 5\n",
      "[Errno 2] No such file or directory: 'KMeans/outputs_tsne/GRACE_cora_5.npz'\n",
      "KMeans GRACE cora 6\n",
      "[Errno 2] No such file or directory: 'KMeans/outputs_tsne/GRACE_cora_6.npz'\n",
      "KMeans GRACE cora 7\n",
      "[Errno 2] No such file or directory: 'KMeans/outputs_tsne/GRACE_cora_7.npz'\n",
      "KMeans GRACE cora 8\n",
      "[Errno 2] No such file or directory: 'KMeans/outputs_tsne/GRACE_cora_8.npz'\n",
      "KMeans GRACE cora 9\n",
      "[Errno 2] No such file or directory: 'KMeans/outputs_tsne/GRACE_cora_9.npz'\n",
      "KMeans GRACE citeseer 0\n",
      "[Errno 2] No such file or directory: 'KMeans/outputs_tsne/GRACE_citeseer_0.npz'\n",
      "KMeans GRACE citeseer 1\n",
      "[Errno 2] No such file or directory: 'KMeans/outputs_tsne/GRACE_citeseer_1.npz'\n",
      "KMeans GRACE citeseer 2\n",
      "[Errno 2] No such file or directory: 'KMeans/outputs_tsne/GRACE_citeseer_2.npz'\n",
      "KMeans GRACE citeseer 3\n",
      "[Errno 2] No such file or directory: 'KMeans/outputs_tsne/GRACE_citeseer_3.npz'\n",
      "KMeans GRACE citeseer 4\n",
      "[Errno 2] No such file or directory: 'KMeans/outputs_tsne/GRACE_citeseer_4.npz'\n",
      "KMeans GRACE citeseer 5\n",
      "[Errno 2] No such file or directory: 'KMeans/outputs_tsne/GRACE_citeseer_5.npz'\n",
      "KMeans GRACE citeseer 6\n",
      "[Errno 2] No such file or directory: 'KMeans/outputs_tsne/GRACE_citeseer_6.npz'\n",
      "KMeans GRACE citeseer 7\n",
      "[Errno 2] No such file or directory: 'KMeans/outputs_tsne/GRACE_citeseer_7.npz'\n",
      "KMeans GRACE citeseer 8\n",
      "[Errno 2] No such file or directory: 'KMeans/outputs_tsne/GRACE_citeseer_8.npz'\n",
      "KMeans GRACE citeseer 9\n",
      "[Errno 2] No such file or directory: 'KMeans/outputs_tsne/GRACE_citeseer_9.npz'\n",
      "KMeans GRACE wiki 0\n",
      "[Errno 2] No such file or directory: 'KMeans/outputs_tsne/GRACE_wiki_0.npz'\n",
      "KMeans GRACE wiki 1\n",
      "[Errno 2] No such file or directory: 'KMeans/outputs_tsne/GRACE_wiki_1.npz'\n",
      "KMeans GRACE wiki 2\n",
      "[Errno 2] No such file or directory: 'KMeans/outputs_tsne/GRACE_wiki_2.npz'\n",
      "KMeans GRACE wiki 3\n",
      "[Errno 2] No such file or directory: 'KMeans/outputs_tsne/GRACE_wiki_3.npz'\n",
      "KMeans GRACE wiki 4\n",
      "[Errno 2] No such file or directory: 'KMeans/outputs_tsne/GRACE_wiki_4.npz'\n",
      "KMeans GRACE wiki 5\n",
      "[Errno 2] No such file or directory: 'KMeans/outputs_tsne/GRACE_wiki_5.npz'\n",
      "KMeans GRACE wiki 6\n",
      "[Errno 2] No such file or directory: 'KMeans/outputs_tsne/GRACE_wiki_6.npz'\n",
      "KMeans GRACE wiki 7\n",
      "[Errno 2] No such file or directory: 'KMeans/outputs_tsne/GRACE_wiki_7.npz'\n",
      "KMeans GRACE wiki 8\n",
      "[Errno 2] No such file or directory: 'KMeans/outputs_tsne/GRACE_wiki_8.npz'\n",
      "KMeans GRACE wiki 9\n",
      "[Errno 2] No such file or directory: 'KMeans/outputs_tsne/GRACE_wiki_9.npz'\n",
      "KMeans GRACE pubmed 0\n",
      "[Errno 2] No such file or directory: 'KMeans/outputs_tsne/GRACE_pubmed_0.npz'\n",
      "KMeans GRACE pubmed 1\n",
      "[Errno 2] No such file or directory: 'KMeans/outputs_tsne/GRACE_pubmed_1.npz'\n",
      "KMeans GRACE pubmed 2\n",
      "[Errno 2] No such file or directory: 'KMeans/outputs_tsne/GRACE_pubmed_2.npz'\n",
      "KMeans GRACE pubmed 3\n",
      "[Errno 2] No such file or directory: 'KMeans/outputs_tsne/GRACE_pubmed_3.npz'\n",
      "KMeans GRACE pubmed 4\n",
      "[Errno 2] No such file or directory: 'KMeans/outputs_tsne/GRACE_pubmed_4.npz'\n",
      "KMeans GRACE pubmed 5\n",
      "[Errno 2] No such file or directory: 'KMeans/outputs_tsne/GRACE_pubmed_5.npz'\n",
      "KMeans GRACE pubmed 6\n",
      "[Errno 2] No such file or directory: 'KMeans/outputs_tsne/GRACE_pubmed_6.npz'\n",
      "KMeans GRACE pubmed 7\n",
      "[Errno 2] No such file or directory: 'KMeans/outputs_tsne/GRACE_pubmed_7.npz'\n",
      "KMeans GRACE pubmed 8\n",
      "[Errno 2] No such file or directory: 'KMeans/outputs_tsne/GRACE_pubmed_8.npz'\n",
      "KMeans GRACE pubmed 9\n",
      "[Errno 2] No such file or directory: 'KMeans/outputs_tsne/GRACE_pubmed_9.npz'\n",
      "KMeans GRACE amazon-photo 0\n",
      "[Errno 2] No such file or directory: 'KMeans/outputs_tsne/GRACE_amazon-photo_0.npz'\n",
      "KMeans GRACE amazon-photo 1\n",
      "[Errno 2] No such file or directory: 'KMeans/outputs_tsne/GRACE_amazon-photo_1.npz'\n",
      "KMeans GRACE amazon-photo 2\n",
      "[Errno 2] No such file or directory: 'KMeans/outputs_tsne/GRACE_amazon-photo_2.npz'\n",
      "KMeans GRACE amazon-photo 3\n",
      "[Errno 2] No such file or directory: 'KMeans/outputs_tsne/GRACE_amazon-photo_3.npz'\n",
      "KMeans GRACE amazon-photo 4\n",
      "[Errno 2] No such file or directory: 'KMeans/outputs_tsne/GRACE_amazon-photo_4.npz'\n",
      "KMeans GRACE amazon-photo 5\n",
      "[Errno 2] No such file or directory: 'KMeans/outputs_tsne/GRACE_amazon-photo_5.npz'\n",
      "KMeans GRACE amazon-photo 6\n",
      "[Errno 2] No such file or directory: 'KMeans/outputs_tsne/GRACE_amazon-photo_6.npz'\n",
      "KMeans GRACE amazon-photo 7\n",
      "[Errno 2] No such file or directory: 'KMeans/outputs_tsne/GRACE_amazon-photo_7.npz'\n",
      "KMeans GRACE amazon-photo 8\n",
      "[Errno 2] No such file or directory: 'KMeans/outputs_tsne/GRACE_amazon-photo_8.npz'\n",
      "KMeans GRACE amazon-photo 9\n",
      "[Errno 2] No such file or directory: 'KMeans/outputs_tsne/GRACE_amazon-photo_9.npz'\n",
      "KMeans GRACE amazon-computers 0\n",
      "[Errno 2] No such file or directory: 'KMeans/outputs_tsne/GRACE_amazon-computers_0.npz'\n",
      "KMeans GRACE amazon-computers 1\n",
      "[Errno 2] No such file or directory: 'KMeans/outputs_tsne/GRACE_amazon-computers_1.npz'\n",
      "KMeans GRACE amazon-computers 2\n",
      "[Errno 2] No such file or directory: 'KMeans/outputs_tsne/GRACE_amazon-computers_2.npz'\n",
      "KMeans GRACE amazon-computers 3\n",
      "[Errno 2] No such file or directory: 'KMeans/outputs_tsne/GRACE_amazon-computers_3.npz'\n",
      "KMeans GRACE amazon-computers 4\n",
      "[Errno 2] No such file or directory: 'KMeans/outputs_tsne/GRACE_amazon-computers_4.npz'\n",
      "KMeans GRACE amazon-computers 5\n",
      "[Errno 2] No such file or directory: 'KMeans/outputs_tsne/GRACE_amazon-computers_5.npz'\n",
      "KMeans GRACE amazon-computers 6\n",
      "[Errno 2] No such file or directory: 'KMeans/outputs_tsne/GRACE_amazon-computers_6.npz'\n",
      "KMeans GRACE amazon-computers 7\n",
      "[Errno 2] No such file or directory: 'KMeans/outputs_tsne/GRACE_amazon-computers_7.npz'\n",
      "KMeans GRACE amazon-computers 8\n",
      "[Errno 2] No such file or directory: 'KMeans/outputs_tsne/GRACE_amazon-computers_8.npz'\n",
      "KMeans GRACE amazon-computers 9\n",
      "[Errno 2] No such file or directory: 'KMeans/outputs_tsne/GRACE_amazon-computers_9.npz'\n",
      "SC-F GRACE cora 0\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_tsne/GRACE_cora_0.npz'\n",
      "SC-F GRACE cora 1\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_tsne/GRACE_cora_1.npz'\n",
      "SC-F GRACE cora 2\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_tsne/GRACE_cora_2.npz'\n",
      "SC-F GRACE cora 3\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_tsne/GRACE_cora_3.npz'\n",
      "SC-F GRACE cora 4\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_tsne/GRACE_cora_4.npz'\n",
      "SC-F GRACE cora 5\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_tsne/GRACE_cora_5.npz'\n",
      "SC-F GRACE cora 6\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_tsne/GRACE_cora_6.npz'\n",
      "SC-F GRACE cora 7\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_tsne/GRACE_cora_7.npz'\n",
      "SC-F GRACE cora 8\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_tsne/GRACE_cora_8.npz'\n",
      "SC-F GRACE cora 9\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_tsne/GRACE_cora_9.npz'\n",
      "SC-F GRACE citeseer 0\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_tsne/GRACE_citeseer_0.npz'\n",
      "SC-F GRACE citeseer 1\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_tsne/GRACE_citeseer_1.npz'\n",
      "SC-F GRACE citeseer 2\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_tsne/GRACE_citeseer_2.npz'\n",
      "SC-F GRACE citeseer 3\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_tsne/GRACE_citeseer_3.npz'\n",
      "SC-F GRACE citeseer 4\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_tsne/GRACE_citeseer_4.npz'\n",
      "SC-F GRACE citeseer 5\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_tsne/GRACE_citeseer_5.npz'\n",
      "SC-F GRACE citeseer 6\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_tsne/GRACE_citeseer_6.npz'\n",
      "SC-F GRACE citeseer 7\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_tsne/GRACE_citeseer_7.npz'\n",
      "SC-F GRACE citeseer 8\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_tsne/GRACE_citeseer_8.npz'\n",
      "SC-F GRACE citeseer 9\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_tsne/GRACE_citeseer_9.npz'\n",
      "SC-F GRACE wiki 0\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_tsne/GRACE_wiki_0.npz'\n",
      "SC-F GRACE wiki 1\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_tsne/GRACE_wiki_1.npz'\n",
      "SC-F GRACE wiki 2\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_tsne/GRACE_wiki_2.npz'\n",
      "SC-F GRACE wiki 3\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_tsne/GRACE_wiki_3.npz'\n",
      "SC-F GRACE wiki 4\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_tsne/GRACE_wiki_4.npz'\n",
      "SC-F GRACE wiki 5\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_tsne/GRACE_wiki_5.npz'\n",
      "SC-F GRACE wiki 6\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_tsne/GRACE_wiki_6.npz'\n",
      "SC-F GRACE wiki 7\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_tsne/GRACE_wiki_7.npz'\n",
      "SC-F GRACE wiki 8\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_tsne/GRACE_wiki_8.npz'\n",
      "SC-F GRACE wiki 9\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_tsne/GRACE_wiki_9.npz'\n",
      "SC-F GRACE pubmed 0\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_tsne/GRACE_pubmed_0.npz'\n",
      "SC-F GRACE pubmed 1\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_tsne/GRACE_pubmed_1.npz'\n",
      "SC-F GRACE pubmed 2\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_tsne/GRACE_pubmed_2.npz'\n",
      "SC-F GRACE pubmed 3\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_tsne/GRACE_pubmed_3.npz'\n",
      "SC-F GRACE pubmed 4\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_tsne/GRACE_pubmed_4.npz'\n",
      "SC-F GRACE pubmed 5\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_tsne/GRACE_pubmed_5.npz'\n",
      "SC-F GRACE pubmed 6\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_tsne/GRACE_pubmed_6.npz'\n",
      "SC-F GRACE pubmed 7\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_tsne/GRACE_pubmed_7.npz'\n",
      "SC-F GRACE pubmed 8\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_tsne/GRACE_pubmed_8.npz'\n",
      "SC-F GRACE pubmed 9\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_tsne/GRACE_pubmed_9.npz'\n",
      "SC-F GRACE amazon-photo 0\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_tsne/GRACE_amazon-photo_0.npz'\n",
      "SC-F GRACE amazon-photo 1\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_tsne/GRACE_amazon-photo_1.npz'\n",
      "SC-F GRACE amazon-photo 2\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_tsne/GRACE_amazon-photo_2.npz'\n",
      "SC-F GRACE amazon-photo 3\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_tsne/GRACE_amazon-photo_3.npz'\n",
      "SC-F GRACE amazon-photo 4\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_tsne/GRACE_amazon-photo_4.npz'\n",
      "SC-F GRACE amazon-photo 5\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_tsne/GRACE_amazon-photo_5.npz'\n",
      "SC-F GRACE amazon-photo 6\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_tsne/GRACE_amazon-photo_6.npz'\n",
      "SC-F GRACE amazon-photo 7\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_tsne/GRACE_amazon-photo_7.npz'\n",
      "SC-F GRACE amazon-photo 8\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_tsne/GRACE_amazon-photo_8.npz'\n",
      "SC-F GRACE amazon-photo 9\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_tsne/GRACE_amazon-photo_9.npz'\n",
      "SC-F GRACE amazon-computers 0\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_tsne/GRACE_amazon-computers_0.npz'\n",
      "SC-F GRACE amazon-computers 1\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_tsne/GRACE_amazon-computers_1.npz'\n",
      "SC-F GRACE amazon-computers 2\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_tsne/GRACE_amazon-computers_2.npz'\n",
      "SC-F GRACE amazon-computers 3\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_tsne/GRACE_amazon-computers_3.npz'\n",
      "SC-F GRACE amazon-computers 4\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_tsne/GRACE_amazon-computers_4.npz'\n",
      "SC-F GRACE amazon-computers 5\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_tsne/GRACE_amazon-computers_5.npz'\n",
      "SC-F GRACE amazon-computers 6\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_tsne/GRACE_amazon-computers_6.npz'\n",
      "SC-F GRACE amazon-computers 7\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_tsne/GRACE_amazon-computers_7.npz'\n",
      "SC-F GRACE amazon-computers 8\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_tsne/GRACE_amazon-computers_8.npz'\n",
      "SC-F GRACE amazon-computers 9\n",
      "[Errno 2] No such file or directory: 'SC-F/outputs_tsne/GRACE_amazon-computers_9.npz'\n",
      "AP GRACE cora 0\n",
      "AP GRACE cora 1\n",
      "AP GRACE cora 2\n",
      "AP GRACE cora 3\n",
      "AP GRACE cora 4\n",
      "AP GRACE cora 5\n",
      "AP GRACE cora 6\n",
      "AP GRACE cora 7\n",
      "AP GRACE cora 8\n",
      "AP GRACE cora 9\n",
      "AP GRACE citeseer 0\n",
      "AP GRACE citeseer 1\n",
      "AP GRACE citeseer 2\n",
      "AP GRACE citeseer 3\n",
      "AP GRACE citeseer 4\n",
      "AP GRACE citeseer 5\n",
      "AP GRACE citeseer 6\n",
      "AP GRACE citeseer 7\n",
      "AP GRACE citeseer 8\n",
      "AP GRACE citeseer 9\n",
      "AP GRACE wiki 0\n",
      "AP GRACE wiki 1\n",
      "AP GRACE wiki 2\n",
      "AP GRACE wiki 3\n",
      "AP GRACE wiki 4\n",
      "AP GRACE wiki 5\n",
      "AP GRACE wiki 6\n",
      "AP GRACE wiki 7\n",
      "AP GRACE wiki 8\n",
      "AP GRACE wiki 9\n",
      "AP GRACE pubmed 0\n",
      "AP GRACE pubmed 1\n",
      "AP GRACE pubmed 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AP GRACE pubmed 3\n",
      "AP GRACE pubmed 4\n",
      "AP GRACE pubmed 5\n",
      "AP GRACE pubmed 6\n",
      "AP GRACE pubmed 7\n",
      "AP GRACE pubmed 8\n",
      "AP GRACE pubmed 9\n",
      "AP GRACE amazon-photo 0\n",
      "AP GRACE amazon-photo 1\n",
      "AP GRACE amazon-photo 2\n",
      "AP GRACE amazon-photo 3\n",
      "AP GRACE amazon-photo 4\n",
      "AP GRACE amazon-photo 5\n",
      "AP GRACE amazon-photo 6\n",
      "AP GRACE amazon-photo 7\n",
      "AP GRACE amazon-photo 8\n",
      "AP GRACE amazon-photo 9\n",
      "AP GRACE amazon-computers 0\n",
      "AP GRACE amazon-computers 1\n",
      "AP GRACE amazon-computers 2\n",
      "AP GRACE amazon-computers 3\n",
      "AP GRACE amazon-computers 4\n",
      "AP GRACE amazon-computers 5\n",
      "AP GRACE amazon-computers 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 3/6 [00:00<00:00,  6.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AP GRACE amazon-computers 7\n",
      "AP GRACE amazon-computers 8\n",
      "AP GRACE amazon-computers 9\n",
      "HCA GRACE cora 0\n",
      "HCA GRACE cora 1\n",
      "HCA GRACE cora 2\n",
      "HCA GRACE cora 3\n",
      "HCA GRACE cora 4\n",
      "HCA GRACE cora 5\n",
      "HCA GRACE cora 6\n",
      "HCA GRACE cora 7\n",
      "HCA GRACE cora 8\n",
      "HCA GRACE cora 9\n",
      "HCA GRACE citeseer 0\n",
      "HCA GRACE citeseer 1\n",
      "HCA GRACE citeseer 2\n",
      "HCA GRACE citeseer 3\n",
      "HCA GRACE citeseer 4\n",
      "HCA GRACE citeseer 5\n",
      "HCA GRACE citeseer 6\n",
      "HCA GRACE citeseer 7\n",
      "HCA GRACE citeseer 8\n",
      "HCA GRACE citeseer 9\n",
      "HCA GRACE wiki 0\n",
      "HCA GRACE wiki 1\n",
      "HCA GRACE wiki 2\n",
      "HCA GRACE wiki 3\n",
      "HCA GRACE wiki 4\n",
      "HCA GRACE wiki 5\n",
      "HCA GRACE wiki 6\n",
      "HCA GRACE wiki 7\n",
      "HCA GRACE wiki 8\n",
      "HCA GRACE wiki 9\n",
      "HCA GRACE pubmed 0\n",
      "HCA GRACE pubmed 1\n",
      "HCA GRACE pubmed 2\n",
      "HCA GRACE pubmed 3\n",
      "HCA GRACE pubmed 4\n",
      "HCA GRACE pubmed 5\n",
      "HCA GRACE pubmed 6\n",
      "HCA GRACE pubmed 7\n",
      "HCA GRACE pubmed 8\n",
      "HCA GRACE pubmed 9\n",
      "HCA GRACE amazon-photo 0\n",
      "HCA GRACE amazon-photo 1\n",
      "HCA GRACE amazon-photo 2\n",
      "HCA GRACE amazon-photo 3\n",
      "HCA GRACE amazon-photo 4\n",
      "HCA GRACE amazon-photo 5\n",
      "HCA GRACE amazon-photo 6\n",
      "HCA GRACE amazon-photo 7\n",
      "HCA GRACE amazon-photo 8\n",
      "HCA GRACE amazon-photo 9\n",
      "HCA GRACE amazon-computers 0\n",
      "HCA GRACE amazon-computers 1\n",
      "HCA GRACE amazon-computers 2\n",
      "HCA GRACE amazon-computers 3\n",
      "HCA GRACE amazon-computers 4\n",
      "HCA GRACE amazon-computers 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 4/6 [00:01<00:00,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HCA GRACE amazon-computers 6\n",
      "HCA GRACE amazon-computers 7\n",
      "HCA GRACE amazon-computers 8\n",
      "HCA GRACE amazon-computers 9\n",
      "HDBSCAN GRACE cora 0\n",
      "HDBSCAN GRACE cora 1\n",
      "HDBSCAN GRACE cora 2\n",
      "HDBSCAN GRACE cora 3\n",
      "HDBSCAN GRACE cora 4\n",
      "HDBSCAN GRACE cora 5\n",
      "HDBSCAN GRACE cora 6\n",
      "HDBSCAN GRACE cora 7\n",
      "HDBSCAN GRACE cora 8\n",
      "HDBSCAN GRACE cora 9\n",
      "HDBSCAN GRACE citeseer 0\n",
      "HDBSCAN GRACE citeseer 1\n",
      "HDBSCAN GRACE citeseer 2\n",
      "HDBSCAN GRACE citeseer 3\n",
      "HDBSCAN GRACE citeseer 4\n",
      "HDBSCAN GRACE citeseer 5\n",
      "HDBSCAN GRACE citeseer 6\n",
      "HDBSCAN GRACE citeseer 7\n",
      "HDBSCAN GRACE citeseer 8\n",
      "HDBSCAN GRACE citeseer 9\n",
      "HDBSCAN GRACE wiki 0\n",
      "HDBSCAN GRACE wiki 1\n",
      "HDBSCAN GRACE wiki 2\n",
      "HDBSCAN GRACE wiki 3\n",
      "HDBSCAN GRACE wiki 4\n",
      "HDBSCAN GRACE wiki 5\n",
      "HDBSCAN GRACE wiki 6\n",
      "HDBSCAN GRACE wiki 7\n",
      "HDBSCAN GRACE wiki 8\n",
      "HDBSCAN GRACE wiki 9\n",
      "HDBSCAN GRACE pubmed 0\n",
      "HDBSCAN GRACE pubmed 1\n",
      "HDBSCAN GRACE pubmed 2\n",
      "HDBSCAN GRACE pubmed 3\n",
      "HDBSCAN GRACE pubmed 4\n",
      "HDBSCAN GRACE pubmed 5\n",
      "HDBSCAN GRACE pubmed 6\n",
      "HDBSCAN GRACE pubmed 7\n",
      "HDBSCAN GRACE pubmed 8\n",
      "HDBSCAN GRACE pubmed 9\n",
      "HDBSCAN GRACE amazon-photo 0\n",
      "HDBSCAN GRACE amazon-photo 1\n",
      "HDBSCAN GRACE amazon-photo 2\n",
      "HDBSCAN GRACE amazon-photo 3\n",
      "HDBSCAN GRACE amazon-photo 4\n",
      "HDBSCAN GRACE amazon-photo 5\n",
      "HDBSCAN GRACE amazon-photo 6\n",
      "HDBSCAN GRACE amazon-photo 7\n",
      "HDBSCAN GRACE amazon-photo 8\n",
      "HDBSCAN GRACE amazon-photo 9\n",
      "HDBSCAN GRACE amazon-computers 0\n",
      "HDBSCAN GRACE amazon-computers 1\n",
      "HDBSCAN GRACE amazon-computers 2\n",
      "HDBSCAN GRACE amazon-computers 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 5/6 [00:01<00:00,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HDBSCAN GRACE amazon-computers 4\n",
      "HDBSCAN GRACE amazon-computers 5\n",
      "HDBSCAN GRACE amazon-computers 6\n",
      "HDBSCAN GRACE amazon-computers 7\n",
      "HDBSCAN GRACE amazon-computers 8\n",
      "HDBSCAN GRACE amazon-computers 9\n",
      "Mean-shift GRACE cora 0\n",
      "Mean-shift GRACE cora 1\n",
      "Mean-shift GRACE cora 2\n",
      "Mean-shift GRACE cora 3\n",
      "Mean-shift GRACE cora 4\n",
      "Mean-shift GRACE cora 5\n",
      "Mean-shift GRACE cora 6\n",
      "Mean-shift GRACE cora 7\n",
      "Mean-shift GRACE cora 8\n",
      "Mean-shift GRACE cora 9\n",
      "Mean-shift GRACE citeseer 0\n",
      "Mean-shift GRACE citeseer 1\n",
      "Mean-shift GRACE citeseer 2\n",
      "Mean-shift GRACE citeseer 3\n",
      "Mean-shift GRACE citeseer 4\n",
      "Mean-shift GRACE citeseer 5\n",
      "Mean-shift GRACE citeseer 6\n",
      "Mean-shift GRACE citeseer 7\n",
      "Mean-shift GRACE citeseer 8\n",
      "Mean-shift GRACE citeseer 9\n",
      "Mean-shift GRACE wiki 0\n",
      "Mean-shift GRACE wiki 1\n",
      "Mean-shift GRACE wiki 2\n",
      "Mean-shift GRACE wiki 3\n",
      "Mean-shift GRACE wiki 4\n",
      "Mean-shift GRACE wiki 5\n",
      "Mean-shift GRACE wiki 6\n",
      "Mean-shift GRACE wiki 7\n",
      "Mean-shift GRACE wiki 8\n",
      "Mean-shift GRACE wiki 9\n",
      "Mean-shift GRACE pubmed 0\n",
      "Mean-shift GRACE pubmed 1\n",
      "Mean-shift GRACE pubmed 2\n",
      "Mean-shift GRACE pubmed 3\n",
      "Mean-shift GRACE pubmed 4\n",
      "Mean-shift GRACE pubmed 5\n",
      "Mean-shift GRACE pubmed 6\n",
      "Mean-shift GRACE pubmed 7\n",
      "Mean-shift GRACE pubmed 8\n",
      "Mean-shift GRACE pubmed 9\n",
      "Mean-shift GRACE amazon-photo 0\n",
      "Mean-shift GRACE amazon-photo 1\n",
      "Mean-shift GRACE amazon-photo 2\n",
      "Mean-shift GRACE amazon-photo 3\n",
      "Mean-shift GRACE amazon-photo 4\n",
      "Mean-shift GRACE amazon-photo 5\n",
      "Mean-shift GRACE amazon-photo 6\n",
      "Mean-shift GRACE amazon-photo 7\n",
      "Mean-shift GRACE amazon-photo 8\n",
      "Mean-shift GRACE amazon-photo 9\n",
      "Mean-shift GRACE amazon-computers 0\n",
      "Mean-shift GRACE amazon-computers 1\n",
      "Mean-shift GRACE amazon-computers 2\n",
      "Mean-shift GRACE amazon-computers 3\n",
      "Mean-shift GRACE amazon-computers 4\n",
      "Mean-shift GRACE amazon-computers 5\n",
      "Mean-shift GRACE amazon-computers 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:02<00:00,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean-shift GRACE amazon-computers 7\n",
      "Mean-shift GRACE amazon-computers 8\n",
      "Mean-shift GRACE amazon-computers 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import normalized_mutual_info_score as NMI, adjusted_mutual_info_score as AMI, adjusted_rand_score as ARI\n",
    "from tqdm import tqdm\n",
    "\n",
    "seeds = np.arange(10, dtype=int)\n",
    "for model in tqdm(models, total=len(models)):\n",
    "    for dataset in datasets:\n",
    "        nmis, amis, aris = [], [], []\n",
    "        nclasses = []\n",
    "        for seed in seeds:\n",
    "            emb_model = emb_models[0]\n",
    "            \n",
    "            print(model, emb_model, dataset, seed)\n",
    "            \n",
    "            try:\n",
    "                emb_name = os.path.join(\"{}/outputs_tsne\".format(model), \"{}_{}_{}.npz\".format(emb_model, dataset, seed))\n",
    "                data = np.load(emb_name)\n",
    "\n",
    "                preds = data[\"preds\"]\n",
    "                labels = true_labels[dataset]\n",
    "\n",
    "                nmi = NMI(labels, preds)\n",
    "                ami = AMI(labels, preds)\n",
    "                ari = ARI(labels, preds)\n",
    "                nclass = np.unique(preds).shape[0]\n",
    "                \n",
    "                nmis.append(nmi)\n",
    "                amis.append(ami)\n",
    "                aris.append(ari)\n",
    "                nclasses.append(nclass)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                \n",
    "        try:\n",
    "            nmi_m = np.mean(nmis)\n",
    "            ami_m = np.mean(amis)\n",
    "            ari_m = np.mean(aris)\n",
    "            nclass_m = np.mean(nclasses)\n",
    "\n",
    "            df_nmi[dataset][models.index(model)] = nmi_m\n",
    "            df_ami[dataset][models.index(model)] = ami_m\n",
    "            df_ari[dataset][models.index(model)] = ari_m \n",
    "            df_nclass[dataset][models.index(model)] = nclass_m\n",
    "        except Exception as e:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "699e6a67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>models</th>\n",
       "      <th>cora</th>\n",
       "      <th>citeseer</th>\n",
       "      <th>wiki</th>\n",
       "      <th>pubmed</th>\n",
       "      <th>amazon-photo</th>\n",
       "      <th>amazon-computers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KMeans</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SC-F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AP</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HCA</td>\n",
       "      <td>0.544437</td>\n",
       "      <td>0.333785</td>\n",
       "      <td>0.487907</td>\n",
       "      <td>0.263968</td>\n",
       "      <td>0.677993</td>\n",
       "      <td>0.503526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HDBSCAN</td>\n",
       "      <td>0.494273</td>\n",
       "      <td>0.268579</td>\n",
       "      <td>0.463944</td>\n",
       "      <td>0.224133</td>\n",
       "      <td>0.641777</td>\n",
       "      <td>0.53434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mean-shift</td>\n",
       "      <td>0.540815</td>\n",
       "      <td>0.348474</td>\n",
       "      <td>0.474763</td>\n",
       "      <td>0.277176</td>\n",
       "      <td>0.649011</td>\n",
       "      <td>0.474687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       models      cora  citeseer      wiki    pubmed amazon-photo  \\\n",
       "0      KMeans       NaN       NaN       NaN       NaN          NaN   \n",
       "1        SC-F       NaN       NaN       NaN       NaN          NaN   \n",
       "2          AP      -0.0       0.0      -0.0       0.0          0.0   \n",
       "3         HCA  0.544437  0.333785  0.487907  0.263968     0.677993   \n",
       "4     HDBSCAN  0.494273  0.268579  0.463944  0.224133     0.641777   \n",
       "5  Mean-shift  0.540815  0.348474  0.474763  0.277176     0.649011   \n",
       "\n",
       "  amazon-computers  \n",
       "0              NaN  \n",
       "1              NaN  \n",
       "2             -0.0  \n",
       "3         0.503526  \n",
       "4          0.53434  \n",
       "5         0.474687  "
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "608f47a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>models</th>\n",
       "      <th>cora</th>\n",
       "      <th>citeseer</th>\n",
       "      <th>wiki</th>\n",
       "      <th>pubmed</th>\n",
       "      <th>amazon-photo</th>\n",
       "      <th>amazon-computers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KMeans</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SC-F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HCA</td>\n",
       "      <td>0.467754</td>\n",
       "      <td>0.307182</td>\n",
       "      <td>0.329852</td>\n",
       "      <td>0.210744</td>\n",
       "      <td>0.57276</td>\n",
       "      <td>0.346754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HDBSCAN</td>\n",
       "      <td>0.385956</td>\n",
       "      <td>0.140811</td>\n",
       "      <td>0.265682</td>\n",
       "      <td>0.11981</td>\n",
       "      <td>0.490928</td>\n",
       "      <td>0.259422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mean-shift</td>\n",
       "      <td>0.485187</td>\n",
       "      <td>0.345441</td>\n",
       "      <td>0.329782</td>\n",
       "      <td>0.269545</td>\n",
       "      <td>0.564122</td>\n",
       "      <td>0.359291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       models      cora  citeseer      wiki    pubmed amazon-photo  \\\n",
       "0      KMeans       NaN       NaN       NaN       NaN          NaN   \n",
       "1        SC-F       NaN       NaN       NaN       NaN          NaN   \n",
       "2          AP       0.0       0.0       0.0       0.0          0.0   \n",
       "3         HCA  0.467754  0.307182  0.329852  0.210744      0.57276   \n",
       "4     HDBSCAN  0.385956  0.140811  0.265682   0.11981     0.490928   \n",
       "5  Mean-shift  0.485187  0.345441  0.329782  0.269545     0.564122   \n",
       "\n",
       "  amazon-computers  \n",
       "0              NaN  \n",
       "1              NaN  \n",
       "2              0.0  \n",
       "3         0.346754  \n",
       "4         0.259422  \n",
       "5         0.359291  "
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "7313a5b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>models</th>\n",
       "      <th>cora</th>\n",
       "      <th>citeseer</th>\n",
       "      <th>wiki</th>\n",
       "      <th>pubmed</th>\n",
       "      <th>amazon-photo</th>\n",
       "      <th>amazon-computers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KMeans</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SC-F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AP</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HCA</td>\n",
       "      <td>0.542373</td>\n",
       "      <td>0.332051</td>\n",
       "      <td>0.475858</td>\n",
       "      <td>0.26384</td>\n",
       "      <td>0.677371</td>\n",
       "      <td>0.50299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HDBSCAN</td>\n",
       "      <td>0.491971</td>\n",
       "      <td>0.265728</td>\n",
       "      <td>0.448063</td>\n",
       "      <td>0.222935</td>\n",
       "      <td>0.640074</td>\n",
       "      <td>0.531917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mean-shift</td>\n",
       "      <td>0.539081</td>\n",
       "      <td>0.347234</td>\n",
       "      <td>0.46486</td>\n",
       "      <td>0.277098</td>\n",
       "      <td>0.648455</td>\n",
       "      <td>0.474202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       models      cora  citeseer      wiki    pubmed amazon-photo  \\\n",
       "0      KMeans       NaN       NaN       NaN       NaN          NaN   \n",
       "1        SC-F       NaN       NaN       NaN       NaN          NaN   \n",
       "2          AP      -0.0       0.0      -0.0       0.0          0.0   \n",
       "3         HCA  0.542373  0.332051  0.475858   0.26384     0.677371   \n",
       "4     HDBSCAN  0.491971  0.265728  0.448063  0.222935     0.640074   \n",
       "5  Mean-shift  0.539081  0.347234   0.46486  0.277098     0.648455   \n",
       "\n",
       "  amazon-computers  \n",
       "0              NaN  \n",
       "1              NaN  \n",
       "2             -0.0  \n",
       "3          0.50299  \n",
       "4         0.531917  \n",
       "5         0.474202  "
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "53a268ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>models</th>\n",
       "      <th>cora</th>\n",
       "      <th>citeseer</th>\n",
       "      <th>wiki</th>\n",
       "      <th>pubmed</th>\n",
       "      <th>amazon-photo</th>\n",
       "      <th>amazon-computers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KMeans</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SC-F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HCA</td>\n",
       "      <td>8.8</td>\n",
       "      <td>7.4</td>\n",
       "      <td>18.8</td>\n",
       "      <td>5.9</td>\n",
       "      <td>9.5</td>\n",
       "      <td>7.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HDBSCAN</td>\n",
       "      <td>8.3</td>\n",
       "      <td>10.4</td>\n",
       "      <td>23.7</td>\n",
       "      <td>65.3</td>\n",
       "      <td>24.3</td>\n",
       "      <td>38.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mean-shift</td>\n",
       "      <td>7.4</td>\n",
       "      <td>5.3</td>\n",
       "      <td>14.7</td>\n",
       "      <td>3.4</td>\n",
       "      <td>7.8</td>\n",
       "      <td>6.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       models cora citeseer  wiki pubmed amazon-photo amazon-computers\n",
       "0      KMeans  NaN      NaN   NaN    NaN          NaN              NaN\n",
       "1        SC-F  NaN      NaN   NaN    NaN          NaN              NaN\n",
       "2          AP  1.0      1.0   1.0    1.0          1.0              1.0\n",
       "3         HCA  8.8      7.4  18.8    5.9          9.5              7.8\n",
       "4     HDBSCAN  8.3     10.4  23.7   65.3         24.3             38.9\n",
       "5  Mean-shift  7.4      5.3  14.7    3.4          7.8              6.3"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a623ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7675ea6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7217c00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82139702",
   "metadata": {},
   "source": [
    "## New baselines: SUBLIME, SLAP-S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "416a0ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"SUBLIME\"]\n",
    "graph_learners = [\"fgp\"]\n",
    "models_ = [models[0]+\"-\"+x for x in graph_learners]\n",
    "datasets = [\"pubmed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "58137503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>models</th>\n",
       "      <th>pubmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SUBLIME-mlp</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        models pubmed\n",
       "0  SUBLIME-mlp    NaN"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data={\"models\":models_}, columns=[\"models\"]+datasets)\n",
    "df_nmi = df.copy()\n",
    "df_ami = df.copy()\n",
    "df_ari = df.copy()\n",
    "df_edges = df.copy()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "9db3093f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUBLIME pubmed 0\n",
      "SUBLIME pubmed 1\n",
      "SUBLIME pubmed 2\n",
      "SUBLIME pubmed 3\n",
      "SUBLIME pubmed 4\n",
      "SUBLIME pubmed 5\n",
      "SUBLIME pubmed 6\n",
      "SUBLIME pubmed 7\n",
      "SUBLIME pubmed 8\n",
      "SUBLIME pubmed 9\n",
      "SUBLIME pubmed 0\n",
      "SUBLIME pubmed 1\n",
      "SUBLIME pubmed 2\n",
      "SUBLIME pubmed 3\n",
      "SUBLIME pubmed 4\n",
      "SUBLIME pubmed 5\n",
      "SUBLIME pubmed 6\n",
      "SUBLIME pubmed 7\n",
      "SUBLIME pubmed 8\n",
      "SUBLIME pubmed 9\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import scipy.sparse as sp\n",
    "\n",
    "for model_idx, model in enumerate(models):\n",
    "    for graph_learner_idx, graph_learner in enumerate(graph_learners):\n",
    "        for dataset in datasets:\n",
    "            nseed=10\n",
    "            labels = true_labels[dataset]\n",
    "\n",
    "            nmis, amis, aris, edges = [], [], [], []\n",
    "            for seed in range(nseed):\n",
    "                print(model, dataset, seed)\n",
    "\n",
    "                np.random.seed(seed)\n",
    "                random.seed(seed)\n",
    "\n",
    "                data = np.load(\"{}/outputs/learned_adj_{}_{}_{}.npz\".format(model, graph_learner, dataset, seed))\n",
    "                adj_data, adj_row, adj_col = data[\"data\"], data[\"row\"], data[\"col\"]\n",
    "\n",
    "                adj = sp.coo_matrix((adj_data, (adj_row, adj_col)), shape=(labels.shape[0], labels.shape[0]))\n",
    "                adj.eliminate_zeros()\n",
    "\n",
    "                edges.append(adj.sum())\n",
    "\n",
    "            df_edges[\"{}\".format(dataset)][graph_learner_idx] = np.mean(edges)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "57b00516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>models</th>\n",
       "      <th>pubmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SUBLIME-att</td>\n",
       "      <td>210164.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SUBLIME-mlp</td>\n",
       "      <td>385797.40625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        models        pubmed\n",
       "0  SUBLIME-att     210164.75\n",
       "1  SUBLIME-mlp  385797.40625"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f597eedd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d988062e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def louvain_cluster(adj, labels, random_state=None):\n",
    "    from community import community_louvain\n",
    "    import networkx as nx\n",
    "    from sklearn.metrics import normalized_mutual_info_score as NMI, adjusted_mutual_info_score as AMI\n",
    "\n",
    "    graph = nx.from_scipy_sparse_matrix(adj)\n",
    "    partition = community_louvain.best_partition(graph, random_state=random_state)\n",
    "    preds = list(partition.values())\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "21ff5fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "def sampling(adj, rate=0.5):\n",
    "    n = adj.shape[0]\n",
    "    adj = adj.toarray()\n",
    "    \n",
    "    ret = np.zeros((n,n))\n",
    "    \n",
    "    for i in range(n):\n",
    "        row_idx = adj[i].nonzero()[0]\n",
    "        arr = np.random.choice(row_idx, int(rate*row_idx.shape[0]))\n",
    "        ret[i][arr] = 1\n",
    "    \n",
    "    return sp.coo_matrix(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10aec5d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d6ed69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42e4401",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "3fe35e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values([0.12683826257573305, 0.13246301755903395, 0.13279640394319814, 0.131966020199843, 0.13155560782339473, 0.13333153686344315, 0.13226083705010203, 0.1319178137020473, 0.13332282826291197, 0.13287921949533482])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1400x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import scipy.sparse as sp\n",
    "from sklearn.metrics import normalized_mutual_info_score as NMI, adjusted_mutual_info_score as AMI, adjusted_rand_score as ARI\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, len(datasets), figsize=(14,2))\n",
    "\n",
    "xx = np.arange(1, 11, dtype=int).tolist()\n",
    "xx = [str(x) + \"m\" for x in xx]\n",
    "df_data_nmi = pd.DataFrame(columns=[\"models\", \"dataset\"]+xx)\n",
    "df_data_ami = pd.DataFrame(columns=[\"models\", \"dataset\"]+xx)\n",
    "df_data_ari = pd.DataFrame(columns=[\"models\", \"dataset\"]+xx)\n",
    "\n",
    "for model_idx, model in enumerate(models):\n",
    "    for graph_learner_idx, graph_learner in enumerate(graph_learners):\n",
    "        model_ = model+\"-\"+graph_learner\n",
    "        for dataset in datasets:\n",
    "            nseed=10\n",
    "            labels = true_labels[dataset]\n",
    "\n",
    "            nmi_m, ami_m, ari_m, nclass_m = {}, {}, {}, {}\n",
    "\n",
    "            edges = np.arange(num_edges[dataset], 11*num_edges[dataset], num_edges[dataset], dtype=int)\n",
    "            for m_idx, m in enumerate(edges):\n",
    "                nmis, amis, aris, nclasses = [], [], [], []\n",
    "\n",
    "                for seed in range(nseed):\n",
    "                    np.random.seed(seed)\n",
    "                    random.seed(seed)\n",
    "\n",
    "#                     print(model, dataset, m_idx, seed)\n",
    "\n",
    "                    try:\n",
    "                        data = np.load(\"{}/Cluster_new/{}/lo_{}_preds_{}_{}.npz\".format(model, graph_learner, dataset, seed, m))\n",
    "                        preds = data[\"preds\"]\n",
    "                        \n",
    "                        labels = true_labels[dataset]\n",
    "\n",
    "                        nmi = NMI(labels, preds)\n",
    "                        ami = AMI(labels, preds)\n",
    "                        ari = ARI(labels, preds)\n",
    "                        nclass = np.unique(preds).shape[0]\n",
    "\n",
    "                        nmis.append(nmi)\n",
    "                        amis.append(ami)\n",
    "                        aris.append(ari)\n",
    "                        nclasses.append(nclass)\n",
    "\n",
    "                    except Exception as e:\n",
    "#                         data = np.load(\"{}/outputs/learned_adj_{}_{}_{}.npz\".format(model, graph_learner, dataset, seed))\n",
    "#                         adj_data, adj_row, adj_col = data[\"data\"], data[\"row\"], data[\"col\"]\n",
    "\n",
    "#                         adj = sp.coo_matrix((adj_data, (adj_row, adj_col)), shape=(labels.shape[0], labels.shape[0]))\n",
    "#                         adj.eliminate_zeros()\n",
    "                        \n",
    "#                         sampling_rate=m / adj.sum()\n",
    "#                         adj_s = sampling(adj, rate=sampling_rate)\n",
    "                        \n",
    "#                         preds = louvain_cluster(adj_s, labels, random_state=seed)\n",
    "                        \n",
    "#                         os.makedirs(\"{}/Cluster/{}\".format(model, graph_learner), exist_ok=True)\n",
    "#                         np.savez(\"{}/Cluster/{}/lo_{}_preds_{}_{}.npz\".format(model, graph_learner, dataset, seed, m), preds=preds)\n",
    "                        \n",
    "                        \n",
    "                        pass\n",
    "    #                     print(e)\n",
    "                    \n",
    "\n",
    "                if len(nmis) > 0:\n",
    "                    nmi_m[m] = np.mean(nmis)\n",
    "                    ami_m[m] = np.mean(amis)\n",
    "                    ari_m[m] = np.mean(aris)\n",
    "                    nclass_m[m] = np.mean(nclasses)\n",
    "                    \n",
    "            try:\n",
    "                new_line = pd.DataFrame([[model_, dataset] + list(nmi_m.values())], columns=df_data_nmi.columns)\n",
    "                df_data_nmi = pd.concat([df_data_nmi, new_line])\n",
    "\n",
    "                new_line = pd.DataFrame([[model_, dataset] + list(ami_m.values())], columns=df_data_ami.columns)\n",
    "                df_data_ami = pd.concat([df_data_ami, new_line])\n",
    "\n",
    "                new_line = pd.DataFrame([[model_, dataset] + list(ari_m.values())], columns=df_data_ari.columns)\n",
    "                df_data_ari = pd.concat([df_data_ari, new_line])\n",
    "                print(nmi_m.values())\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                pass\n",
    "\n",
    "df_data_nmi.to_csv(\"SUBLIME_baseline_NMI.csv\", index=False)\n",
    "df_data_ami.to_csv(\"SUBLIME_baseline_AMI.csv\", index=False)\n",
    "df_data_ari.to_csv(\"SUBLIME_baseline_ARI.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57029725",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845c51c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import scipy.sparse as sp\n",
    "\n",
    "for model_idx, model in enumerate(models):\n",
    "    for dataset in datasets:\n",
    "        nseed=10\n",
    "        labels = true_labels[dataset]\n",
    "        \n",
    "        nmis, amis, aris, edges = [], [], [], []\n",
    "        for seed in range(nseed):\n",
    "            print(model, dataset, seed)\n",
    "            \n",
    "            np.random.seed(seed)\n",
    "            random.seed(seed)\n",
    "            \n",
    "            data = np.load(\"{}/outputs/learned_adj_{}_{}.npz\".format(model, dataset, seed))\n",
    "            adj_data, adj_row, adj_col = data[\"data\"], data[\"row\"], data[\"col\"]\n",
    "            \n",
    "            adj = sp.coo_matrix((adj_data, (adj_row, adj_col)), shape=(labels.shape[0], labels.shape[0]))\n",
    "            adj.eliminate_zeros()\n",
    "            \n",
    "            edges.append(adj.sum())\n",
    "        \n",
    "        df_edges[\"{}\".format(dataset)][model_idx] = np.mean(edges)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a045bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a28970",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a863ca9",
   "metadata": {},
   "source": [
    "## NEW baseline: KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef2803d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"KNN\"\n",
    "datasets = [\"cora\", \"citeseer\", \"wiki\", \"pubmed\", \"amazon-photo\", \"amazon-computers\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b18212c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3504665599600011\n",
      "0.1967935894436156\n",
      "0.3274109754306123\n",
      "0.09857601849621575\n",
      "0.5435443464384394\n",
      "0.3107441371792515\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1400x200 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import scipy.sparse as sp\n",
    "from sklearn.metrics import normalized_mutual_info_score as NMI, adjusted_mutual_info_score as AMI, adjusted_rand_score as ARI\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, len(datasets), figsize=(14,2))\n",
    "\n",
    "xx = np.arange(1, 11, dtype=int).tolist()\n",
    "xx = [str(x) + \"m\" for x in xx]\n",
    "df_data_nmi = pd.DataFrame(columns=[\"models\", \"dataset\"]+xx)\n",
    "df_data_ami = pd.DataFrame(columns=[\"models\", \"dataset\"]+xx)\n",
    "df_data_ari = pd.DataFrame(columns=[\"models\", \"dataset\"]+xx)\n",
    "\n",
    "for dataset in datasets:\n",
    "    nseed=10\n",
    "    labels = true_labels[dataset]\n",
    "\n",
    "    nmi_m, ami_m, ari_m, nclass_m = {}, {}, {}, {}\n",
    "\n",
    "#     edges = np.arange(num_edges[dataset], 11*num_edges[dataset], num_edges[dataset], dtype=int)\n",
    "    sampling_rates = np.arange(1.0, 11.0, 1.0, dtype=int)\n",
    "#     for m_idx, m in enumerate(edges):\n",
    "    for sampling_rate in sampling_rates:\n",
    "        nmis, amis, aris, nclasses = [], [], [], []\n",
    "\n",
    "        for seed in range(nseed):\n",
    "            np.random.seed(seed)\n",
    "            random.seed(seed)\n",
    "\n",
    "\n",
    "            try:\n",
    "                data = np.load(\"{}/Cluster/GRACE/lo_{}_preds_{}_{:.1f}.npz\".format(model, dataset, seed, sampling_rate))\n",
    "                preds = data[\"preds\"]\n",
    "                labels = true_labels[dataset]\n",
    "\n",
    "                nmi = NMI(labels, preds)\n",
    "                ami = AMI(labels, preds)\n",
    "                ari = ARI(labels, preds)\n",
    "                nclass = np.unique(preds).shape[0]\n",
    "\n",
    "                nmis.append(nmi)\n",
    "                amis.append(ami)\n",
    "                aris.append(ari)\n",
    "                nclasses.append(nclass)\n",
    "\n",
    "            except Exception as e: \n",
    "#                 print(e)\n",
    "                pass\n",
    "                    \n",
    "\n",
    "        if len(nmis) > 0:\n",
    "            nmi_m[sampling_rate] = np.mean(nmis)\n",
    "            ami_m[sampling_rate] = np.mean(amis)\n",
    "            ari_m[sampling_rate] = np.mean(aris)\n",
    "            nclass_m[sampling_rate] = np.mean(nclasses)\n",
    "                    \n",
    "#     try:\n",
    "#         new_line = pd.DataFrame([[model_, dataset] + list(nmi_m.values())], columns=df_data_nmi.columns)\n",
    "#         df_data_nmi = pd.concat([df_data_nmi, new_line])\n",
    "\n",
    "#         new_line = pd.DataFrame([[model_, dataset] + list(ami_m.values())], columns=df_data_ami.columns)\n",
    "#         df_data_ami = pd.concat([df_data_ami, new_line])\n",
    "\n",
    "#         new_line = pd.DataFrame([[model_, dataset] + list(ari_m.values())], columns=df_data_ari.columns)\n",
    "#         df_data_ari = pd.concat([df_data_ari, new_line])\n",
    "#         print(ari_m)\n",
    "#     except Exception as e:\n",
    "#         print(e)\n",
    "#         pass\n",
    "    print(ari_m[10])\n",
    "\n",
    "df_data_nmi.to_csv(\"KNN_baseline_NMI.csv\", index=False)\n",
    "df_data_ami.to_csv(\"KNN_baseline_AMI.csv\", index=False)\n",
    "df_data_ari.to_csv(\"KNN_baseline_ARI.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e635ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import scipy.sparse as sp\n",
    "from sklearn.metrics import normalized_mutual_info_score as NMI, adjusted_mutual_info_score as AMI, adjusted_rand_score as ARI\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, len(datasets), figsize=(14,2))\n",
    "\n",
    "xx = np.arange(1, 11, dtype=int).tolist()\n",
    "xx = [str(x) + \"m\" for x in xx]\n",
    "df_data_nmi = pd.DataFrame(columns=[\"models\", \"dataset\"]+xx)\n",
    "df_data_ami = pd.DataFrame(columns=[\"models\", \"dataset\"]+xx)\n",
    "df_data_ari = pd.DataFrame(columns=[\"models\", \"dataset\"]+xx)\n",
    "\n",
    "for dataset in datasets:\n",
    "    nseed=10\n",
    "    labels = true_labels[dataset]\n",
    "\n",
    "    nmi_m, ami_m, ari_m, nclass_m = {}, {}, {}, {}\n",
    "\n",
    "#     edges = np.arange(num_edges[dataset], 11*num_edges[dataset], num_edges[dataset], dtype=int)\n",
    "    sampling_rates = np.arange(1.0, 11.0, 1.0, dtype=int)\n",
    "#     for m_idx, m in enumerate(edges):\n",
    "    for sampling_rate in sampling_rates:\n",
    "        nmis, amis, aris, nclasses = [], [], [], []\n",
    "\n",
    "        for seed in range(nseed):\n",
    "            np.random.seed(seed)\n",
    "            random.seed(seed)\n",
    "\n",
    "\n",
    "            try:\n",
    "                data = np.load(\"{}/Cluster_leiden/GRACE/lo_{}_preds_{}_{:.1f}.npz\".format(model, dataset, seed, sampling_rate))\n",
    "                preds = data[\"preds\"]\n",
    "                labels = true_labels[dataset]\n",
    "\n",
    "                nmi = NMI(labels, preds)\n",
    "                ami = AMI(labels, preds)\n",
    "                ari = ARI(labels, preds)\n",
    "                nclass = np.unique(preds).shape[0]\n",
    "\n",
    "                nmis.append(nmi)\n",
    "                amis.append(ami)\n",
    "                aris.append(ari)\n",
    "                nclasses.append(nclass)\n",
    "\n",
    "            except Exception as e: \n",
    "#                 print(e)\n",
    "                pass\n",
    "                    \n",
    "\n",
    "        if len(nmis) > 0:\n",
    "            nmi_m[sampling_rate] = np.mean(nmis)\n",
    "            ami_m[sampling_rate] = np.mean(amis)\n",
    "            ari_m[sampling_rate] = np.mean(aris)\n",
    "            nclass_m[sampling_rate] = np.mean(nclasses)\n",
    "                    \n",
    "#     try:\n",
    "#         new_line = pd.DataFrame([[model_, dataset] + list(nmi_m.values())], columns=df_data_nmi.columns)\n",
    "#         df_data_nmi = pd.concat([df_data_nmi, new_line])\n",
    "\n",
    "#         new_line = pd.DataFrame([[model_, dataset] + list(ami_m.values())], columns=df_data_ami.columns)\n",
    "#         df_data_ami = pd.concat([df_data_ami, new_line])\n",
    "\n",
    "#         new_line = pd.DataFrame([[model_, dataset] + list(ari_m.values())], columns=df_data_ari.columns)\n",
    "#         df_data_ari = pd.concat([df_data_ari, new_line])\n",
    "#         print(ari_m)\n",
    "#     except Exception as e:\n",
    "#         print(e)\n",
    "#         pass\n",
    "    print(ari_m[10])\n",
    "\n",
    "df_data_nmi.to_csv(\"KNN_baseline_NMI.csv\", index=False)\n",
    "df_data_ami.to_csv(\"KNN_baseline_AMI.csv\", index=False)\n",
    "df_data_ari.to_csv(\"KNN_baseline_ARI.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a95d034",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1704f3da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "277dc123",
   "metadata": {},
   "source": [
    "## New baseline: GAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "5d049122",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"GAE\"\n",
    "datasets = [\"cora\", \"citeseer\", \"wiki\", \"pubmed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "f3fabd3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values([21.0, 10.0, 6.0, 5.0, 5.0, 6.0, 4.0, 5.0, 5.0, 6.0])\n",
      "dict_values([17.0, 13.0, 6.0, 5.0, 6.0, 5.0, 4.0, 4.0, 4.0, 4.0])\n",
      "dict_values([4.0, 3.0, 4.0, 4.0, 3.0, 3.0, 4.0, 3.0, 3.0, 3.0])\n",
      "dict_values([16.0, 5.0, 4.0, 4.0, 4.0, 3.0, 4.0, 3.0, 4.0, 3.0])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1400x200 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import scipy.sparse as sp\n",
    "from sklearn.metrics import normalized_mutual_info_score as NMI, adjusted_mutual_info_score as AMI, adjusted_rand_score as ARI\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, len(datasets), figsize=(14,2))\n",
    "\n",
    "xx = np.arange(1, 11, dtype=int).tolist()\n",
    "xx = [str(x) + \"m\" for x in xx]\n",
    "df_data_nmi = pd.DataFrame(columns=[\"models\", \"dataset\"]+xx)\n",
    "df_data_ami = pd.DataFrame(columns=[\"models\", \"dataset\"]+xx)\n",
    "df_data_ari = pd.DataFrame(columns=[\"models\", \"dataset\"]+xx)\n",
    "\n",
    "for dataset in datasets:\n",
    "    nseed=10\n",
    "    labels = true_labels[dataset]\n",
    "\n",
    "    nmi_m, ami_m, ari_m, nclass_m = {}, {}, {}, {}\n",
    "\n",
    "#     edges = np.arange(num_edges[dataset], 11*num_edges[dataset], num_edges[dataset], dtype=int)\n",
    "    sampling_rates = np.arange(1.0, 11.0, 1.0, dtype=int)\n",
    "#     for m_idx, m in enumerate(edges):\n",
    "    for sampling_rate in sampling_rates:\n",
    "        nmis, amis, aris, nclasses = [], [], [], []\n",
    "\n",
    "        for seed in range(nseed):\n",
    "            np.random.seed(seed)\n",
    "            random.seed(seed)\n",
    "\n",
    "\n",
    "            try:\n",
    "                data = np.load(\"{}/Cluster/lo_{}_preds_{}_{:.1f}.npz\".format(model, dataset, seed, sampling_rate))\n",
    "                preds = data[\"preds\"]\n",
    "                labels = true_labels[dataset]\n",
    "\n",
    "                nmi = NMI(labels, preds)\n",
    "                ami = AMI(labels, preds)\n",
    "                ari = ARI(labels, preds)\n",
    "                nclass = np.unique(preds).shape[0]\n",
    "                        \n",
    "                nmis.append(nmi)\n",
    "                amis.append(ami)\n",
    "                aris.append(ari)\n",
    "                nclasses.append(nclass)\n",
    "                \n",
    "\n",
    "            except Exception as e: \n",
    "#                 print(e)\n",
    "                pass\n",
    "                    \n",
    "\n",
    "        if len(nmis) > 0:\n",
    "            nmi_m[sampling_rate] = np.mean(nmis)\n",
    "            ami_m[sampling_rate] = np.mean(amis)\n",
    "            ari_m[sampling_rate] = np.mean(aris)\n",
    "            nclass_m[sampling_rate] = np.mean(nclass)\n",
    "                    \n",
    "#     try:\n",
    "#         new_line = pd.DataFrame([[model_, dataset] + list(nmi_m.values())], columns=df_data_nmi.columns)\n",
    "#         df_data_nmi = pd.concat([df_data_nmi, new_line])\n",
    "\n",
    "#         new_line = pd.DataFrame([[model_, dataset] + list(ami_m.values())], columns=df_data_ami.columns)\n",
    "#         df_data_ami = pd.concat([df_data_ami, new_line])\n",
    "\n",
    "#         new_line = pd.DataFrame([[model_, dataset] + list(ari_m.values())], columns=df_data_ari.columns)\n",
    "#         df_data_ari = pd.concat([df_data_ari, new_line])\n",
    "#         print(ari_m)\n",
    "#     except Exception as e:\n",
    "#         print(e)\n",
    "#         pass\n",
    "    print(nclass_m.values())\n",
    "\n",
    "df_data_nmi.to_csv(\"GAE_baseline_NMI.csv\", index=False)\n",
    "df_data_ami.to_csv(\"GAE_baseline_AMI.csv\", index=False)\n",
    "df_data_ari.to_csv(\"GAE_baseline_ARI.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a1a7ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab88fb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8edb106b",
   "metadata": {},
   "source": [
    "## New baseline: ILouvain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "b08a8846",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\"cora\", \"citeseer\", \"wiki\", \"pubmed\", \"amazon-photo\", \"amazon-computers\"]\n",
    "model = \"ILouvain\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "5f4fa80f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cora 0\n",
      "cora 1\n",
      "cora 2\n",
      "cora 3\n",
      "cora 4\n",
      "cora 5\n",
      "cora 6\n",
      "cora 7\n",
      "cora 8\n",
      "cora 9\n",
      "citeseer 0\n",
      "citeseer 1\n",
      "citeseer 2\n",
      "citeseer 3\n",
      "citeseer 4\n",
      "citeseer 5\n",
      "citeseer 6\n",
      "citeseer 7\n",
      "citeseer 8\n",
      "citeseer 9\n",
      "wiki 0\n",
      "wiki 1\n",
      "wiki 2\n",
      "wiki 3\n",
      "wiki 4\n",
      "wiki 5\n",
      "wiki 6\n",
      "wiki 7\n",
      "wiki 8\n",
      "wiki 9\n",
      "pubmed 0\n",
      "pubmed 1\n",
      "pubmed 2\n",
      "pubmed 3\n",
      "pubmed 4\n",
      "pubmed 5\n",
      "pubmed 6\n",
      "pubmed 7\n",
      "pubmed 8\n",
      "pubmed 9\n",
      "amazon-photo 0\n",
      "amazon-photo 1\n",
      "amazon-photo 2\n",
      "amazon-photo 3\n",
      "amazon-photo 4\n",
      "amazon-photo 5\n",
      "amazon-photo 6\n",
      "amazon-photo 7\n",
      "amazon-photo 8\n",
      "amazon-photo 9\n",
      "amazon-computers 0\n",
      "amazon-computers 1\n",
      "amazon-computers 2\n",
      "amazon-computers 3\n",
      "amazon-computers 4\n",
      "amazon-computers 5\n",
      "amazon-computers 6\n",
      "amazon-computers 7\n",
      "amazon-computers 8\n",
      "amazon-computers 9\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df_data = pd.DataFrame({\"models\":[\"ILouvain\"]}, columns=[\"models\"] + datasets)\n",
    "df_data_nmi = df_data.copy()\n",
    "df_data_ami = df_data.copy()\n",
    "df_data_ari = df_data.copy()\n",
    "df_data_nclass = df_data.copy()\n",
    "\n",
    "\n",
    "for dataset in datasets:\n",
    "        nseed = 10\n",
    "        \n",
    "        nmis, amis, aris, nclasses = [], [], [], []\n",
    "\n",
    "        for seed in range(nseed):\n",
    "            print(dataset, seed)\n",
    "            try:\n",
    "                filename = \"{}/data/{}/{}_{}.2ModLouvain\".format(model, dataset, dataset, seed)\n",
    "                labels = true_labels[dataset]\n",
    "                \n",
    "                with open(filename, \"r\") as f:\n",
    "                    lines = f.readlines()\n",
    "                    \n",
    "                    if len(lines) != labels.shape[0]:\n",
    "                        print(\"Error: Not equal length!\")\n",
    "\n",
    "                preds = [int(x.strip().split(\" \")[1]) for x in lines]\n",
    "                \n",
    "\n",
    "\n",
    "                nmi = NMI(labels, preds)\n",
    "                ami = AMI(labels, preds)\n",
    "                ari = ARI(labels, preds)\n",
    "                nclass = np.unique(preds).shape[0]\n",
    "\n",
    "                nmis.append(nmi)\n",
    "                amis.append(ami)\n",
    "                aris.append(ari)\n",
    "                nclasses.append(nclass)\n",
    "            except Exception as e:\n",
    "                pass\n",
    "        \n",
    "        if len(nmis) > 0:\n",
    "            df_data_nmi[dataset][0] = np.mean(nmis)\n",
    "            df_data_ami[dataset][0] = np.mean(amis)\n",
    "            df_data_ari[dataset][0] = np.mean(aris)\n",
    "            df_data_nclass[dataset][0] = np.mean(nclasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "7d100aa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>models</th>\n",
       "      <th>cora</th>\n",
       "      <th>citeseer</th>\n",
       "      <th>wiki</th>\n",
       "      <th>pubmed</th>\n",
       "      <th>amazon-photo</th>\n",
       "      <th>amazon-computers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ILouvain</td>\n",
       "      <td>0.396106</td>\n",
       "      <td>0.338198</td>\n",
       "      <td>0.307528</td>\n",
       "      <td>0.181003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     models      cora  citeseer      wiki    pubmed amazon-photo  \\\n",
       "0  ILouvain  0.396106  0.338198  0.307528  0.181003          NaN   \n",
       "\n",
       "  amazon-computers  \n",
       "0              NaN  "
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data_nmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "0a2a445d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>models</th>\n",
       "      <th>cora</th>\n",
       "      <th>citeseer</th>\n",
       "      <th>wiki</th>\n",
       "      <th>pubmed</th>\n",
       "      <th>amazon-photo</th>\n",
       "      <th>amazon-computers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ILouvain</td>\n",
       "      <td>0.313071</td>\n",
       "      <td>0.205442</td>\n",
       "      <td>0.257537</td>\n",
       "      <td>0.160379</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     models      cora  citeseer      wiki    pubmed amazon-photo  \\\n",
       "0  ILouvain  0.313071  0.205442  0.257537  0.160379          NaN   \n",
       "\n",
       "  amazon-computers  \n",
       "0              NaN  "
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data_ami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "f025f4a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>models</th>\n",
       "      <th>cora</th>\n",
       "      <th>citeseer</th>\n",
       "      <th>wiki</th>\n",
       "      <th>pubmed</th>\n",
       "      <th>amazon-photo</th>\n",
       "      <th>amazon-computers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ILouvain</td>\n",
       "      <td>0.040802</td>\n",
       "      <td>0.016722</td>\n",
       "      <td>0.038273</td>\n",
       "      <td>0.037901</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     models      cora  citeseer      wiki    pubmed amazon-photo  \\\n",
       "0  ILouvain  0.040802  0.016722  0.038273  0.037901          NaN   \n",
       "\n",
       "  amazon-computers  \n",
       "0              NaN  "
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data_ari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "ef4d812a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>models</th>\n",
       "      <th>cora</th>\n",
       "      <th>citeseer</th>\n",
       "      <th>wiki</th>\n",
       "      <th>pubmed</th>\n",
       "      <th>amazon-photo</th>\n",
       "      <th>amazon-computers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ILouvain</td>\n",
       "      <td>387.0</td>\n",
       "      <td>889.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1541.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     models   cora citeseer  wiki  pubmed amazon-photo amazon-computers\n",
       "0  ILouvain  387.0    889.0  75.0  1541.0          NaN              NaN"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data_nclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba44cea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6e7c47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f5caee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "5608560b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cora 0\n",
      "cora 1\n",
      "cora 2\n",
      "cora 3\n",
      "cora 4\n",
      "cora 5\n",
      "cora 6\n",
      "cora 7\n",
      "cora 8\n",
      "cora 9\n",
      "citeseer 0\n",
      "citeseer 1\n",
      "citeseer 2\n",
      "citeseer 3\n",
      "citeseer 4\n",
      "citeseer 5\n",
      "citeseer 6\n",
      "citeseer 7\n",
      "citeseer 8\n",
      "citeseer 9\n",
      "wiki 0\n",
      "wiki 1\n",
      "wiki 2\n",
      "wiki 3\n",
      "wiki 4\n",
      "wiki 5\n",
      "wiki 6\n",
      "wiki 7\n",
      "wiki 8\n",
      "wiki 9\n",
      "pubmed 0\n",
      "pubmed 1\n",
      "pubmed 2\n",
      "pubmed 3\n",
      "pubmed 4\n",
      "pubmed 5\n",
      "pubmed 6\n",
      "pubmed 7\n",
      "pubmed 8\n",
      "pubmed 9\n",
      "amazon-photo 0\n",
      "[Errno 2] No such file or directory: 'ILouvain/data/amazon-photo/amazon-photo_0_emb.2ModLouvain'\n",
      "amazon-photo 1\n",
      "[Errno 2] No such file or directory: 'ILouvain/data/amazon-photo/amazon-photo_1_emb.2ModLouvain'\n",
      "amazon-photo 2\n",
      "[Errno 2] No such file or directory: 'ILouvain/data/amazon-photo/amazon-photo_2_emb.2ModLouvain'\n",
      "amazon-photo 3\n",
      "[Errno 2] No such file or directory: 'ILouvain/data/amazon-photo/amazon-photo_3_emb.2ModLouvain'\n",
      "amazon-photo 4\n",
      "[Errno 2] No such file or directory: 'ILouvain/data/amazon-photo/amazon-photo_4_emb.2ModLouvain'\n",
      "amazon-photo 5\n",
      "[Errno 2] No such file or directory: 'ILouvain/data/amazon-photo/amazon-photo_5_emb.2ModLouvain'\n",
      "amazon-photo 6\n",
      "[Errno 2] No such file or directory: 'ILouvain/data/amazon-photo/amazon-photo_6_emb.2ModLouvain'\n",
      "amazon-photo 7\n",
      "[Errno 2] No such file or directory: 'ILouvain/data/amazon-photo/amazon-photo_7_emb.2ModLouvain'\n",
      "amazon-photo 8\n",
      "[Errno 2] No such file or directory: 'ILouvain/data/amazon-photo/amazon-photo_8_emb.2ModLouvain'\n",
      "amazon-photo 9\n",
      "[Errno 2] No such file or directory: 'ILouvain/data/amazon-photo/amazon-photo_9_emb.2ModLouvain'\n",
      "amazon-computers 0\n",
      "[Errno 2] No such file or directory: 'ILouvain/data/amazon-computers/amazon-computers_0_emb.2ModLouvain'\n",
      "amazon-computers 1\n",
      "[Errno 2] No such file or directory: 'ILouvain/data/amazon-computers/amazon-computers_1_emb.2ModLouvain'\n",
      "amazon-computers 2\n",
      "[Errno 2] No such file or directory: 'ILouvain/data/amazon-computers/amazon-computers_2_emb.2ModLouvain'\n",
      "amazon-computers 3\n",
      "[Errno 2] No such file or directory: 'ILouvain/data/amazon-computers/amazon-computers_3_emb.2ModLouvain'\n",
      "amazon-computers 4\n",
      "[Errno 2] No such file or directory: 'ILouvain/data/amazon-computers/amazon-computers_4_emb.2ModLouvain'\n",
      "amazon-computers 5\n",
      "[Errno 2] No such file or directory: 'ILouvain/data/amazon-computers/amazon-computers_5_emb.2ModLouvain'\n",
      "amazon-computers 6\n",
      "[Errno 2] No such file or directory: 'ILouvain/data/amazon-computers/amazon-computers_6_emb.2ModLouvain'\n",
      "amazon-computers 7\n",
      "[Errno 2] No such file or directory: 'ILouvain/data/amazon-computers/amazon-computers_7_emb.2ModLouvain'\n",
      "amazon-computers 8\n",
      "[Errno 2] No such file or directory: 'ILouvain/data/amazon-computers/amazon-computers_8_emb.2ModLouvain'\n",
      "amazon-computers 9\n",
      "[Errno 2] No such file or directory: 'ILouvain/data/amazon-computers/amazon-computers_9_emb.2ModLouvain'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df_data = pd.DataFrame({\"models\":[\"ILouvain\"]}, columns=[\"models\"] + datasets)\n",
    "df_data_nmi = df_data.copy()\n",
    "df_data_ami = df_data.copy()\n",
    "df_data_ari = df_data.copy()\n",
    "df_data_nclass = df_data.copy()\n",
    "\n",
    "\n",
    "for dataset in datasets:\n",
    "        nseed = 10\n",
    "        \n",
    "        nmis, amis, aris, nclasses = [], [], [], []\n",
    "\n",
    "        for seed in range(nseed):\n",
    "            print(dataset, seed)\n",
    "            try:\n",
    "                filename = \"{}/data/{}/{}_{}_emb.2ModLouvain\".format(model, dataset, dataset, seed)\n",
    "                labels = true_labels[dataset]\n",
    "                \n",
    "                with open(filename, \"r\") as f:\n",
    "                    lines = f.readlines()\n",
    "                    \n",
    "                    if len(lines) != labels.shape[0]:\n",
    "                        print(\"Error: Not equal length!\")\n",
    "\n",
    "                preds = [int(x.strip().split(\" \")[1]) for x in lines]\n",
    "                \n",
    "\n",
    "\n",
    "                nmi = NMI(labels, preds)\n",
    "                ami = AMI(labels, preds)\n",
    "                ari = ARI(labels, preds)\n",
    "                nclass = np.unique(preds).shape[0]\n",
    "\n",
    "                nmis.append(nmi)\n",
    "                amis.append(ami)\n",
    "                aris.append(ari)\n",
    "                nclasses.append(nclass)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                pass\n",
    "        \n",
    "        if len(nmis) > 0:\n",
    "            df_data_nmi[dataset][0] = np.mean(nmis)\n",
    "            df_data_ami[dataset][0] = np.mean(amis)\n",
    "            df_data_ari[dataset][0] = np.mean(aris)\n",
    "            df_data_nclass[dataset][0] = np.mean(nclasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "7cccb7d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>models</th>\n",
       "      <th>cora</th>\n",
       "      <th>citeseer</th>\n",
       "      <th>wiki</th>\n",
       "      <th>pubmed</th>\n",
       "      <th>amazon-photo</th>\n",
       "      <th>amazon-computers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ILouvain</td>\n",
       "      <td>0.40352</td>\n",
       "      <td>0.339542</td>\n",
       "      <td>0.386219</td>\n",
       "      <td>0.179212</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     models     cora  citeseer      wiki    pubmed amazon-photo  \\\n",
       "0  ILouvain  0.40352  0.339542  0.386219  0.179212          NaN   \n",
       "\n",
       "  amazon-computers  \n",
       "0              NaN  "
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data_nmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "49d45944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>models</th>\n",
       "      <th>cora</th>\n",
       "      <th>citeseer</th>\n",
       "      <th>wiki</th>\n",
       "      <th>pubmed</th>\n",
       "      <th>amazon-photo</th>\n",
       "      <th>amazon-computers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ILouvain</td>\n",
       "      <td>0.307487</td>\n",
       "      <td>0.205851</td>\n",
       "      <td>0.326993</td>\n",
       "      <td>0.157833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     models      cora  citeseer      wiki    pubmed amazon-photo  \\\n",
       "0  ILouvain  0.307487  0.205851  0.326993  0.157833          NaN   \n",
       "\n",
       "  amazon-computers  \n",
       "0              NaN  "
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data_ami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "e44c3292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>models</th>\n",
       "      <th>cora</th>\n",
       "      <th>citeseer</th>\n",
       "      <th>wiki</th>\n",
       "      <th>pubmed</th>\n",
       "      <th>amazon-photo</th>\n",
       "      <th>amazon-computers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ILouvain</td>\n",
       "      <td>0.029653</td>\n",
       "      <td>0.015345</td>\n",
       "      <td>0.103502</td>\n",
       "      <td>0.023357</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     models      cora  citeseer      wiki    pubmed amazon-photo  \\\n",
       "0  ILouvain  0.029653  0.015345  0.103502  0.023357          NaN   \n",
       "\n",
       "  amazon-computers  \n",
       "0              NaN  "
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data_ari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "9bcf2f30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>models</th>\n",
       "      <th>cora</th>\n",
       "      <th>citeseer</th>\n",
       "      <th>wiki</th>\n",
       "      <th>pubmed</th>\n",
       "      <th>amazon-photo</th>\n",
       "      <th>amazon-computers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ILouvain</td>\n",
       "      <td>471.4</td>\n",
       "      <td>900.0</td>\n",
       "      <td>120.9</td>\n",
       "      <td>1631.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     models   cora citeseer   wiki  pubmed amazon-photo amazon-computers\n",
       "0  ILouvain  471.4    900.0  120.9  1631.5          NaN              NaN"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data_nclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c09954",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce2c157",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b5898a8",
   "metadata": {},
   "source": [
    "## KNN cora-full im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "761b056b",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    \"KNN\",\n",
    "#     \"SUBLIME\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "461bb895",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cora_full_im(rate=0.1, seed=None):\n",
    "    filename = \"/data/liuyue/New/SBM/mySBM/data_im/cora-full_{:.1f}_{:d}.npz\".format(rate, seed)\n",
    "    data = np.load(filename)\n",
    "\n",
    "    adj_raw, features_raw, labels_raw, _, _, _ = load_data(\"cora-full\")\n",
    "\n",
    "    adj_data, adj_row, adj_col, features_load, labels_load, mask = data[\"data\"], data[\"row\"], data[\"col\"], data[\"features\"], data[\"labels\"], data[\"mask\"]\n",
    "    adj_load = sp.coo_matrix((adj_data, (adj_row, adj_col)), shape=(labels_load.shape[0], labels_load.shape[0]))\n",
    "\n",
    "    adj_mask = adj_raw.toarray()[mask,:][:,mask]\n",
    "    assert (adj_mask - adj_load).sum() < 1e-7\n",
    "    features_mask = features_raw.toarray()[mask]\n",
    "    assert (features_mask - features_load).sum() < 1e-7\n",
    "\n",
    "    return adj_load, features_load, labels_load, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "511a5009",
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = np.arange(0, 3, dtype=int) # seed = {0,1,2}\n",
    "rates = np.arange(0.1, 1.0, 0.2) # minimum rention rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0cdad2b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN 0.1 0\n",
      "KNN 0.1 1\n",
      "KNN 0.1 2\n",
      "KNN 0.30000000000000004 0\n",
      "KNN 0.30000000000000004 1\n",
      "KNN 0.30000000000000004 2\n",
      "KNN 0.5000000000000001 0\n",
      "KNN 0.5000000000000001 1\n",
      "KNN 0.5000000000000001 2\n",
      "KNN 0.7000000000000001 0\n",
      "KNN 0.7000000000000001 1\n",
      "KNN 0.7000000000000001 2\n",
      "KNN 0.9000000000000001 0\n",
      "KNN 0.9000000000000001 1\n",
      "KNN 0.9000000000000001 2\n",
      "dict_values([0.40267541493272835, 0.523647167174917, 0.5910796417098164, 0.634785193060938, 0.6450385592332868])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import normalized_mutual_info_score as NMI, adjusted_mutual_info_score as AMI, adjusted_rand_score as ARI\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "for model in models:\n",
    "    \n",
    "    nmi_m, ami_m, ari_m = {}, {}, {}\n",
    "    \n",
    "    for rate in rates:\n",
    "        nmis, amis, aris = [], [], []\n",
    "        \n",
    "        \n",
    "            \n",
    "        for seed in seeds:\n",
    "            print(model, rate, seed)\n",
    "            \n",
    "            adj, features, labels, mask = load_cora_full_im(rate, seed)\n",
    "            \n",
    "            np.random.seed(seed)\n",
    "            torch.manual_seed(seed)\n",
    "            random.seed(seed)\n",
    "            torch.cuda.manual_seed(seed)  \n",
    "            \n",
    "            data = np.load(\"{}/Cluster_im/lo_preds_{:.1f}_{:d}.npz\".format(model, rate, seed))\n",
    "            preds = data[\"preds\"]\n",
    "            \n",
    "            nmi = NMI(labels, preds)\n",
    "            ami = AMI(labels, preds)\n",
    "            ari = ARI(labels, preds)\n",
    "            \n",
    "            nmis.append(nmi)\n",
    "            amis.append(ami)\n",
    "            aris.append(ari)\n",
    "            \n",
    "        nmi_m[rate] = np.mean(nmis)\n",
    "        ami_m[rate] = np.mean(amis)\n",
    "        ari_m[rate] = np.mean(aris)\n",
    "        \n",
    "#     print(nmi_m.values())\n",
    "#     print(ami_m.values())\n",
    "    print(ari_m.values())\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "78d9b8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN 0.1 0\n",
      "KNN 0.1 1\n",
      "KNN 0.1 2\n",
      "KNN 0.30000000000000004 0\n",
      "KNN 0.30000000000000004 1\n",
      "KNN 0.30000000000000004 2\n",
      "KNN 0.5000000000000001 0\n",
      "KNN 0.5000000000000001 1\n",
      "KNN 0.5000000000000001 2\n",
      "KNN 0.7000000000000001 0\n",
      "KNN 0.7000000000000001 1\n",
      "KNN 0.7000000000000001 2\n",
      "KNN 0.9000000000000001 0\n",
      "KNN 0.9000000000000001 1\n",
      "KNN 0.9000000000000001 2\n",
      "dict_values([0.5521181478043679, 0.6137178737592355, 0.6641068252487272, 0.6951086482601699, 0.7050576979226894])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import normalized_mutual_info_score as NMI, adjusted_mutual_info_score as AMI, adjusted_rand_score as ARI\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "for model in models:\n",
    "    \n",
    "    nmi_m, ami_m, ari_m = {}, {}, {}\n",
    "    \n",
    "    for rate in rates:\n",
    "        nmis, amis, aris = [], [], []\n",
    "        \n",
    "        \n",
    "            \n",
    "        for seed in seeds:\n",
    "            print(model, rate, seed)\n",
    "            \n",
    "            adj, features, labels, mask = load_cora_full_im(rate, seed)\n",
    "            \n",
    "            np.random.seed(seed)\n",
    "            torch.manual_seed(seed)\n",
    "            random.seed(seed)\n",
    "            torch.cuda.manual_seed(seed)  \n",
    "            \n",
    "            data = np.load(\"{}/Cluster_im/lo_preds_{:.1f}_{:d}.npz\".format(model, rate, seed))\n",
    "            preds = data[\"preds\"]\n",
    "            \n",
    "            nmi = NMI(labels, preds)\n",
    "            ami = AMI(labels, preds)\n",
    "            ari = ARI(labels, preds)\n",
    "            \n",
    "            nmis.append(nmi)\n",
    "            amis.append(ami)\n",
    "            aris.append(ari)\n",
    "            \n",
    "        nmi_m[rate] = np.mean(nmis)\n",
    "        ami_m[rate] = np.mean(amis)\n",
    "        ari_m[rate] = np.mean(aris)\n",
    "        \n",
    "#     print(nmi_m.values())\n",
    "#     print(ami_m.values())\n",
    "    print(ami_m.values())\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0788987c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9b5e6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a950e4c9",
   "metadata": {},
   "source": [
    "## KNN cora-full im 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b03b5e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    \"KNN\",\n",
    "#     \"SUBLIME\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6bfdcb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cora_full_im(rate=0.1, seed=None):\n",
    "    filename = \"/data/liuyue/New/SBM/mySBM/data_im/cora-full_{:.1f}_{:d}_5.npz\".format(rate, seed)\n",
    "    data = np.load(filename)\n",
    "\n",
    "    adj_raw, features_raw, labels_raw, _, _, _ = load_data(\"cora-full\")\n",
    "\n",
    "    adj_data, adj_row, adj_col, features_load, labels_load, mask = data[\"data\"], data[\"row\"], data[\"col\"], data[\"features\"], data[\"labels\"], data[\"mask\"]\n",
    "    adj_load = sp.coo_matrix((adj_data, (adj_row, adj_col)), shape=(labels_load.shape[0], labels_load.shape[0]))\n",
    "\n",
    "    adj_mask = adj_raw.toarray()[mask,:][:,mask]\n",
    "    assert (adj_mask - adj_load).sum() < 1e-7\n",
    "    features_mask = features_raw.toarray()[mask]\n",
    "    assert (features_mask - features_load).sum() < 1e-7\n",
    "\n",
    "    return adj_load, features_load, labels_load, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a79f4d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN 0.1 0\n",
      "KNN 0.1 1\n",
      "KNN 0.1 2\n",
      "KNN 0.30000000000000004 0\n",
      "KNN 0.30000000000000004 1\n",
      "KNN 0.30000000000000004 2\n",
      "KNN 0.5000000000000001 0\n",
      "KNN 0.5000000000000001 1\n",
      "KNN 0.5000000000000001 2\n",
      "KNN 0.7000000000000001 0\n",
      "KNN 0.7000000000000001 1\n",
      "KNN 0.7000000000000001 2\n",
      "KNN 0.9000000000000001 0\n",
      "KNN 0.9000000000000001 1\n",
      "KNN 0.9000000000000001 2\n",
      "dict_values([0.5305394217212321, 0.6118735145922625, 0.6427954098429701, 0.6907754899170427, 0.7119549998626667])\n"
     ]
    }
   ],
   "source": [
    "seeds = np.arange(0, 3, dtype=int) # seed = {0,1,2}\n",
    "rates = np.arange(0.1, 1.0, 0.2) # minimum rention rates\n",
    "from sklearn.metrics import normalized_mutual_info_score as NMI, adjusted_mutual_info_score as AMI, adjusted_rand_score as ARI\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "for model in models:\n",
    "    \n",
    "    nmi_m, ami_m, ari_m = {}, {}, {}\n",
    "    \n",
    "    for rate in rates:\n",
    "        nmis, amis, aris = [], [], []\n",
    "        \n",
    "        \n",
    "            \n",
    "        for seed in seeds:\n",
    "            print(model, rate, seed)\n",
    "            \n",
    "            adj, features, labels, mask = load_cora_full_im(rate, seed)\n",
    "            \n",
    "            np.random.seed(seed)\n",
    "            torch.manual_seed(seed)\n",
    "            random.seed(seed)\n",
    "            torch.cuda.manual_seed(seed)  \n",
    "            \n",
    "            data = np.load(\"{}/Cluster_im/lo_preds_MVGRL_{:.1f}_{:d}_5.npz\".format(model, rate, seed))\n",
    "            preds = data[\"preds\"]\n",
    "            \n",
    "            nmi = NMI(labels, preds)\n",
    "            ami = AMI(labels, preds)\n",
    "            ari = ARI(labels, preds)\n",
    "            \n",
    "            nmis.append(nmi)\n",
    "            amis.append(ami)\n",
    "            aris.append(ari)\n",
    "            \n",
    "        nmi_m[rate] = np.mean(nmis)\n",
    "        ami_m[rate] = np.mean(amis)\n",
    "        ari_m[rate] = np.mean(aris)\n",
    "        \n",
    "#     print(nmi_m.values())\n",
    "#     print(ami_m.values())\n",
    "    print(ari_m.values())\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "bdce3959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN 0.1 0\n",
      "KNN 0.30000000000000004 0\n",
      "KNN 0.5000000000000001 0\n",
      "KNN 0.7000000000000001 0\n",
      "KNN 0.9000000000000001 0\n",
      "dict_values([0.4353698392836347, 0.5322440341443901, 0.5815682590427402, 0.626713846066881, 0.6481211972111862])\n"
     ]
    }
   ],
   "source": [
    "seeds = np.arange(0, 1, dtype=int) # seed = {0,1,2}\n",
    "rates = np.arange(0.1, 1.0, 0.2) # minimum rention rates\n",
    "from sklearn.metrics import normalized_mutual_info_score as NMI, adjusted_mutual_info_score as AMI, adjusted_rand_score as ARI\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "for model in models:\n",
    "    \n",
    "    nmi_m, ami_m, ari_m = {}, {}, {}\n",
    "    \n",
    "    for rate in rates:\n",
    "        nmis, amis, aris = [], [], []\n",
    "        \n",
    "        \n",
    "            \n",
    "        for seed in seeds:\n",
    "            print(model, rate, seed)\n",
    "            \n",
    "            adj, features, labels, mask = load_cora_full_im(rate, seed)\n",
    "            \n",
    "            np.random.seed(seed)\n",
    "            torch.manual_seed(seed)\n",
    "            random.seed(seed)\n",
    "            torch.cuda.manual_seed(seed)  \n",
    "            \n",
    "            data = np.load(\"{}/Cluster_im/lo_preds_MVGRL_{:.1f}_{:d}_5.npz\".format(model, rate, seed))\n",
    "            preds = data[\"preds\"]\n",
    "            \n",
    "            nmi = NMI(labels, preds)\n",
    "            ami = AMI(labels, preds)\n",
    "            ari = ARI(labels, preds)\n",
    "            \n",
    "            nmis.append(nmi)\n",
    "            amis.append(ami)\n",
    "            aris.append(ari)\n",
    "            \n",
    "        nmi_m[rate] = np.mean(nmis)\n",
    "        ami_m[rate] = np.mean(amis)\n",
    "        ari_m[rate] = np.mean(aris)\n",
    "        \n",
    "#     print(nmi_m.values())\n",
    "#     print(ami_m.values())\n",
    "    print(ari_m.values())\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e3908709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN 0.1 0\n",
      "KNN 0.1 1\n",
      "KNN 0.1 2\n",
      "KNN 0.30000000000000004 0\n",
      "KNN 0.30000000000000004 1\n",
      "KNN 0.30000000000000004 2\n",
      "KNN 0.5000000000000001 0\n",
      "KNN 0.5000000000000001 1\n",
      "KNN 0.5000000000000001 2\n",
      "KNN 0.7000000000000001 0\n",
      "KNN 0.7000000000000001 1\n",
      "KNN 0.7000000000000001 2\n",
      "KNN 0.9000000000000001 0\n",
      "KNN 0.9000000000000001 1\n",
      "KNN 0.9000000000000001 2\n",
      "dict_values([0.6156464420025216, 0.667424455783557, 0.6776703149256323, 0.7041333789303095, 0.7216029472021268])\n"
     ]
    }
   ],
   "source": [
    "seeds = np.arange(0, 3, dtype=int) # seed = {0,1,2}\n",
    "rates = np.arange(0.1, 1.0, 0.2) # minimum rention rates\n",
    "from sklearn.metrics import normalized_mutual_info_score as NMI, adjusted_mutual_info_score as AMI, adjusted_rand_score as ARI\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "for model in models:\n",
    "    \n",
    "    nmi_m, ami_m, ari_m = {}, {}, {}\n",
    "    \n",
    "    for rate in rates:\n",
    "        nmis, amis, aris = [], [], []\n",
    "        \n",
    "        \n",
    "            \n",
    "        for seed in seeds:\n",
    "            print(model, rate, seed)\n",
    "            \n",
    "            adj, features, labels, mask = load_cora_full_im(rate, seed)\n",
    "            \n",
    "            np.random.seed(seed)\n",
    "            torch.manual_seed(seed)\n",
    "            random.seed(seed)\n",
    "            torch.cuda.manual_seed(seed)  \n",
    "            \n",
    "            data = np.load(\"{}/Cluster_im/lo_preds_MVGRL_{:.1f}_{:d}_5.npz\".format(model, rate, seed))\n",
    "            preds = data[\"preds\"]\n",
    "            \n",
    "            nmi = NMI(labels, preds)\n",
    "            ami = AMI(labels, preds)\n",
    "            ari = ARI(labels, preds)\n",
    "            \n",
    "            nmis.append(nmi)\n",
    "            amis.append(ami)\n",
    "            aris.append(ari)\n",
    "            \n",
    "        nmi_m[rate] = np.mean(nmis)\n",
    "        ami_m[rate] = np.mean(amis)\n",
    "        ari_m[rate] = np.mean(aris)\n",
    "        \n",
    "#     print(nmi_m.values())\n",
    "#     print(ami_m.values())\n",
    "    print(ami_m.values())\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8376fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5edbafd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57d5b18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "48ffa23f",
   "metadata": {},
   "source": [
    "## KNN cora-full im GRACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6179e6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    \"KNN\",\n",
    "#     \"SUBLIME\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e76d5f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cora_full_im(rate=0.1, seed=None):\n",
    "    filename = \"/data/liuyue/New/SBM/mySBM/data_im/cora-full_{:.1f}_{:d}_5.npz\".format(rate, seed)\n",
    "    data = np.load(filename)\n",
    "\n",
    "    adj_raw, features_raw, labels_raw, _, _, _ = load_data(\"cora-full\")\n",
    "\n",
    "    adj_data, adj_row, adj_col, features_load, labels_load, mask = data[\"data\"], data[\"row\"], data[\"col\"], data[\"features\"], data[\"labels\"], data[\"mask\"]\n",
    "    adj_load = sp.coo_matrix((adj_data, (adj_row, adj_col)), shape=(labels_load.shape[0], labels_load.shape[0]))\n",
    "\n",
    "    adj_mask = adj_raw.toarray()[mask,:][:,mask]\n",
    "    assert (adj_mask - adj_load).sum() < 1e-7\n",
    "    features_mask = features_raw.toarray()[mask]\n",
    "    assert (features_mask - features_load).sum() < 1e-7\n",
    "\n",
    "    return adj_load, features_load, labels_load, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "02712f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN 0.1 0\n",
      "KNN 0.30000000000000004 0\n",
      "KNN 0.5000000000000001 0\n",
      "KNN 0.7000000000000001 0\n",
      "KNN 0.9000000000000001 0\n",
      "dict_values([0.22465780796531348, 0.2957587633166664, 0.29304039043848606, 0.3451820129885648, 0.437747491881007])\n"
     ]
    }
   ],
   "source": [
    "seeds = np.arange(0, 1, dtype=int) # seed = {0}\n",
    "rates = np.arange(0.1, 1.0, 0.2) # minimum rention rates\n",
    "from sklearn.metrics import normalized_mutual_info_score as NMI, adjusted_mutual_info_score as AMI, adjusted_rand_score as ARI\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "for model in models:\n",
    "    \n",
    "    nmi_m, ami_m, ari_m = {}, {}, {}\n",
    "    \n",
    "    for rate in rates:\n",
    "        nmis, amis, aris = [], [], []\n",
    "        \n",
    "        \n",
    "            \n",
    "        for seed in seeds:\n",
    "            print(model, rate, seed)\n",
    "            \n",
    "            adj, features, labels, mask = load_cora_full_im(rate, seed)\n",
    "            \n",
    "            np.random.seed(seed)\n",
    "            torch.manual_seed(seed)\n",
    "            random.seed(seed)\n",
    "            torch.cuda.manual_seed(seed)  \n",
    "            \n",
    "            data = np.load(\"{}/Cluster_im/lo_preds_GRACE_{:.1f}_{:d}_5.npz\".format(model, rate, seed))\n",
    "            preds = data[\"preds\"]\n",
    "            \n",
    "            nmi = NMI(labels, preds)\n",
    "            ami = AMI(labels, preds)\n",
    "            ari = ARI(labels, preds)\n",
    "            \n",
    "            nmis.append(nmi)\n",
    "            amis.append(ami)\n",
    "            aris.append(ari)\n",
    "            \n",
    "        nmi_m[rate] = np.mean(nmis)\n",
    "        ami_m[rate] = np.mean(amis)\n",
    "        ari_m[rate] = np.mean(aris)\n",
    "        \n",
    "#     print(nmi_m.values())\n",
    "#     print(ami_m.values())\n",
    "    print(ari_m.values())\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0220c2b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN 0.1 0\n",
      "KNN 0.1 1\n",
      "KNN 0.1 2\n",
      "KNN 0.30000000000000004 0\n",
      "KNN 0.30000000000000004 1\n",
      "KNN 0.30000000000000004 2\n",
      "KNN 0.5000000000000001 0\n",
      "KNN 0.5000000000000001 1\n",
      "KNN 0.5000000000000001 2\n",
      "KNN 0.7000000000000001 0\n",
      "KNN 0.7000000000000001 1\n",
      "KNN 0.7000000000000001 2\n",
      "KNN 0.9000000000000001 0\n",
      "KNN 0.9000000000000001 1\n",
      "KNN 0.9000000000000001 2\n",
      "dict_values([0.21770099056979328, 0.2902799318379127, 0.3190234779847761, 0.39690746267069926, 0.46203832233095854])\n"
     ]
    }
   ],
   "source": [
    "seeds = np.arange(0, 3, dtype=int) # seed = {0,1,2}\n",
    "rates = np.arange(0.1, 1.0, 0.2) # minimum rention rates\n",
    "from sklearn.metrics import normalized_mutual_info_score as NMI, adjusted_mutual_info_score as AMI, adjusted_rand_score as ARI\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "for model in models:\n",
    "    \n",
    "    nmi_m, ami_m, ari_m = {}, {}, {}\n",
    "    \n",
    "    for rate in rates:\n",
    "        nmis, amis, aris = [], [], []\n",
    "        \n",
    "        \n",
    "            \n",
    "        for seed in seeds:\n",
    "            print(model, rate, seed)\n",
    "            \n",
    "            adj, features, labels, mask = load_cora_full_im(rate, seed)\n",
    "            \n",
    "            np.random.seed(seed)\n",
    "            torch.manual_seed(seed)\n",
    "            random.seed(seed)\n",
    "            torch.cuda.manual_seed(seed)  \n",
    "            \n",
    "            data = np.load(\"{}/Cluster_im/lo_preds_GRACE_{:.1f}_{:d}_5.npz\".format(model, rate, seed))\n",
    "            preds = data[\"preds\"]\n",
    "            \n",
    "            nmi = NMI(labels, preds)\n",
    "            ami = AMI(labels, preds)\n",
    "            ari = ARI(labels, preds)\n",
    "            \n",
    "            nmis.append(nmi)\n",
    "            amis.append(ami)\n",
    "            aris.append(ari)\n",
    "            \n",
    "        nmi_m[rate] = np.mean(nmis)\n",
    "        ami_m[rate] = np.mean(amis)\n",
    "        ari_m[rate] = np.mean(aris)\n",
    "        \n",
    "#     print(nmi_m.values())\n",
    "#     print(ami_m.values())\n",
    "    print(ari_m.values())\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c6055dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN 0.1 0\n",
      "KNN 0.1 1\n",
      "KNN 0.1 2\n",
      "KNN 0.30000000000000004 0\n",
      "KNN 0.30000000000000004 1\n",
      "KNN 0.30000000000000004 2\n",
      "KNN 0.5000000000000001 0\n",
      "KNN 0.5000000000000001 1\n",
      "KNN 0.5000000000000001 2\n",
      "KNN 0.7000000000000001 0\n",
      "KNN 0.7000000000000001 1\n",
      "KNN 0.7000000000000001 2\n",
      "KNN 0.9000000000000001 0\n",
      "KNN 0.9000000000000001 1\n",
      "KNN 0.9000000000000001 2\n",
      "dict_values([0.3565935012763895, 0.44031023838808814, 0.4621588086625181, 0.510937539482267, 0.5404571553932355])\n"
     ]
    }
   ],
   "source": [
    "seeds = np.arange(0, 3, dtype=int) # seed = {0,1,2}\n",
    "rates = np.arange(0.1, 1.0, 0.2) # minimum rention rates\n",
    "from sklearn.metrics import normalized_mutual_info_score as NMI, adjusted_mutual_info_score as AMI, adjusted_rand_score as ARI\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "for model in models:\n",
    "    \n",
    "    nmi_m, ami_m, ari_m = {}, {}, {}\n",
    "    \n",
    "    for rate in rates:\n",
    "        nmis, amis, aris = [], [], []\n",
    "        \n",
    "        \n",
    "            \n",
    "        for seed in seeds:\n",
    "            print(model, rate, seed)\n",
    "            \n",
    "            adj, features, labels, mask = load_cora_full_im(rate, seed)\n",
    "            \n",
    "            np.random.seed(seed)\n",
    "            torch.manual_seed(seed)\n",
    "            random.seed(seed)\n",
    "            torch.cuda.manual_seed(seed)  \n",
    "            \n",
    "            data = np.load(\"{}/Cluster_im/lo_preds_GRACE_{:.1f}_{:d}_5.npz\".format(model, rate, seed))\n",
    "            preds = data[\"preds\"]\n",
    "            \n",
    "            nmi = NMI(labels, preds)\n",
    "            ami = AMI(labels, preds)\n",
    "            ari = ARI(labels, preds)\n",
    "            \n",
    "            nmis.append(nmi)\n",
    "            amis.append(ami)\n",
    "            aris.append(ari)\n",
    "            \n",
    "        nmi_m[rate] = np.mean(nmis)\n",
    "        ami_m[rate] = np.mean(amis)\n",
    "        ari_m[rate] = np.mean(aris)\n",
    "        \n",
    "#     print(nmi_m.values())\n",
    "#     print(ami_m.values())\n",
    "    print(ami_m.values())\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b4bb39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557d6ee9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b0fadf77",
   "metadata": {},
   "source": [
    "## Louvain-full cora-full im 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0dfff03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rates = np.arange(0.1, 1.0, 0.2)\n",
    "seeds = np.arange(3, dtype=int)\n",
    "model = \"MVGRL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a5e04a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 0\n",
      "0.1 1\n",
      "0.1 2\n",
      "0.30000000000000004 0\n",
      "0.30000000000000004 1\n",
      "0.30000000000000004 2\n",
      "0.5000000000000001 0\n",
      "0.5000000000000001 1\n",
      "0.5000000000000001 2\n",
      "0.7000000000000001 0\n",
      "0.7000000000000001 1\n",
      "0.7000000000000001 2\n",
      "0.9000000000000001 0\n",
      "0.9000000000000001 1\n",
      "0.9000000000000001 2\n",
      "dict_values([0.650273425462047, 0.6221028523745341, 0.6126190999955646, 0.593196691630195, 0.5786829112121248])\n"
     ]
    }
   ],
   "source": [
    "nmi_m, ami_m, ari_m = {}, {}, {}\n",
    "for rate in rates:\n",
    "    for seed in seeds:\n",
    "        print(rate, seed)\n",
    "            \n",
    "        adj, features, labels, mask = load_cora_full_im(rate, seed)\n",
    "        \n",
    "        data = np.load(\"/data/liuyue/New/SBM/mySBM/baselines/Louvain-full/outputs/{}/cora-full_{:.1f}_{:d}.npz\".format(model, rate, seed))\n",
    "        preds = data[\"preds\"]\n",
    "        \n",
    "        nmi = NMI(labels, preds)\n",
    "        ami = AMI(labels, preds)\n",
    "        ari = ARI(labels, preds)\n",
    "            \n",
    "        nmis.append(nmi)\n",
    "        amis.append(ami)\n",
    "        aris.append(ari)\n",
    "            \n",
    "    nmi_m[rate] = np.mean(nmis)\n",
    "    ami_m[rate] = np.mean(amis)\n",
    "    ari_m[rate] = np.mean(aris)\n",
    "print(ari_m.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "94c9b720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 0\n",
      "0.1 1\n",
      "0.1 2\n",
      "0.30000000000000004 0\n",
      "0.30000000000000004 1\n",
      "0.30000000000000004 2\n",
      "0.5000000000000001 0\n",
      "0.5000000000000001 1\n",
      "0.5000000000000001 2\n",
      "0.7000000000000001 0\n",
      "0.7000000000000001 1\n",
      "0.7000000000000001 2\n",
      "0.9000000000000001 0\n",
      "0.9000000000000001 1\n",
      "0.9000000000000001 2\n",
      "dict_values([0.6331488456615656, 0.6332223069139485, 0.6361199350604995, 0.6350364404894765, 0.6332086568308302])\n"
     ]
    }
   ],
   "source": [
    "nmi_m, ami_m, ari_m = {}, {}, {}\n",
    "for rate in rates:\n",
    "    for seed in seeds:\n",
    "        print(rate, seed)\n",
    "            \n",
    "        adj, features, labels, mask = load_cora_full_im(rate, seed)\n",
    "        \n",
    "        data = np.load(\"/data/liuyue/New/SBM/mySBM/baselines/Louvain-full/outputs/{}/cora-full_{:.1f}_{:d}.npz\".format(model, rate, seed))\n",
    "        preds = data[\"preds\"]\n",
    "        \n",
    "        nmi = NMI(labels, preds)\n",
    "        ami = AMI(labels, preds)\n",
    "        ari = ARI(labels, preds)\n",
    "            \n",
    "        nmis.append(nmi)\n",
    "        amis.append(ami)\n",
    "        aris.append(ari)\n",
    "            \n",
    "    nmi_m[rate] = np.mean(nmis)\n",
    "    ami_m[rate] = np.mean(amis)\n",
    "    ari_m[rate] = np.mean(aris)\n",
    "print(ami_m.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c544dfe5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7b8ef7d",
   "metadata": {},
   "source": [
    "## KNN cora-full diff cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c79b3ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cora_full_diff_cls(nclass=10, seed=None):\n",
    "    filename = \"/data/liuyue/New/SBM/mySBM/data_diff_cls/cora-full_{}_{}.npz\".format(nclass, seed)\n",
    "    data = np.load(filename)\n",
    "\n",
    "    adj_raw, features_raw, labels_raw, _, _, _ = load_data(\"cora-full\")\n",
    "\n",
    "    adj_data, adj_row, adj_col, features_load, labels_load, mask = data[\"data\"], data[\"row\"], data[\"col\"], data[\"features\"], data[\"labels\"], data[\"mask\"]\n",
    "    adj_load = sp.coo_matrix((adj_data, (adj_row, adj_col)), shape=(labels_load.shape[0], labels_load.shape[0]))\n",
    "\n",
    "    adj_mask = adj_raw.toarray()[mask,:][:,mask]\n",
    "    assert (adj_mask - adj_load).sum() < 1e-7\n",
    "    features_mask = features_raw.toarray()[mask]\n",
    "    assert (features_mask - features_load).sum() < 1e-7\n",
    "\n",
    "    return adj_load, features_load, labels_load, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7e97bf1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN 5 0\n",
      "KNN 10 0\n",
      "KNN 15 0\n",
      "KNN 20 0\n",
      "KNN 25 0\n",
      "dict_values([0.4336886165239179, 0.5983024864887231, 0.5707472841221046, 0.4761169122531454, 0.41552430400719037])\n"
     ]
    }
   ],
   "source": [
    "seeds = np.arange(0, 1, dtype=int) # seed = {0}\n",
    "nclasses = np.arange(5, 30, 5, dtype=int)\n",
    "from sklearn.metrics import normalized_mutual_info_score as NMI, adjusted_mutual_info_score as AMI, adjusted_rand_score as ARI\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "for model in models:\n",
    "    \n",
    "    nmi_m, ami_m, ari_m = {}, {}, {}\n",
    "    \n",
    "    for nclass in nclasses:\n",
    "        nmis, amis, aris = [], [], []\n",
    "        \n",
    "        \n",
    "            \n",
    "        for seed in seeds:\n",
    "            print(model, nclass, seed)\n",
    "            \n",
    "            adj, features, labels, mask = load_cora_full_diff_cls(nclass, seed)\n",
    "            \n",
    "            np.random.seed(seed)\n",
    "            torch.manual_seed(seed)\n",
    "            random.seed(seed)\n",
    "            torch.cuda.manual_seed(seed)  \n",
    "            \n",
    "            data = np.load(\"{}/Cluster_diff_cls/lo_preds_{:d}_{:d}.npz\".format(model, nclass, seed))\n",
    "            preds = data[\"preds\"]\n",
    "            \n",
    "            nmi = NMI(labels, preds)\n",
    "            ami = AMI(labels, preds)\n",
    "            ari = ARI(labels, preds)\n",
    "            \n",
    "            nmis.append(nmi)\n",
    "            amis.append(ami)\n",
    "            aris.append(ari)\n",
    "            \n",
    "        nmi_m[nclass] = np.mean(nmis)\n",
    "        ami_m[nclass] = np.mean(amis)\n",
    "        ari_m[nclass] = np.mean(aris)\n",
    "        \n",
    "#     print(nmi_m.values())\n",
    "#     print(ami_m.values())\n",
    "    print(ari_m.values())\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "69fd0a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN 5 0\n",
      "KNN 5 1\n",
      "KNN 5 2\n",
      "KNN 10 0\n",
      "KNN 10 1\n",
      "KNN 10 2\n",
      "KNN 15 0\n",
      "KNN 15 1\n",
      "KNN 15 2\n",
      "KNN 20 0\n",
      "KNN 20 1\n",
      "KNN 20 2\n",
      "KNN 25 0\n",
      "KNN 25 1\n",
      "KNN 25 2\n",
      "dict_values([0.6394376045945239, 0.6490915144308349, 0.54910020425273, 0.48065093124437314, 0.4072053275224767])\n"
     ]
    }
   ],
   "source": [
    "seeds = np.arange(0, 3, dtype=int) # seed = {0,1,2}\n",
    "nclasses = np.arange(5, 30, 5, dtype=int)from sklearn.metrics import normalized_mutual_info_score as NMI, adjusted_mutual_info_score as AMI, adjusted_rand_score as ARI\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "for model in models:\n",
    "    \n",
    "    nmi_m, ami_m, ari_m = {}, {}, {}\n",
    "    \n",
    "    for nclass in nclasses:\n",
    "        nmis, amis, aris = [], [], []\n",
    "        \n",
    "        \n",
    "            \n",
    "        for seed in seeds:\n",
    "            print(model, nclass, seed)\n",
    "            \n",
    "            adj, features, labels, mask = load_cora_full_diff_cls(nclass, seed)\n",
    "            \n",
    "            np.random.seed(seed)\n",
    "            torch.manual_seed(seed)\n",
    "            random.seed(seed)\n",
    "            torch.cuda.manual_seed(seed)  \n",
    "            \n",
    "            data = np.load(\"{}/Cluster_diff_cls/lo_preds_{:d}_{:d}.npz\".format(model, nclass, seed))\n",
    "            preds = data[\"preds\"]\n",
    "            \n",
    "            nmi = NMI(labels, preds)\n",
    "            ami = AMI(labels, preds)\n",
    "            ari = ARI(labels, preds)\n",
    "            \n",
    "            nmis.append(nmi)\n",
    "            amis.append(ami)\n",
    "            aris.append(ari)\n",
    "            \n",
    "        nmi_m[nclass] = np.mean(nmis)\n",
    "        ami_m[nclass] = np.mean(amis)\n",
    "        ari_m[nclass] = np.mean(aris)\n",
    "        \n",
    "#     print(nmi_m.values())\n",
    "#     print(ami_m.values())\n",
    "    print(ari_m.values())\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "32c58baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN 5 0\n",
      "KNN 5 1\n",
      "KNN 5 2\n",
      "KNN 10 0\n",
      "KNN 10 1\n",
      "KNN 10 2\n",
      "KNN 15 0\n",
      "KNN 15 1\n",
      "KNN 15 2\n",
      "KNN 20 0\n",
      "KNN 20 1\n",
      "KNN 20 2\n",
      "KNN 25 0\n",
      "KNN 25 1\n",
      "KNN 25 2\n",
      "dict_values([0.6670355689716946, 0.7059515754979815, 0.6746965498760535, 0.6482330683615417, 0.6160755361512771])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import normalized_mutual_info_score as NMI, adjusted_mutual_info_score as AMI, adjusted_rand_score as ARI\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "for model in models:\n",
    "    \n",
    "    nmi_m, ami_m, ari_m = {}, {}, {}\n",
    "    \n",
    "    for nclass in nclasses:\n",
    "        nmis, amis, aris = [], [], []\n",
    "        \n",
    "        \n",
    "            \n",
    "        for seed in seeds:\n",
    "            print(model, nclass, seed)\n",
    "            \n",
    "            adj, features, labels, mask = load_cora_full_diff_cls(nclass, seed)\n",
    "            \n",
    "            np.random.seed(seed)\n",
    "            torch.manual_seed(seed)\n",
    "            random.seed(seed)\n",
    "            torch.cuda.manual_seed(seed)  \n",
    "            \n",
    "            data = np.load(\"{}/Cluster_diff_cls/lo_preds_{:d}_{:d}.npz\".format(model, nclass, seed))\n",
    "            preds = data[\"preds\"]\n",
    "            \n",
    "            nmi = NMI(labels, preds)\n",
    "            ami = AMI(labels, preds)\n",
    "            ari = ARI(labels, preds)\n",
    "            \n",
    "            nmis.append(nmi)\n",
    "            amis.append(ami)\n",
    "            aris.append(ari)\n",
    "            \n",
    "        nmi_m[nclass] = np.mean(nmis)\n",
    "        ami_m[nclass] = np.mean(amis)\n",
    "        ari_m[nclass] = np.mean(aris)\n",
    "        \n",
    "#     print(nmi_m.values())\n",
    "#     print(ami_m.values())\n",
    "    print(ami_m.values())\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162984bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "14807265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN 2 0\n",
      "KNN 4 0\n",
      "KNN 6 0\n",
      "KNN 8 0\n",
      "KNN 10 0\n",
      "dict_values([0.28578876622897215, 0.4177724813877944, 0.5645367161074539, 0.5495291203473794, 0.5860185744820885])\n"
     ]
    }
   ],
   "source": [
    "seeds = np.arange(0, 1, dtype=int) # seed = {0}\n",
    "nclasses = np.arange(2, 12, 2, dtype=int)\n",
    "from sklearn.metrics import normalized_mutual_info_score as NMI, adjusted_mutual_info_score as AMI, adjusted_rand_score as ARI\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "for model in models:\n",
    "    \n",
    "    nmi_m, ami_m, ari_m = {}, {}, {}\n",
    "    \n",
    "    for nclass in nclasses:\n",
    "        nmis, amis, aris = [], [], []\n",
    "        \n",
    "        \n",
    "            \n",
    "        for seed in seeds:\n",
    "            print(model, nclass, seed)\n",
    "            \n",
    "            adj, features, labels, mask = load_cora_full_diff_cls(nclass, seed)\n",
    "            \n",
    "            np.random.seed(seed)\n",
    "            torch.manual_seed(seed)\n",
    "            random.seed(seed)\n",
    "            torch.cuda.manual_seed(seed)  \n",
    "            \n",
    "            data = np.load(\"{}/Cluster_diff_cls/lo_preds_{:d}_{:d}.npz\".format(model, nclass, seed))\n",
    "            preds = data[\"preds\"]\n",
    "            \n",
    "            nmi = NMI(labels, preds)\n",
    "            ami = AMI(labels, preds)\n",
    "            ari = ARI(labels, preds)\n",
    "            \n",
    "            nmis.append(nmi)\n",
    "            amis.append(ami)\n",
    "            aris.append(ari)\n",
    "            \n",
    "        nmi_m[nclass] = np.mean(nmis)\n",
    "        ami_m[nclass] = np.mean(amis)\n",
    "        ari_m[nclass] = np.mean(aris)\n",
    "        \n",
    "#     print(nmi_m.values())\n",
    "#     print(ami_m.values())\n",
    "    print(ari_m.values())\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "110fda3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN 2 0\n",
      "KNN 2 1\n",
      "KNN 2 2\n",
      "KNN 4 0\n",
      "KNN 4 1\n",
      "KNN 4 2\n",
      "KNN 6 0\n",
      "KNN 6 1\n",
      "KNN 6 2\n",
      "KNN 8 0\n",
      "KNN 8 1\n",
      "KNN 8 2\n",
      "KNN 10 0\n",
      "KNN 10 1\n",
      "KNN 10 2\n",
      "dict_values([0.35322102885073453, 0.6246079463555835, 0.6858712682658418, 0.5987591411443498, 0.6557884201286891])\n"
     ]
    }
   ],
   "source": [
    "seeds = np.arange(0, 3, dtype=int) # seed = {0,1,2}\n",
    "nclasses = np.arange(2, 12, 2, dtype=int)\n",
    "from sklearn.metrics import normalized_mutual_info_score as NMI, adjusted_mutual_info_score as AMI, adjusted_rand_score as ARI\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "for model in models:\n",
    "    \n",
    "    nmi_m, ami_m, ari_m = {}, {}, {}\n",
    "    \n",
    "    for nclass in nclasses:\n",
    "        nmis, amis, aris = [], [], []\n",
    "        \n",
    "        \n",
    "            \n",
    "        for seed in seeds:\n",
    "            print(model, nclass, seed)\n",
    "            \n",
    "            adj, features, labels, mask = load_cora_full_diff_cls(nclass, seed)\n",
    "            \n",
    "            np.random.seed(seed)\n",
    "            torch.manual_seed(seed)\n",
    "            random.seed(seed)\n",
    "            torch.cuda.manual_seed(seed)  \n",
    "            \n",
    "            data = np.load(\"{}/Cluster_diff_cls/lo_preds_{:d}_{:d}.npz\".format(model, nclass, seed))\n",
    "            preds = data[\"preds\"]\n",
    "            \n",
    "            nmi = NMI(labels, preds)\n",
    "            ami = AMI(labels, preds)\n",
    "            ari = ARI(labels, preds)\n",
    "            \n",
    "            nmis.append(nmi)\n",
    "            amis.append(ami)\n",
    "            aris.append(ari)\n",
    "            \n",
    "        nmi_m[nclass] = np.mean(nmis)\n",
    "        ami_m[nclass] = np.mean(amis)\n",
    "        ari_m[nclass] = np.mean(aris)\n",
    "        \n",
    "#     print(nmi_m.values())\n",
    "#     print(ami_m.values())\n",
    "    print(ari_m.values())\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a26553f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN 2 0\n",
      "KNN 2 1\n",
      "KNN 2 2\n",
      "KNN 4 0\n",
      "KNN 4 1\n",
      "KNN 4 2\n",
      "KNN 6 0\n",
      "KNN 6 1\n",
      "KNN 6 2\n",
      "KNN 8 0\n",
      "KNN 8 1\n",
      "KNN 8 2\n",
      "KNN 10 0\n",
      "KNN 10 1\n",
      "KNN 10 2\n",
      "dict_values([0.49514724585652387, 0.6593967820869666, 0.7131740963363832, 0.6628805710677481, 0.711123644634323])\n"
     ]
    }
   ],
   "source": [
    "seeds = np.arange(0, 3, dtype=int) # seed = {0,1,2}\n",
    "nclasses = np.arange(2, 12, 2, dtype=int)\n",
    "from sklearn.metrics import normalized_mutual_info_score as NMI, adjusted_mutual_info_score as AMI, adjusted_rand_score as ARI\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "for model in models:\n",
    "    \n",
    "    nmi_m, ami_m, ari_m = {}, {}, {}\n",
    "    \n",
    "    for nclass in nclasses:\n",
    "        nmis, amis, aris = [], [], []\n",
    "        \n",
    "        \n",
    "            \n",
    "        for seed in seeds:\n",
    "            print(model, nclass, seed)\n",
    "            \n",
    "            adj, features, labels, mask = load_cora_full_diff_cls(nclass, seed)\n",
    "            \n",
    "            np.random.seed(seed)\n",
    "            torch.manual_seed(seed)\n",
    "            random.seed(seed)\n",
    "            torch.cuda.manual_seed(seed)  \n",
    "            \n",
    "            data = np.load(\"{}/Cluster_diff_cls/lo_preds_{:d}_{:d}.npz\".format(model, nclass, seed))\n",
    "            preds = data[\"preds\"]\n",
    "            \n",
    "            nmi = NMI(labels, preds)\n",
    "            ami = AMI(labels, preds)\n",
    "            ari = ARI(labels, preds)\n",
    "            \n",
    "            nmis.append(nmi)\n",
    "            amis.append(ami)\n",
    "            aris.append(ari)\n",
    "            \n",
    "        nmi_m[nclass] = np.mean(nmis)\n",
    "        ami_m[nclass] = np.mean(amis)\n",
    "        ari_m[nclass] = np.mean(aris)\n",
    "        \n",
    "#     print(nmi_m.values())\n",
    "#     print(ami_m.values())\n",
    "    print(ami_m.values())\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df60c4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce73517",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc903c09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d94e635f",
   "metadata": {},
   "source": [
    "## KNN cora-full diff cls 20m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d939c087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN 5 0\n",
      "KNN 5 1\n",
      "KNN 5 2\n",
      "KNN 10 0\n",
      "KNN 10 1\n",
      "KNN 10 2\n",
      "KNN 15 0\n",
      "KNN 15 1\n",
      "KNN 15 2\n",
      "KNN 20 0\n",
      "KNN 20 1\n",
      "KNN 20 2\n",
      "KNN 25 0\n",
      "KNN 25 1\n",
      "KNN 25 2\n",
      "dict_values([0.6923254060424816, 0.6481766528262951, 0.5142909929978279, 0.45526820099302295, 0.3817912037714503])\n"
     ]
    }
   ],
   "source": [
    "seeds = np.arange(0, 3, dtype=int) # seed = {0,1,2}\n",
    "nclasses = np.arange(5, 30, 5, dtype=int)\n",
    "from sklearn.metrics import normalized_mutual_info_score as NMI, adjusted_mutual_info_score as AMI, adjusted_rand_score as ARI\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "for model in models:\n",
    "    \n",
    "    nmi_m, ami_m, ari_m = {}, {}, {}\n",
    "    \n",
    "    for nclass in nclasses:\n",
    "        nmis, amis, aris = [], [], []\n",
    "        \n",
    "        \n",
    "            \n",
    "        for seed in seeds:\n",
    "            print(model, nclass, seed)\n",
    "            \n",
    "            adj, features, labels, mask = load_cora_full_diff_cls(nclass, seed)\n",
    "            \n",
    "            np.random.seed(seed)\n",
    "            torch.manual_seed(seed)\n",
    "            random.seed(seed)\n",
    "            torch.cuda.manual_seed(seed)  \n",
    "            \n",
    "            data = np.load(\"{}/Cluster_diff_cls/lo_preds_{:d}_{:d}_20m.npz\".format(model, nclass, seed))\n",
    "            preds = data[\"preds\"]\n",
    "            \n",
    "            nmi = NMI(labels, preds)\n",
    "            ami = AMI(labels, preds)\n",
    "            ari = ARI(labels, preds)\n",
    "            \n",
    "            nmis.append(nmi)\n",
    "            amis.append(ami)\n",
    "            aris.append(ari)\n",
    "            \n",
    "        nmi_m[nclass] = np.mean(nmis)\n",
    "        ami_m[nclass] = np.mean(amis)\n",
    "        ari_m[nclass] = np.mean(aris)\n",
    "        \n",
    "#     print(nmi_m.values())\n",
    "#     print(ami_m.values())\n",
    "    print(ari_m.values())\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5b860415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN 5 0\n",
      "KNN 10 0\n",
      "KNN 15 0\n",
      "KNN 20 0\n",
      "KNN 25 0\n",
      "dict_values([0.5042041150586188, 0.5653995866991947, 0.5171168709883304, 0.44251629175234164, 0.3945023632817341])\n"
     ]
    }
   ],
   "source": [
    "seeds = np.arange(0, 1, dtype=int) # seed = {0}\n",
    "nclasses = np.arange(5, 30, 5, dtype=int)\n",
    "from sklearn.metrics import normalized_mutual_info_score as NMI, adjusted_mutual_info_score as AMI, adjusted_rand_score as ARI\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "for model in models:\n",
    "    \n",
    "    nmi_m, ami_m, ari_m = {}, {}, {}\n",
    "    \n",
    "    for nclass in nclasses:\n",
    "        nmis, amis, aris = [], [], []\n",
    "        \n",
    "        \n",
    "            \n",
    "        for seed in seeds:\n",
    "            print(model, nclass, seed)\n",
    "            \n",
    "            adj, features, labels, mask = load_cora_full_diff_cls(nclass, seed)\n",
    "            \n",
    "            np.random.seed(seed)\n",
    "            torch.manual_seed(seed)\n",
    "            random.seed(seed)\n",
    "            torch.cuda.manual_seed(seed)  \n",
    "            \n",
    "            data = np.load(\"{}/Cluster_diff_cls/lo_preds_{:d}_{:d}_20m.npz\".format(model, nclass, seed))\n",
    "            preds = data[\"preds\"]\n",
    "            \n",
    "            nmi = NMI(labels, preds)\n",
    "            ami = AMI(labels, preds)\n",
    "            ari = ARI(labels, preds)\n",
    "            \n",
    "            nmis.append(nmi)\n",
    "            amis.append(ami)\n",
    "            aris.append(ari)\n",
    "            \n",
    "        nmi_m[nclass] = np.mean(nmis)\n",
    "        ami_m[nclass] = np.mean(amis)\n",
    "        ari_m[nclass] = np.mean(aris)\n",
    "        \n",
    "#     print(nmi_m.values())\n",
    "#     print(ami_m.values())\n",
    "    print(ari_m.values())\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b54158",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb332c34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d40b400",
   "metadata": {},
   "source": [
    "## KNN cora-full diff cls 30m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "adceda70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN 5 0\n",
      "KNN 10 0\n",
      "KNN 15 0\n",
      "KNN 20 0\n",
      "KNN 25 0\n",
      "dict_values([0.53670538767229, 0.5988175591350375, 0.5123947092154294, 0.42709331844891896, 0.38400368818445385])\n"
     ]
    }
   ],
   "source": [
    "seeds = np.arange(0, 1, dtype=int) # seed = {0}\n",
    "nclasses = np.arange(5, 30, 5, dtype=int)\n",
    "from sklearn.metrics import normalized_mutual_info_score as NMI, adjusted_mutual_info_score as AMI, adjusted_rand_score as ARI\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "for model in models:\n",
    "    \n",
    "    nmi_m, ami_m, ari_m = {}, {}, {}\n",
    "    \n",
    "    for nclass in nclasses:\n",
    "        nmis, amis, aris = [], [], []\n",
    "        \n",
    "        \n",
    "            \n",
    "        for seed in seeds:\n",
    "            print(model, nclass, seed)\n",
    "            \n",
    "            adj, features, labels, mask = load_cora_full_diff_cls(nclass, seed)\n",
    "            \n",
    "            np.random.seed(seed)\n",
    "            torch.manual_seed(seed)\n",
    "            random.seed(seed)\n",
    "            torch.cuda.manual_seed(seed)  \n",
    "            \n",
    "            data = np.load(\"{}/Cluster_diff_cls/lo_preds_{:d}_{:d}_30m.npz\".format(model, nclass, seed))\n",
    "            preds = data[\"preds\"]\n",
    "            \n",
    "            nmi = NMI(labels, preds)\n",
    "            ami = AMI(labels, preds)\n",
    "            ari = ARI(labels, preds)\n",
    "            \n",
    "            nmis.append(nmi)\n",
    "            amis.append(ami)\n",
    "            aris.append(ari)\n",
    "            \n",
    "        nmi_m[nclass] = np.mean(nmis)\n",
    "        ami_m[nclass] = np.mean(amis)\n",
    "        ari_m[nclass] = np.mean(aris)\n",
    "        \n",
    "#     print(nmi_m.values())\n",
    "#     print(ami_m.values())\n",
    "    print(ari_m.values())\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7e8a4922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN 5 0\n",
      "KNN 5 1\n",
      "KNN 5 2\n",
      "KNN 10 0\n",
      "KNN 10 1\n",
      "KNN 10 2\n",
      "KNN 15 0\n",
      "KNN 15 1\n",
      "KNN 15 2\n",
      "KNN 20 0\n",
      "KNN 20 1\n",
      "KNN 20 2\n",
      "KNN 25 0\n",
      "KNN 25 1\n",
      "KNN 25 2\n",
      "dict_values([0.7273394547592128, 0.6429065104949334, 0.4943558871534792, 0.42869681171484614, 0.3722466178606505])\n"
     ]
    }
   ],
   "source": [
    "seeds = np.arange(0, 3, dtype=int) # seed = {0,1,2}\n",
    "nclasses = np.arange(5, 30, 5, dtype=int)\n",
    "from sklearn.metrics import normalized_mutual_info_score as NMI, adjusted_mutual_info_score as AMI, adjusted_rand_score as ARI\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "for model in models:\n",
    "    \n",
    "    nmi_m, ami_m, ari_m = {}, {}, {}\n",
    "    \n",
    "    for nclass in nclasses:\n",
    "        nmis, amis, aris = [], [], []\n",
    "        \n",
    "        \n",
    "            \n",
    "        for seed in seeds:\n",
    "            print(model, nclass, seed)\n",
    "            \n",
    "            adj, features, labels, mask = load_cora_full_diff_cls(nclass, seed)\n",
    "            \n",
    "            np.random.seed(seed)\n",
    "            torch.manual_seed(seed)\n",
    "            random.seed(seed)\n",
    "            torch.cuda.manual_seed(seed)  \n",
    "            \n",
    "            data = np.load(\"{}/Cluster_diff_cls/lo_preds_{:d}_{:d}_30m.npz\".format(model, nclass, seed))\n",
    "            preds = data[\"preds\"]\n",
    "            \n",
    "            nmi = NMI(labels, preds)\n",
    "            ami = AMI(labels, preds)\n",
    "            ari = ARI(labels, preds)\n",
    "            \n",
    "            nmis.append(nmi)\n",
    "            amis.append(ami)\n",
    "            aris.append(ari)\n",
    "            \n",
    "        nmi_m[nclass] = np.mean(nmis)\n",
    "        ami_m[nclass] = np.mean(amis)\n",
    "        ari_m[nclass] = np.mean(aris)\n",
    "        \n",
    "#     print(nmi_m.values())\n",
    "#     print(ami_m.values())\n",
    "    print(ari_m.values())\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097e54fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1cff1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0623d49a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600328db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b1a8794d",
   "metadata": {},
   "source": [
    "## SUBLIME cora-full im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a3156fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    \"SUBLIME\"\n",
    "]\n",
    "graph_learners = [\n",
    "    \"fgp\",\n",
    "    \"att\",\n",
    "    \"mlp\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "14d3f44f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUBLIME 0.1 0\n",
      "SUBLIME 0.1 1\n",
      "SUBLIME 0.1 2\n",
      "SUBLIME 0.2 0\n",
      "SUBLIME 0.2 1\n",
      "SUBLIME 0.2 2\n",
      "SUBLIME 0.30000000000000004 0\n",
      "SUBLIME 0.30000000000000004 1\n",
      "SUBLIME 0.30000000000000004 2\n",
      "SUBLIME 0.4 0\n",
      "SUBLIME 0.4 1\n",
      "SUBLIME 0.4 2\n",
      "SUBLIME 0.5 0\n",
      "SUBLIME 0.5 1\n",
      "SUBLIME 0.5 2\n",
      "SUBLIME 0.6 0\n",
      "SUBLIME 0.6 1\n",
      "SUBLIME 0.6 2\n",
      "SUBLIME 0.7000000000000001 0\n",
      "SUBLIME 0.7000000000000001 1\n",
      "SUBLIME 0.7000000000000001 2\n",
      "SUBLIME 0.8 0\n",
      "SUBLIME 0.8 1\n",
      "SUBLIME 0.8 2\n",
      "SUBLIME 0.9 0\n",
      "SUBLIME 0.9 1\n",
      "SUBLIME 0.9 2\n",
      "fgp dict_values([0.5641799469408071, 0.5719847516111346, 0.5548683404491933, 0.5566203662041945, 0.5629866790691769, 0.5828037869516972, 0.575537361205189, 0.5729156693779108, 0.5787820819799704])\n",
      "SUBLIME 0.1 0\n",
      "SUBLIME 0.1 1\n",
      "SUBLIME 0.1 2\n",
      "SUBLIME 0.2 0\n",
      "SUBLIME 0.2 1\n",
      "SUBLIME 0.2 2\n",
      "SUBLIME 0.30000000000000004 0\n",
      "SUBLIME 0.30000000000000004 1\n",
      "SUBLIME 0.30000000000000004 2\n",
      "SUBLIME 0.4 0\n",
      "SUBLIME 0.4 1\n",
      "SUBLIME 0.4 2\n",
      "SUBLIME 0.5 0\n",
      "SUBLIME 0.5 1\n",
      "SUBLIME 0.5 2\n",
      "SUBLIME 0.6 0\n",
      "SUBLIME 0.6 1\n",
      "SUBLIME 0.6 2\n",
      "SUBLIME 0.7000000000000001 0\n",
      "SUBLIME 0.7000000000000001 1\n",
      "SUBLIME 0.7000000000000001 2\n",
      "SUBLIME 0.8 0\n",
      "SUBLIME 0.8 1\n",
      "SUBLIME 0.8 2\n",
      "SUBLIME 0.9 0\n",
      "SUBLIME 0.9 1\n",
      "SUBLIME 0.9 2\n",
      "att dict_values([0.4801696918472364, 0.4942336707156994, 0.4988938710218385, 0.5032362904450678, 0.5080730673318962, 0.5350613658450735, 0.5112488906576734, 0.5260097232909011, 0.5236711062386241])\n",
      "SUBLIME 0.1 0\n",
      "SUBLIME 0.1 1\n",
      "SUBLIME 0.1 2\n",
      "SUBLIME 0.2 0\n",
      "SUBLIME 0.2 1\n",
      "SUBLIME 0.2 2\n",
      "SUBLIME 0.30000000000000004 0\n",
      "SUBLIME 0.30000000000000004 1\n",
      "SUBLIME 0.30000000000000004 2\n",
      "SUBLIME 0.4 0\n",
      "SUBLIME 0.4 1\n",
      "SUBLIME 0.4 2\n",
      "SUBLIME 0.5 0\n",
      "SUBLIME 0.5 1\n",
      "SUBLIME 0.5 2\n",
      "SUBLIME 0.6 0\n",
      "SUBLIME 0.6 1\n",
      "SUBLIME 0.6 2\n",
      "SUBLIME 0.7000000000000001 0\n",
      "SUBLIME 0.7000000000000001 1\n",
      "SUBLIME 0.7000000000000001 2\n",
      "SUBLIME 0.8 0\n",
      "SUBLIME 0.8 1\n",
      "SUBLIME 0.8 2\n",
      "SUBLIME 0.9 0\n",
      "SUBLIME 0.9 1\n",
      "SUBLIME 0.9 2\n",
      "mlp dict_values([0.051925853422346575, 0.07433442872440471, 0.12468804213730407, 0.09284555358322562, 0.09171820166400442, 0.0969480997722285, 0.09523997880653005, 0.11031960112968149, 0.12461122827405309])\n"
     ]
    }
   ],
   "source": [
    "seeds = np.arange(0, 3, dtype=int) # seed = {0,1,2}\n",
    "rates = np.arange(0.1, 1.0, 0.1) # minimum rention rates\n",
    "from sklearn.metrics import normalized_mutual_info_score as NMI, adjusted_mutual_info_score as AMI, adjusted_rand_score as ARI\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "for model in models:\n",
    "    \n",
    "    for graph_learner in graph_learners:\n",
    "    \n",
    "        nmi_m, ami_m, ari_m = {}, {}, {}\n",
    "\n",
    "        for rate in rates:\n",
    "            nmis, amis, aris = [], [], []\n",
    "\n",
    "\n",
    "\n",
    "            for seed in seeds:\n",
    "                print(model, rate, seed)\n",
    "\n",
    "                adj, features, labels, mask = load_cora_full_im(rate, seed)\n",
    "\n",
    "                np.random.seed(seed)\n",
    "                torch.manual_seed(seed)\n",
    "                random.seed(seed)\n",
    "                torch.cuda.manual_seed(seed)  \n",
    "\n",
    "                data = np.load(\"{}/Cluster_im/{}/lo_cora-full_preds_{:.1f}_{:d}.npz\".format(model, graph_learner, rate, seed))\n",
    "                preds = data[\"preds\"]\n",
    "\n",
    "                nmi = NMI(labels, preds)\n",
    "                ami = AMI(labels, preds)\n",
    "                ari = ARI(labels, preds)\n",
    "\n",
    "                nmis.append(nmi)\n",
    "                amis.append(ami)\n",
    "                aris.append(ari)\n",
    "\n",
    "            nmi_m[rate] = np.mean(nmis)\n",
    "            ami_m[rate] = np.mean(amis)\n",
    "            ari_m[rate] = np.mean(aris)\n",
    "\n",
    "    #     print(nmi_m.values())\n",
    "    #     print(ami_m.values())\n",
    "        print(graph_learner, ari_m.values())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d1f2ff7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUBLIME 0.1 0\n",
      "SUBLIME 0.1 1\n",
      "SUBLIME 0.1 2\n",
      "SUBLIME 0.2 0\n",
      "SUBLIME 0.2 1\n",
      "SUBLIME 0.2 2\n",
      "SUBLIME 0.30000000000000004 0\n",
      "SUBLIME 0.30000000000000004 1\n",
      "SUBLIME 0.30000000000000004 2\n",
      "SUBLIME 0.4 0\n",
      "SUBLIME 0.4 1\n",
      "SUBLIME 0.4 2\n",
      "SUBLIME 0.5 0\n",
      "SUBLIME 0.5 1\n",
      "SUBLIME 0.5 2\n",
      "SUBLIME 0.6 0\n",
      "SUBLIME 0.6 1\n",
      "SUBLIME 0.6 2\n",
      "SUBLIME 0.7000000000000001 0\n",
      "SUBLIME 0.7000000000000001 1\n",
      "SUBLIME 0.7000000000000001 2\n",
      "SUBLIME 0.8 0\n",
      "SUBLIME 0.8 1\n",
      "SUBLIME 0.8 2\n",
      "SUBLIME 0.9 0\n",
      "SUBLIME 0.9 1\n",
      "SUBLIME 0.9 2\n",
      "fgp dict_values([0.5848167542516723, 0.6009345178369937, 0.6041912265352896, 0.6074684773257836, 0.6160886805725098, 0.6282068662615213, 0.6255916245493851, 0.6291289316997603, 0.6279486957019172])\n",
      "SUBLIME 0.1 0\n",
      "SUBLIME 0.1 1\n",
      "SUBLIME 0.1 2\n",
      "SUBLIME 0.2 0\n",
      "SUBLIME 0.2 1\n",
      "SUBLIME 0.2 2\n",
      "SUBLIME 0.30000000000000004 0\n",
      "SUBLIME 0.30000000000000004 1\n",
      "SUBLIME 0.30000000000000004 2\n",
      "SUBLIME 0.4 0\n",
      "SUBLIME 0.4 1\n",
      "SUBLIME 0.4 2\n",
      "SUBLIME 0.5 0\n",
      "SUBLIME 0.5 1\n",
      "SUBLIME 0.5 2\n",
      "SUBLIME 0.6 0\n",
      "SUBLIME 0.6 1\n",
      "SUBLIME 0.6 2\n",
      "SUBLIME 0.7000000000000001 0\n",
      "SUBLIME 0.7000000000000001 1\n",
      "SUBLIME 0.7000000000000001 2\n",
      "SUBLIME 0.8 0\n",
      "SUBLIME 0.8 1\n",
      "SUBLIME 0.8 2\n",
      "SUBLIME 0.9 0\n",
      "SUBLIME 0.9 1\n",
      "SUBLIME 0.9 2\n",
      "att dict_values([0.5407828695612785, 0.5500056555342274, 0.5719229275354462, 0.57548793765624, 0.5762306896417401, 0.5987099726376336, 0.5789389746161165, 0.5948626155995488, 0.5878124857010635])\n",
      "SUBLIME 0.1 0\n",
      "SUBLIME 0.1 1\n",
      "SUBLIME 0.1 2\n",
      "SUBLIME 0.2 0\n",
      "SUBLIME 0.2 1\n",
      "SUBLIME 0.2 2\n",
      "SUBLIME 0.30000000000000004 0\n",
      "SUBLIME 0.30000000000000004 1\n",
      "SUBLIME 0.30000000000000004 2\n",
      "SUBLIME 0.4 0\n",
      "SUBLIME 0.4 1\n",
      "SUBLIME 0.4 2\n",
      "SUBLIME 0.5 0\n",
      "SUBLIME 0.5 1\n",
      "SUBLIME 0.5 2\n",
      "SUBLIME 0.6 0\n",
      "SUBLIME 0.6 1\n",
      "SUBLIME 0.6 2\n",
      "SUBLIME 0.7000000000000001 0\n",
      "SUBLIME 0.7000000000000001 1\n",
      "SUBLIME 0.7000000000000001 2\n",
      "SUBLIME 0.8 0\n",
      "SUBLIME 0.8 1\n",
      "SUBLIME 0.8 2\n",
      "SUBLIME 0.9 0\n",
      "SUBLIME 0.9 1\n",
      "SUBLIME 0.9 2\n",
      "mlp dict_values([0.0835880169255317, 0.11263190964512826, 0.16724521291518188, 0.14940841401310007, 0.1465041154694324, 0.15322995403285686, 0.15444307982597114, 0.18368858810436098, 0.20158580217738142])\n"
     ]
    }
   ],
   "source": [
    "seeds = np.arange(0, 3, dtype=int) # seed = {0,1,2}\n",
    "rates = np.arange(0.1, 1.0, 0.1) # minimum rention rates\n",
    "from sklearn.metrics import normalized_mutual_info_score as NMI, adjusted_mutual_info_score as AMI, adjusted_rand_score as ARI\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "for model in models:\n",
    "    \n",
    "    for graph_learner in graph_learners:\n",
    "    \n",
    "        nmi_m, ami_m, ari_m = {}, {}, {}\n",
    "\n",
    "        for rate in rates:\n",
    "            nmis, amis, aris = [], [], []\n",
    "\n",
    "\n",
    "\n",
    "            for seed in seeds:\n",
    "                print(model, rate, seed)\n",
    "\n",
    "                adj, features, labels, mask = load_cora_full_im(rate, seed)\n",
    "\n",
    "                np.random.seed(seed)\n",
    "                torch.manual_seed(seed)\n",
    "                random.seed(seed)\n",
    "                torch.cuda.manual_seed(seed)  \n",
    "\n",
    "                data = np.load(\"{}/Cluster_im/{}/lo_cora-full_preds_{:.1f}_{:d}.npz\".format(model, graph_learner, rate, seed))\n",
    "                preds = data[\"preds\"]\n",
    "\n",
    "                nmi = NMI(labels, preds)\n",
    "                ami = AMI(labels, preds)\n",
    "                ari = ARI(labels, preds)\n",
    "\n",
    "                nmis.append(nmi)\n",
    "                amis.append(ami)\n",
    "                aris.append(ari)\n",
    "\n",
    "            nmi_m[rate] = np.mean(nmis)\n",
    "            ami_m[rate] = np.mean(amis)\n",
    "            ari_m[rate] = np.mean(aris)\n",
    "\n",
    "    #     print(nmi_m.values())\n",
    "    #     print(ami_m.values())\n",
    "        print(graph_learner, ami_m.values())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb113e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f81e6ef0",
   "metadata": {},
   "source": [
    "## SUBLIME cora-full im 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e3bc6147",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    \"SUBLIME\"\n",
    "]\n",
    "graph_learners = [\n",
    "    \"fgp\",\n",
    "    \"att\",\n",
    "    \"mlp\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "aa59fc9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUBLIME 0.1 0\n",
      "SUBLIME 0.1 1\n",
      "SUBLIME 0.1 2\n",
      "SUBLIME 0.30000000000000004 0\n",
      "SUBLIME 0.30000000000000004 1\n",
      "SUBLIME 0.30000000000000004 2\n",
      "SUBLIME 0.5000000000000001 0\n",
      "SUBLIME 0.5000000000000001 1\n",
      "SUBLIME 0.5000000000000001 2\n",
      "SUBLIME 0.7000000000000001 0\n",
      "SUBLIME 0.7000000000000001 1\n",
      "SUBLIME 0.7000000000000001 2\n",
      "SUBLIME 0.9000000000000001 0\n",
      "SUBLIME 0.9000000000000001 1\n",
      "SUBLIME 0.9000000000000001 2\n",
      "fgp dict_values([0.5532285101723392, 0.6248224549197682, 0.6499944596760883, 0.6633219500321417, 0.6598450034192384])\n",
      "SUBLIME 0.1 0\n",
      "SUBLIME 0.1 1\n",
      "SUBLIME 0.1 2\n",
      "SUBLIME 0.30000000000000004 0\n",
      "SUBLIME 0.30000000000000004 1\n",
      "SUBLIME 0.30000000000000004 2\n",
      "SUBLIME 0.5000000000000001 0\n",
      "SUBLIME 0.5000000000000001 1\n",
      "SUBLIME 0.5000000000000001 2\n",
      "SUBLIME 0.7000000000000001 0\n",
      "SUBLIME 0.7000000000000001 1\n",
      "SUBLIME 0.7000000000000001 2\n",
      "SUBLIME 0.9000000000000001 0\n",
      "SUBLIME 0.9000000000000001 1\n",
      "SUBLIME 0.9000000000000001 2\n",
      "att dict_values([0.3826229981486248, 0.4356214994811447, 0.4706477322013145, 0.550387171266291, 0.5330435442010706])\n",
      "SUBLIME 0.1 0\n",
      "SUBLIME 0.1 1\n",
      "SUBLIME 0.1 2\n",
      "SUBLIME 0.30000000000000004 0\n",
      "SUBLIME 0.30000000000000004 1\n",
      "SUBLIME 0.30000000000000004 2\n",
      "SUBLIME 0.5000000000000001 0\n",
      "SUBLIME 0.5000000000000001 1\n",
      "SUBLIME 0.5000000000000001 2\n",
      "SUBLIME 0.7000000000000001 0\n",
      "SUBLIME 0.7000000000000001 1\n",
      "SUBLIME 0.7000000000000001 2\n",
      "SUBLIME 0.9000000000000001 0\n",
      "SUBLIME 0.9000000000000001 1\n",
      "SUBLIME 0.9000000000000001 2\n",
      "mlp dict_values([0.20532309576342486, 0.21718644638447512, 0.23172018210817055, 0.23184597890860784, 0.28974877109054015])\n"
     ]
    }
   ],
   "source": [
    "seeds = np.arange(0, 3, dtype=int) # seed = {0,1,2}\n",
    "rates = np.arange(0.1, 1.0, 0.2) # minimum rention rates\n",
    "from sklearn.metrics import normalized_mutual_info_score as NMI, adjusted_mutual_info_score as AMI, adjusted_rand_score as ARI\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "for model in models:\n",
    "    \n",
    "    for graph_learner in graph_learners:\n",
    "    \n",
    "        nmi_m, ami_m, ari_m = {}, {}, {}\n",
    "\n",
    "        for rate in rates:\n",
    "            nmis, amis, aris = [], [], []\n",
    "\n",
    "\n",
    "\n",
    "            for seed in seeds:\n",
    "                print(model, rate, seed)\n",
    "\n",
    "                adj, features, labels, mask = load_cora_full_im(rate, seed)\n",
    "\n",
    "                np.random.seed(seed)\n",
    "                torch.manual_seed(seed)\n",
    "                random.seed(seed)\n",
    "                torch.cuda.manual_seed(seed)  \n",
    "\n",
    "                data = np.load(\"{}/Cluster_im/{}/lo_cora-full_preds_{:.1f}_{:d}_5.npz\".format(model, graph_learner, rate, seed))\n",
    "                preds = data[\"preds\"]\n",
    "\n",
    "                nmi = NMI(labels, preds)\n",
    "                ami = AMI(labels, preds)\n",
    "                ari = ARI(labels, preds)\n",
    "\n",
    "                nmis.append(nmi)\n",
    "                amis.append(ami)\n",
    "                aris.append(ari)\n",
    "\n",
    "            nmi_m[rate] = np.mean(nmis)\n",
    "            ami_m[rate] = np.mean(amis)\n",
    "            ari_m[rate] = np.mean(aris)\n",
    "\n",
    "    #     print(nmi_m.values())\n",
    "    #     print(ami_m.values())\n",
    "        print(graph_learner, ari_m.values())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4b7de64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUBLIME 0.1 0\n",
      "SUBLIME 0.1 1\n",
      "SUBLIME 0.1 2\n",
      "SUBLIME 0.30000000000000004 0\n",
      "SUBLIME 0.30000000000000004 1\n",
      "SUBLIME 0.30000000000000004 2\n",
      "SUBLIME 0.5000000000000001 0\n",
      "SUBLIME 0.5000000000000001 1\n",
      "SUBLIME 0.5000000000000001 2\n",
      "SUBLIME 0.7000000000000001 0\n",
      "SUBLIME 0.7000000000000001 1\n",
      "SUBLIME 0.7000000000000001 2\n",
      "SUBLIME 0.9000000000000001 0\n",
      "SUBLIME 0.9000000000000001 1\n",
      "SUBLIME 0.9000000000000001 2\n",
      "fgp dict_values([0.5756234590491942, 0.6148761708203061, 0.6297371232868892, 0.645057391788908, 0.6442105528612728])\n",
      "SUBLIME 0.1 0\n",
      "SUBLIME 0.1 1\n",
      "SUBLIME 0.1 2\n",
      "SUBLIME 0.30000000000000004 0\n",
      "SUBLIME 0.30000000000000004 1\n",
      "SUBLIME 0.30000000000000004 2\n",
      "SUBLIME 0.5000000000000001 0\n",
      "SUBLIME 0.5000000000000001 1\n",
      "SUBLIME 0.5000000000000001 2\n",
      "SUBLIME 0.7000000000000001 0\n",
      "SUBLIME 0.7000000000000001 1\n",
      "SUBLIME 0.7000000000000001 2\n",
      "SUBLIME 0.9000000000000001 0\n",
      "SUBLIME 0.9000000000000001 1\n",
      "SUBLIME 0.9000000000000001 2\n",
      "att dict_values([0.46113984484490117, 0.4927775600653492, 0.5229090676641189, 0.5644345072010974, 0.5458309652922497])\n",
      "SUBLIME 0.1 0\n",
      "SUBLIME 0.1 1\n",
      "SUBLIME 0.1 2\n",
      "SUBLIME 0.30000000000000004 0\n",
      "SUBLIME 0.30000000000000004 1\n",
      "SUBLIME 0.30000000000000004 2\n",
      "SUBLIME 0.5000000000000001 0\n",
      "SUBLIME 0.5000000000000001 1\n",
      "SUBLIME 0.5000000000000001 2\n",
      "SUBLIME 0.7000000000000001 0\n",
      "SUBLIME 0.7000000000000001 1\n",
      "SUBLIME 0.7000000000000001 2\n",
      "SUBLIME 0.9000000000000001 0\n",
      "SUBLIME 0.9000000000000001 1\n",
      "SUBLIME 0.9000000000000001 2\n",
      "mlp dict_values([0.2685981654074345, 0.2875229014180353, 0.29317007194093486, 0.3292772022755966, 0.37927053367826175])\n"
     ]
    }
   ],
   "source": [
    "seeds = np.arange(0, 3, dtype=int) # seed = {0,1,2}\n",
    "rates = np.arange(0.1, 1.0, 0.2) # minimum rention rates\n",
    "from sklearn.metrics import normalized_mutual_info_score as NMI, adjusted_mutual_info_score as AMI, adjusted_rand_score as ARI\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "for model in models:\n",
    "    \n",
    "    for graph_learner in graph_learners:\n",
    "    \n",
    "        nmi_m, ami_m, ari_m = {}, {}, {}\n",
    "\n",
    "        for rate in rates:\n",
    "            nmis, amis, aris = [], [], []\n",
    "\n",
    "\n",
    "\n",
    "            for seed in seeds:\n",
    "                print(model, rate, seed)\n",
    "\n",
    "                adj, features, labels, mask = load_cora_full_im(rate, seed)\n",
    "\n",
    "                np.random.seed(seed)\n",
    "                torch.manual_seed(seed)\n",
    "                random.seed(seed)\n",
    "                torch.cuda.manual_seed(seed)  \n",
    "\n",
    "                data = np.load(\"{}/Cluster_im/{}/lo_cora-full_preds_{:.1f}_{:d}_5.npz\".format(model, graph_learner, rate, seed))\n",
    "                preds = data[\"preds\"]\n",
    "\n",
    "                nmi = NMI(labels, preds)\n",
    "                ami = AMI(labels, preds)\n",
    "                ari = ARI(labels, preds)\n",
    "\n",
    "                nmis.append(nmi)\n",
    "                amis.append(ami)\n",
    "                aris.append(ari)\n",
    "\n",
    "            nmi_m[rate] = np.mean(nmis)\n",
    "            ami_m[rate] = np.mean(amis)\n",
    "            ari_m[rate] = np.mean(aris)\n",
    "\n",
    "    #     print(nmi_m.values())\n",
    "    #     print(ami_m.values())\n",
    "        print(graph_learner, ami_m.values())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107e4d34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ddf15c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e3ba27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "38c99cac",
   "metadata": {},
   "source": [
    "## SUBLIME cora-full diff cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2da07696",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    \"SUBLIME\"\n",
    "]\n",
    "graph_learners = [\n",
    "    \"fgp\",\n",
    "    \"att\",\n",
    "    \"mlp\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0568a44f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUBLIME 5 0\n",
      "SUBLIME 5 1\n",
      "SUBLIME 5 2\n",
      "SUBLIME 10 0\n",
      "SUBLIME 10 1\n",
      "SUBLIME 10 2\n",
      "SUBLIME 15 0\n",
      "SUBLIME 15 1\n",
      "SUBLIME 15 2\n",
      "SUBLIME 20 0\n",
      "SUBLIME 20 1\n",
      "SUBLIME 20 2\n",
      "SUBLIME 25 0\n",
      "SUBLIME 25 1\n",
      "SUBLIME 25 2\n",
      "fgp dict_values([0.633495910732802, 0.582027950689552, 0.440761139567152, 0.3718443601639429, 0.3301357151839557])\n",
      "SUBLIME 5 0\n",
      "SUBLIME 5 1\n",
      "SUBLIME 5 2\n",
      "SUBLIME 10 0\n",
      "SUBLIME 10 1\n",
      "SUBLIME 10 2\n",
      "SUBLIME 15 0\n",
      "SUBLIME 15 1\n",
      "SUBLIME 15 2\n",
      "SUBLIME 20 0\n",
      "SUBLIME 20 1\n",
      "SUBLIME 20 2\n",
      "SUBLIME 25 0\n",
      "SUBLIME 25 1\n",
      "SUBLIME 25 2\n",
      "att dict_values([0.5471410714347225, 0.5542249302794472, 0.4537958884334509, 0.388321312924848, 0.3222015647902495])\n",
      "SUBLIME 5 0\n",
      "SUBLIME 5 1\n",
      "SUBLIME 5 2\n",
      "SUBLIME 10 0\n",
      "SUBLIME 10 1\n",
      "SUBLIME 10 2\n",
      "SUBLIME 15 0\n",
      "SUBLIME 15 1\n",
      "SUBLIME 15 2\n",
      "SUBLIME 20 0\n",
      "SUBLIME 20 1\n",
      "SUBLIME 20 2\n",
      "SUBLIME 25 0\n",
      "SUBLIME 25 1\n",
      "SUBLIME 25 2\n",
      "mlp dict_values([0.25725448102138, 0.262061438906628, 0.19162407231526837, 0.1728509997346439, 0.2316108605179316])\n"
     ]
    }
   ],
   "source": [
    "seeds = np.arange(0, 3, dtype=int) # seed = {0,1,2}\n",
    "nclasses = np.arange(5, 30, 5, dtype=int)\n",
    "from sklearn.metrics import normalized_mutual_info_score as NMI, adjusted_mutual_info_score as AMI, adjusted_rand_score as ARI\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "for model in models:\n",
    "    \n",
    "    for graph_learner in graph_learners:\n",
    "    \n",
    "        nmi_m, ami_m, ari_m = {}, {}, {}\n",
    "\n",
    "        for nclass in nclasses:\n",
    "            nmis, amis, aris = [], [], []\n",
    "\n",
    "\n",
    "\n",
    "            for seed in seeds:\n",
    "                print(model, nclass, seed)\n",
    "\n",
    "                adj, features, labels, mask = load_cora_full_diff_cls(nclass, seed)\n",
    "\n",
    "                np.random.seed(seed)\n",
    "                torch.manual_seed(seed)\n",
    "                random.seed(seed)\n",
    "                torch.cuda.manual_seed(seed)  \n",
    "\n",
    "                data = np.load(\"{}/Cluster_diff_cls/{}/lo_cora-full_preds_{:d}_{:d}.npz\".format(model, graph_learner, nclass, seed))\n",
    "                preds = data[\"preds\"]\n",
    "\n",
    "                nmi = NMI(labels, preds)\n",
    "                ami = AMI(labels, preds)\n",
    "                ari = ARI(labels, preds)\n",
    "\n",
    "                nmis.append(nmi)\n",
    "                amis.append(ami)\n",
    "                aris.append(ari)\n",
    "\n",
    "            nmi_m[nclass] = np.mean(nmis)\n",
    "            ami_m[nclass] = np.mean(amis)\n",
    "            ari_m[nclass] = np.mean(aris)\n",
    "\n",
    "    #     print(nmi_m.values())\n",
    "    #     print(ami_m.values())\n",
    "        print(graph_learner, ari_m.values())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2fa8bc69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUBLIME 5 0\n",
      "SUBLIME 5 1\n",
      "SUBLIME 5 2\n",
      "SUBLIME 10 0\n",
      "SUBLIME 10 1\n",
      "SUBLIME 10 2\n",
      "SUBLIME 15 0\n",
      "SUBLIME 15 1\n",
      "SUBLIME 15 2\n",
      "SUBLIME 20 0\n",
      "SUBLIME 20 1\n",
      "SUBLIME 20 2\n",
      "SUBLIME 25 0\n",
      "SUBLIME 25 1\n",
      "SUBLIME 25 2\n",
      "fgp dict_values([0.6146906141421695, 0.6266376104110057, 0.5591877916211724, 0.5209136390515087, 0.49712108193821547])\n",
      "SUBLIME 5 0\n",
      "SUBLIME 5 1\n",
      "SUBLIME 5 2\n",
      "SUBLIME 10 0\n",
      "SUBLIME 10 1\n",
      "SUBLIME 10 2\n",
      "SUBLIME 15 0\n",
      "SUBLIME 15 1\n",
      "SUBLIME 15 2\n",
      "SUBLIME 20 0\n",
      "SUBLIME 20 1\n",
      "SUBLIME 20 2\n",
      "SUBLIME 25 0\n",
      "SUBLIME 25 1\n",
      "SUBLIME 25 2\n",
      "att dict_values([0.5751445892406952, 0.5965361140667188, 0.5437071319975794, 0.5170591758437012, 0.48327819089081764])\n",
      "SUBLIME 5 0\n",
      "SUBLIME 5 1\n",
      "SUBLIME 5 2\n",
      "SUBLIME 10 0\n",
      "SUBLIME 10 1\n",
      "SUBLIME 10 2\n",
      "SUBLIME 15 0\n",
      "SUBLIME 15 1\n",
      "SUBLIME 15 2\n",
      "SUBLIME 20 0\n",
      "SUBLIME 20 1\n",
      "SUBLIME 20 2\n",
      "SUBLIME 25 0\n",
      "SUBLIME 25 1\n",
      "SUBLIME 25 2\n",
      "mlp dict_values([0.3255760727503017, 0.3674822690575623, 0.3332568795411041, 0.30962900212343264, 0.41608349735283134])\n"
     ]
    }
   ],
   "source": [
    "seeds = np.arange(0, 3, dtype=int) # seed = {0,1,2}\n",
    "nclasses = np.arange(5, 30, 5, dtype=int)\n",
    "from sklearn.metrics import normalized_mutual_info_score as NMI, adjusted_mutual_info_score as AMI, adjusted_rand_score as ARI\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "for model in models:\n",
    "    \n",
    "    for graph_learner in graph_learners:\n",
    "    \n",
    "        nmi_m, ami_m, ari_m = {}, {}, {}\n",
    "\n",
    "        for nclass in nclasses:\n",
    "            nmis, amis, aris = [], [], []\n",
    "\n",
    "\n",
    "\n",
    "            for seed in seeds:\n",
    "                print(model, nclass, seed)\n",
    "\n",
    "                adj, features, labels, mask = load_cora_full_diff_cls(nclass, seed)\n",
    "\n",
    "                np.random.seed(seed)\n",
    "                torch.manual_seed(seed)\n",
    "                random.seed(seed)\n",
    "                torch.cuda.manual_seed(seed)  \n",
    "\n",
    "                data = np.load(\"{}/Cluster_diff_cls/{}/lo_cora-full_preds_{:d}_{:d}.npz\".format(model, graph_learner, nclass, seed))\n",
    "                preds = data[\"preds\"]\n",
    "\n",
    "                nmi = NMI(labels, preds)\n",
    "                ami = AMI(labels, preds)\n",
    "                ari = ARI(labels, preds)\n",
    "\n",
    "                nmis.append(nmi)\n",
    "                amis.append(ami)\n",
    "                aris.append(ari)\n",
    "\n",
    "            nmi_m[nclass] = np.mean(nmis)\n",
    "            ami_m[nclass] = np.mean(amis)\n",
    "            ari_m[nclass] = np.mean(aris)\n",
    "\n",
    "    #     print(nmi_m.values())\n",
    "    #     print(ami_m.values())\n",
    "        print(graph_learner, ami_m.values())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a20ba18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "74460e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUBLIME 2 0\n",
      "SUBLIME 2 1\n",
      "SUBLIME 2 2\n",
      "SUBLIME 4 0\n",
      "SUBLIME 4 1\n",
      "SUBLIME 4 2\n",
      "SUBLIME 6 0\n",
      "SUBLIME 6 1\n",
      "SUBLIME 6 2\n",
      "SUBLIME 8 0\n",
      "SUBLIME 8 1\n",
      "SUBLIME 8 2\n",
      "SUBLIME 10 0\n",
      "SUBLIME 10 1\n",
      "SUBLIME 10 2\n",
      "fgp dict_values([0.4064044309959763, 0.656608791774487, 0.6487981800729842, 0.5682809943679724, 0.5685072368391868])\n",
      "SUBLIME 2 0\n",
      "SUBLIME 2 1\n",
      "SUBLIME 2 2\n",
      "SUBLIME 4 0\n",
      "SUBLIME 4 1\n",
      "SUBLIME 4 2\n",
      "SUBLIME 6 0\n",
      "SUBLIME 6 1\n",
      "SUBLIME 6 2\n",
      "SUBLIME 8 0\n",
      "SUBLIME 8 1\n",
      "SUBLIME 8 2\n",
      "SUBLIME 10 0\n",
      "SUBLIME 10 1\n",
      "SUBLIME 10 2\n",
      "att dict_values([0.19171690159196556, 0.5346405619097886, 0.5628829759622272, 0.548700970218574, 0.5542249302794472])\n",
      "SUBLIME 2 0\n",
      "SUBLIME 2 1\n",
      "SUBLIME 2 2\n",
      "SUBLIME 4 0\n",
      "SUBLIME 4 1\n",
      "SUBLIME 4 2\n",
      "SUBLIME 6 0\n",
      "SUBLIME 6 1\n",
      "SUBLIME 6 2\n",
      "SUBLIME 8 0\n",
      "SUBLIME 8 1\n",
      "SUBLIME 8 2\n",
      "SUBLIME 10 0\n",
      "SUBLIME 10 1\n",
      "SUBLIME 10 2\n",
      "mlp dict_values([0.17500353126876814, 0.24413877562829214, 0.2888437417054184, 0.2695169852282508, 0.262061438906628])\n"
     ]
    }
   ],
   "source": [
    "seeds = np.arange(0, 3, dtype=int) # seed = {0,1,2}\n",
    "nclasses = np.arange(2, 12, 2, dtype=int)\n",
    "from sklearn.metrics import normalized_mutual_info_score as NMI, adjusted_mutual_info_score as AMI, adjusted_rand_score as ARI\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "for model in models:\n",
    "    \n",
    "    for graph_learner in graph_learners:\n",
    "    \n",
    "        nmi_m, ami_m, ari_m = {}, {}, {}\n",
    "\n",
    "        for nclass in nclasses:\n",
    "            nmis, amis, aris = [], [], []\n",
    "\n",
    "\n",
    "\n",
    "            for seed in seeds:\n",
    "                print(model, nclass, seed)\n",
    "\n",
    "                adj, features, labels, mask = load_cora_full_diff_cls(nclass, seed)\n",
    "\n",
    "                np.random.seed(seed)\n",
    "                torch.manual_seed(seed)\n",
    "                random.seed(seed)\n",
    "                torch.cuda.manual_seed(seed)  \n",
    "\n",
    "                data = np.load(\"{}/Cluster_diff_cls/{}/lo_cora-full_preds_{:d}_{:d}.npz\".format(model, graph_learner, nclass, seed))\n",
    "                preds = data[\"preds\"]\n",
    "\n",
    "                nmi = NMI(labels, preds)\n",
    "                ami = AMI(labels, preds)\n",
    "                ari = ARI(labels, preds)\n",
    "\n",
    "                nmis.append(nmi)\n",
    "                amis.append(ami)\n",
    "                aris.append(ari)\n",
    "\n",
    "            nmi_m[nclass] = np.mean(nmis)\n",
    "            ami_m[nclass] = np.mean(amis)\n",
    "            ari_m[nclass] = np.mean(aris)\n",
    "\n",
    "    #     print(nmi_m.values())\n",
    "    #     print(ami_m.values())\n",
    "        print(graph_learner, ari_m.values())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "64c0315f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUBLIME 2 0\n",
      "SUBLIME 2 1\n",
      "SUBLIME 2 2\n",
      "SUBLIME 4 0\n",
      "SUBLIME 4 1\n",
      "SUBLIME 4 2\n",
      "SUBLIME 6 0\n",
      "SUBLIME 6 1\n",
      "SUBLIME 6 2\n",
      "SUBLIME 8 0\n",
      "SUBLIME 8 1\n",
      "SUBLIME 8 2\n",
      "SUBLIME 10 0\n",
      "SUBLIME 10 1\n",
      "SUBLIME 10 2\n",
      "fgp dict_values([0.510801030840765, 0.6364214439449359, 0.6483595370038467, 0.5975062883907314, 0.6197452468482221])\n",
      "SUBLIME 2 0\n",
      "SUBLIME 2 1\n",
      "SUBLIME 2 2\n",
      "SUBLIME 4 0\n",
      "SUBLIME 4 1\n",
      "SUBLIME 4 2\n",
      "SUBLIME 6 0\n",
      "SUBLIME 6 1\n",
      "SUBLIME 6 2\n",
      "SUBLIME 8 0\n",
      "SUBLIME 8 1\n",
      "SUBLIME 8 2\n",
      "SUBLIME 10 0\n",
      "SUBLIME 10 1\n",
      "SUBLIME 10 2\n",
      "att dict_values([0.3562028929257411, 0.5614017338143686, 0.5948702023066264, 0.5740049351912396, 0.5965361140667188])\n",
      "SUBLIME 2 0\n",
      "SUBLIME 2 1\n",
      "SUBLIME 2 2\n",
      "SUBLIME 4 0\n",
      "SUBLIME 4 1\n",
      "SUBLIME 4 2\n",
      "SUBLIME 6 0\n",
      "SUBLIME 6 1\n",
      "SUBLIME 6 2\n",
      "SUBLIME 8 0\n",
      "SUBLIME 8 1\n",
      "SUBLIME 8 2\n",
      "SUBLIME 10 0\n",
      "SUBLIME 10 1\n",
      "SUBLIME 10 2\n",
      "mlp dict_values([0.2976203122617516, 0.3268317888920723, 0.3578972803959107, 0.34930712090963806, 0.3674822690575623])\n"
     ]
    }
   ],
   "source": [
    "seeds = np.arange(0, 3, dtype=int) # seed = {0,1,2}\n",
    "nclasses = np.arange(2, 12, 2, dtype=int)\n",
    "from sklearn.metrics import normalized_mutual_info_score as NMI, adjusted_mutual_info_score as AMI, adjusted_rand_score as ARI\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "for model in models:\n",
    "    \n",
    "    for graph_learner in graph_learners:\n",
    "    \n",
    "        nmi_m, ami_m, ari_m = {}, {}, {}\n",
    "\n",
    "        for nclass in nclasses:\n",
    "            nmis, amis, aris = [], [], []\n",
    "\n",
    "\n",
    "\n",
    "            for seed in seeds:\n",
    "                print(model, nclass, seed)\n",
    "\n",
    "                adj, features, labels, mask = load_cora_full_diff_cls(nclass, seed)\n",
    "\n",
    "                np.random.seed(seed)\n",
    "                torch.manual_seed(seed)\n",
    "                random.seed(seed)\n",
    "                torch.cuda.manual_seed(seed)  \n",
    "\n",
    "                data = np.load(\"{}/Cluster_diff_cls/{}/lo_cora-full_preds_{:d}_{:d}.npz\".format(model, graph_learner, nclass, seed))\n",
    "                preds = data[\"preds\"]\n",
    "\n",
    "                nmi = NMI(labels, preds)\n",
    "                ami = AMI(labels, preds)\n",
    "                ari = ARI(labels, preds)\n",
    "\n",
    "                nmis.append(nmi)\n",
    "                amis.append(ami)\n",
    "                aris.append(ari)\n",
    "\n",
    "            nmi_m[nclass] = np.mean(nmis)\n",
    "            ami_m[nclass] = np.mean(amis)\n",
    "            ari_m[nclass] = np.mean(aris)\n",
    "\n",
    "    #     print(nmi_m.values())\n",
    "    #     print(ami_m.values())\n",
    "        print(graph_learner, ami_m.values())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b987856f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a147a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyg] *",
   "language": "python",
   "name": "conda-env-pyg-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
